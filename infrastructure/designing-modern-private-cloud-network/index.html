<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Designing a modern multi-tenant DC network | Blah, Cloud</title>
<meta name=keywords content="architecture,datacenter,l2 over l3,networking,vxlan">
<meta name=description content="Thought processes for designing a highly scalable datacenter network">
<meta name=author content="Myles Gray">
<link rel=canonical href=https://blah.cloud/infrastructure/designing-modern-private-cloud-network/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.ef8bac17525c299e0f71a2594f31de4bec4d2654aa856f57aca5a9410c5e28da.css integrity="sha256-74usF1JcKZ4PcaJZTzHeS+xNJlSqhW9XrKWpQQxeKNo=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/scroll-toc.min.c4f9a8e78694df8c52f7d3b0c44492ff3dcfa95d42215176796bef76438bc463.js integrity="sha256-xPmo54aU34xS99OwxESS/z3PqV1CIVF2eWvvdkOLxGM="></script>
<link rel=icon href=https://blah.cloud/images/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://blah.cloud/images/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://blah.cloud/images/favicon-32x32.png>
<link rel=apple-touch-icon href=https://blah.cloud/images/apple-touch-icon.png>
<link rel=mask-icon href=https://blah.cloud/images/logo.png>
<meta name=theme-color media="(prefers-color-scheme: dark)" content="rgba(88, 89, 91, 1)">
<meta name=theme-color content="rgba(240, 202, 102, 1)">
<meta name=msapplication-TileColor content="rgba(240, 202, 102, 1)">
<meta name=generator content="Hugo 0.89.2">
<meta property="og:title" content="Designing a modern multi-tenant DC network">
<meta property="og:description" content="Thought processes for designing a highly scalable datacenter network">
<meta property="og:type" content="article">
<meta property="og:url" content="https://blah.cloud/infrastructure/designing-modern-private-cloud-network/"><meta property="og:image" content="https://blah.cloud/infrastructure/designing-modern-private-cloud-network/images/og-card.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2016-10-27T12:00:36+00:00">
<meta property="article:modified_time" content="2021-10-25T13:54:00+00:00"><meta property="og:site_name" content="Blah, Cloud">
<meta property="og:see_also" content="https://blah.cloud/networks/implementing-multi-tenant-networking-platform-nsx/"><meta property="og:see_also" content="https://blah.cloud/infrastructure/designing-networking-platform-iaas-multi-tenancy/"><meta property="og:see_also" content="https://blah.cloud/infrastructure/multi-tenant-network-challenges/">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://blah.cloud/infrastructure/designing-modern-private-cloud-network/images/og-card.png"><meta name=twitter:title content="Designing a modern multi-tenant DC network">
<meta name=twitter:description content="Thought processes for designing a highly scalable datacenter network">
<meta name=twitter:site content="@mylesagray">
<meta name=twitter:creator content="@mylesagray">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Designing a modern multi-tenant DC network","item":"https://blah.cloud/infrastructure/designing-modern-private-cloud-network/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Designing a modern multi-tenant DC network","name":"Designing a modern multi-tenant DC network","description":"Thought processes for designing a highly scalable datacenter network","keywords":["architecture","datacenter","l2 over l3","networking","vxlan"],"wordCount":"3121","inLanguage":"en","image":"https://blah.cloud/infrastructure/designing-modern-private-cloud-network/images/DC-Network-BGP-AS-Leaf-Spine.png","datePublished":"2016-10-27T12:00:36Z","dateModified":"2021-10-25T13:54:00Z","author":{"@type":"Person","name":"Myles Gray","url":"https:\/\/blah.cloud\/about"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blah.cloud/infrastructure/designing-modern-private-cloud-network/"},"copyrightHolder":"Myles Gray","copyrightYear":"2016","isFamilyFriendly":"true","publisher":{"@type":"Person","name":"Myles Gray","logo":{"@type":"ImageObject","url":"https://blah.cloud/images/me.jpg"}}}</script>
<script defer data-domain=blah.cloud data-api=/backend/api/event src=/backend/js/script.outbound-links.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script>
</head>
<body id=top>
<script>window.matchMedia&&window.matchMedia('(prefers-color-scheme: dark)').matches?(document.body.classList.add('dark'),document.body.classList.remove('light')):(document.body.classList.remove('dark'),document.body.classList.add('light'));const darkModeMediaQuery=window.matchMedia('(prefers-color-scheme: dark)');darkModeMediaQuery.addListener(a=>{const b=a.matches;b?(document.body.classList.add('dark'),document.body.classList.remove('light')):(document.body.classList.remove('dark'),document.body.classList.add('light'))})</script>
<noscript>
<style type=text/css>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(240, 202, 102, 1);--secondary:rgba(216, 214, 197, 1);--tertiary:rgba(128, 130 ,133 , 1);--content:rgba(206, 205, 188, 1);--hljs-bg:#282a36;--code-bg:#282a36;--border:rgba(240, 202, 102, 1)}.list{background:var(--theme)}}</style>
</noscript>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://blah.cloud/ accesskey=h title="Blah, Cloud. (Alt + H)">
<picture>
<source media="(min-width: 768px)" srcset=/images/logo-title.avif type=image/avif alt=logo width=245 height=34>
<source media="(min-width: 768px)" srcset=/images/logo-title.webp type=image/webp alt=logo width=245 height=34>
<source srcset=/images/logo.avif type=image/avif alt=logo width=65 height=65>
<source srcset=/images/logo.webp type=image/webp alt=logo width=65 height=65>
<img src=/images/logo-title.png alt=logo aria-label=logo width=245 height=34>
</picture></a>
</div>
<span class=logo-switches>
</span>
<i class=hamburger><svg xmlns="http://www.w3.org/2000/svg" width="24" height="28" viewBox="0 0 24 28"><path d="M24 21v2c0 .547-.453 1-1 1H1c-.547.0-1-.453-1-1v-2c0-.547.453-1 1-1h22c.547.0 1 .453 1 1zm0-8v2c0 .547-.453 1-1 1H1c-.547.0-1-.453-1-1v-2c0-.547.453-1 1-1h22c.547.0 1 .453 1 1zm0-8v2c0 .547-.453 1-1 1H1c-.547.0-1-.453-1-1V5c0-.547.453-1 1-1h22c.547.0 1 .453 1 1z"/></svg>
</i>
<ul id=menu>
<li>
<a href=https://blah.cloud/blog/ title=blog>
<span>blog</span>
</a>
</li>
<li>
<a href=https://blah.cloud/now/ title=now>
<span>now</span>
</a>
</li>
<li>
<a href=https://blah.cloud/works/ title=works>
<span>works</span>
</a>
</li>
<li>
<a href=https://blah.cloud/search/ title=" (Alt + /)" accesskey=/>
<span><svg style="height:1em" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="fill-current w-5" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span>
</a>
</li>
</ul>
</nav>
</header>
<div class=container>
<main class=main>
<div class=wrapper>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Designing a modern multi-tenant DC network
</h1>
<div class=post-description>
Thought processes for designing a highly scalable datacenter network
</div>
<div class=post-meta>October 27, 2016&nbsp;·&nbsp;Myles Gray&nbsp;|&nbsp;<a href=https://github.com/mylesagray/blog/blob/master/content/posts/2016-10-27-designing-modern-private-cloud-network/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#requirement aria-label=Requirement>Requirement</a></li>
<li>
<a href=#initial-thoughts aria-label="Initial Thoughts">Initial Thoughts</a></li>
<li>
<a href=#engineering aria-label=Engineering>Engineering</a><ul>
<li>
<a href=#the-l2-problem aria-label="The L2 Problem">The L2 Problem</a><ul>
<li>
<a href=#loops aria-label=Loops>Loops</a></li>
<li>
<a href=#link-utilisation aria-label="Link Utilisation">Link Utilisation</a></li>
<li>
<a href=#limitations-on-scale aria-label="Limitations on Scale">Limitations on Scale</a></li>
<li>
<a href=#operational-risk aria-label="Operational Risk">Operational Risk</a></li></ul>
</li>
<li>
<a href=#solving-the-l2-problem-with-l3 aria-label="Solving the L2 problem with L3">Solving the L2 problem with L3</a><ul>
<li>
<a href=#l2-over-l3 aria-label="L2 over L3">L2 over L3</a><ul>
<li>
<a href=#technologyshowdown aria-label=#TechnologyShowdown>#TechnologyShowdown</a></li></ul>
</li>
<li>
<a href=#providing-an-l3-core aria-label="Providing an L3 core">Providing an L3 core</a></li>
<li>
<a href=#routing aria-label=Routing>Routing</a></li></ul>
</li></ul>
</li>
<li>
<a href=#wrapping-up aria-label="Wrapping Up">Wrapping Up</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>Over the last 12 months my posting has been dialled back, this isn&rsquo;t for lack of wanting or ideas, mainly a lack of time and mental bandwidth. Reason being, I have been designing and implementing a new cloud platform (namely <a href=https://www.novosco.com/cloud-solutions/single-tenant-cloud>&ldquo;STC&rdquo;</a>) for my employer, Novosco - as with any new service or product this requires an element of discretion - but now is the time to let slip some of the detail on what makes the service tick!</p>
<p>Boilerplate caveat: any views or opinions expressed in this post or on this blog in general are my own and not that of my employer.</p>
<h2 id=requirement>Requirement<a hidden class=anchor aria-hidden=true href=#requirement>#</a></h2>
<p>Back when this project kicked off the brief was &ldquo;make something scale-out, with dedicated kit per tenant in which they can manage their own virtualisation environment as if it were on-prem, BYO Licensing, BYO Backup, BYO Disaster Recovery&rdquo;.</p>
<p><em>We like the idea of Bring Your Own X for this product</em></p>
<p><img loading=lazy src=http://i.imgur.com/ny7qxSN.jpg alt="&amp;ldquo;All the things&amp;rdquo;"></p>
<p>So, scale out, but dedicated hardware per tenant and we have to be able to spin these up at will, without much lead time and allow them to manage everything on their environment.</p>
<h2 id=initial-thoughts>Initial Thoughts<a hidden class=anchor aria-hidden=true href=#initial-thoughts>#</a></h2>
<p>The obvious solution for this kind of request is to go the whole &ldquo;SDDC&rdquo; road; SDS, SDN, the works, but then commercially it becomes ridiculous, plus SDN tech like NSX doesn&rsquo;t allow for vmkernel traffic to be encapsulated, not that this is a blocker but, it doesn&rsquo;t help - so maybe we can meet halfway?</p>
<p>If we have a SDS stack; ScaleIO, SpringPath, VSAN, &mldr;Maxta - just some hyperconverged node style SDS solution with a more traditional networking stack - could it be commercially viable and yet still meet the requirements we set out with?</p>
<p>Problems are obviously going to rear their heads when you have a dedicated compute environment that allows the ability to install BYO-anything on said environment, the focus very quickly becomes the shared components - in this case, networking.</p>
<p>I will go into the physical topology in another article as well as the decisions and math that led to it, just know that it is a 10/40GbE Spine and Leaf design with redundant ToR switching that is shared between customer environments.</p>
<h2 id=engineering>Engineering<a hidden class=anchor aria-hidden=true href=#engineering>#</a></h2>
<p>Generally when people want to separate customers that use the same networking kit; VLANs are the first port of call - but as a wise man once told me:</p>
<blockquote>
<p>Friends don&rsquo;t let friends build large L2 networks</p>
</blockquote>
<p>This is easy to say, but <strong><em>why</em></strong>?</p>
<h3 id=the-l2-problem>The L2 Problem<a hidden class=anchor aria-hidden=true href=#the-l2-problem>#</a></h3>
<p>A few reasons, large L2 is certainly do-able, and a great many SPs do maintain and manage large L2 networks, so what&rsquo;s the problem?</p>
<h4 id=loops>Loops<a hidden class=anchor aria-hidden=true href=#loops>#</a></h4>
<p>Looping and L2 networking are inseparable, there is always a pub argument to be had. Where multiple links to the same devices cause continuous looping of BUM (Broadcast, Unknown Unicast, Multicast) traffic.</p>
<p>There are of course remedies to this, MC-LAG, Bonding, Spanning Tree in any flavour will kill off the problems with looping on a multi-link switch to switch level - these of course come with their own limitations; link utilisation and load balancing being primary of which, with link aggregation of all flavours being more band-aid type solutions than &ldquo;solving the L2 problem&rdquo; - after all, you still need spanning tree even if you bond all your links to stop topological loops, and you still only have 4096 VLANs.</p>
<p>You can get into some pretty ugly config when you spin up a STP instance per VLAN (a-la MST/PVST) or you have a single instance and just lose half your bandwidth (or more).</p>
<p>But&mldr; What if the looping device only has a single link and doesn&rsquo;t participate in spanning tree?</p>
<p>That&rsquo;s right, you can have a loop on an STP enabled network from a device with only a single NIC. VMware&rsquo;s vSwitching (both standard and distributed) are cases of such, or at least with VMs configured incorrectly they can be.</p>
<p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&cmd=displayKC&externalId=2017193">Read this KB</a> - it is the harbinger of doom when it comes to L2 scenarios you never want to encounter.</p>
<p>Engineering around a situation like this is extremely difficult - it largely becomes T&Cs and user education. That is not to say it cannot be mitigated at least to a degree. <a href=http://blog.ipspace.net/2012/09/dear-vmware-bpdu-filter-bpdu-guard.html>Ivan at IPSpace</a> makes some very good arguments with reference to VMware&rsquo;s BPDU position and vSwitch implementation that will further help you understand the problem should you not see it so far (he has diagrams!).</p>
<p>I would also highly recommends <a href=http://bradhedlund.com/2012/01/25/construct-a-leaf-spine-design-with-40g-or-10g-an-observation-in-scaling-the-fabric/>his webinars on DC networking topologies</a> on this topic if you&rsquo;re interested in the engineering behind them.</p>
<p>Forged transmits, port security, BDPU filter and BPDU guard can all be used to mitigate these <em>to a degree</em> for your specific scenario but won&rsquo;t stop the loops - the KB does a good job in dealing with these cases, as a service provider it is hard to determine if any of these cases are true unless you have visibility over the workloads operating on the environment, we do, thankfully - however, if you don&rsquo;t there are behaviours and conditions you can view as &ldquo;acceptable risks&rdquo; should someone not follow the ToS.</p>
<ul>
<li>What is the maximum speed/pps my link can loop at (the link to the host&rsquo;s speed)?</li>
<li>What traffic volume can my spine uplinks/switch take?</li>
<li>Is it acceptable that if the customer violates Terms of Use that their environment is &ldquo;DoS&rsquo;d&rdquo; by BPDU Guard on the switches?</li>
<li>Is it acceptable to request in the user manual if a customer wants to deploy an SSL-VPN appliance on the service they should contact the SP first for guidance?</li>
</ul>
<p>In some cases it may be acceptable to the SP that when a customer violates the ToS their environment stability is at risk <strong>as long as it does not affect other customers using the shared components</strong>. Your position is entirely up to you but a combination of the above usually makes a good compromise.</p>
<h4 id=link-utilisation>Link Utilisation<a hidden class=anchor aria-hidden=true href=#link-utilisation>#</a></h4>
<p>Second to looping, there is link utilisation, which actually is where a lot of the solutions to looping actually lie. It also happens to be where most vendors have their secret-sauce flavour of link aggregation (Dell - VLT, Brocade - VCS, Cisco - FabricPath), there is of course an open standard for this, <a href=http://www.cisco.com/c/en/us/about/press/internet-protocol-journal/back-issues/table-contents-53/143-trill.html>TRILL operates at layer 2/3</a> using a modified link-state routing protocol (IS-IS), but as of yet there is limited vendor support.</p>
<p>These all solve a Layer 2 problem, but with the caveat of proprietary tech, increased expense and eventually redundancy when an open standard takes over.</p>
<p>So, with that in mind, why use a large L2 &ldquo;fabric&rdquo; for your datacenter network - especially given it is a band-aide making Ethernet do things it was never meant to?</p>
<h4 id=limitations-on-scale>Limitations on Scale<a hidden class=anchor aria-hidden=true href=#limitations-on-scale>#</a></h4>
<p>We all know there is a VLAN limit of 4096, to most this might not seem like much of a limit and generally it isn&rsquo;t - but when you are dealing with multi-tenancy and separation on a per-tenant level where they may have an allocation of 30-50 VLANs each, that has to do transit links, LANs, DMZs, storage, interconnects - it doesn&rsquo;t add up to much when building out a scalable datacenter.</p>
<h4 id=operational-risk>Operational Risk<a hidden class=anchor aria-hidden=true href=#operational-risk>#</a></h4>
<p>A result of all the above, particularly loops is the risk involved from an operational standpoint - in a large scale L2 network there is always risk involved, Murphy&rsquo;s law and all that. You just need a switch that is not participating in STP, or indeed one with the wrong bridge ID to case a world of pain - granted you can say that about almost any switching environment, but L2 problems tend to be quite catastrophic.</p>
<h3 id=solving-the-l2-problem-with-l3>Solving the L2 problem with L3<a hidden class=anchor aria-hidden=true href=#solving-the-l2-problem-with-l3>#</a></h3>
<p>You know what solves all of the above? Layer 3 - no loops (let&rsquo;s ignore routing loops for now), fully utilised links from point to point when using a routed core with OSPF/BGP and ECMP selection with 5-tuple hashing for traffic distribution.</p>
<p>However, L2 adjacency is handy sometimes; like when you have a single tenant&rsquo;s compute cluster split across racks (remember, L3 routed Spine/Leaf). We start off with a DC looking like this, but we get an order for 3 new nodes - normally we would have to waste the space left in <code>Rack 1</code> to provide L2 adjacency when there is a L3 boundary between racks:</p>
<p><picture>
<source srcset=images/DC-Network-Scale-Out-1-Rack.avif type=image/avif>
<source srcset=images/DC-Network-Scale-Out-1-Rack.webp type=image/webp>
<img src=images/DC-Network-Scale-Out-1-Rack.png alt="DC Networking Single Rack" loading=lazy decoding=async>
</picture></p>
<p>If this is the case the L2 networks need to be accessible in both racks, if you vMotion a VM from one to another or DRS does it, it still needs to be contactable by all other VMs in that broadcast domain.</p>
<p>So is there a way to get all the benefits as a service provider from a big L3 routed core network, with the ability to fully utilise all our links and have no loops - but still provide L2 adjacency and segregation to tenants across racks?</p>
<h4 id=l2-over-l3>L2 over L3<a hidden class=anchor aria-hidden=true href=#l2-over-l3>#</a></h4>
<p><picture>
<source srcset=images/DC-Network-Overlay.avif type=image/avif>
<source srcset=images/DC-Network-Overlay.webp type=image/webp>
<img src=images/DC-Network-Overlay.png alt="DC Networking Overlay" loading=lazy decoding=async>
</picture></p>
<p>Sure, let&rsquo;s provide L2 over L3, there is a lot of tech out there to skin this particularly unlucky cat, most in use by telcos providing services like VPLS (typically using pseudo-wire tech AToM, GRE, L2TPv3) but sticking with a purely datacenter context the common options are VXLAN and EVPN.</p>
<p>Overlays allow us to do some very cool stuff, take the instance above where we have an L3 boundary between racks, but we have a customer that wants to come on with 3 nodes, to do this across racks, we need to provide L2 adjacency to the customer LAN networks to allow the VMs to move around easily - if we encapsulate the L2 traffic and route it across the L3 core we can decapsulate the packet on the destination ToR switch and the L2 traffic will continue as if it were in the same rack as below.</p>
<p><picture>
<source srcset=images/DC-Network-Scale-Out-2-Racks.avif type=image/avif>
<source srcset=images/DC-Network-Scale-Out-2-Racks.webp type=image/webp>
<img src=images/DC-Network-Scale-Out-2-Racks.png alt="DC Network two racks" loading=lazy decoding=async>
</picture></p>
<p>This of course can scale across multiple racks, as it is point to multi-point technology, allowing for us to stretch a given L2 network across a &ldquo;limitless&rdquo; number of racks, so we can mix and match customer nodes anywhere within the datacenter:</p>
<p><picture>
<source srcset=images/DC-Network-Scale-Out-3-Racks.avif type=image/avif>
<source srcset=images/DC-Network-Scale-Out-3-Racks.webp type=image/webp>
<img src=images/DC-Network-Scale-Out-3-Racks.png alt="DC Network multiple racks" loading=lazy decoding=async>
</picture></p>
<h5 id=technologyshowdown>#TechnologyShowdown<a hidden class=anchor aria-hidden=true href=#technologyshowdown>#</a></h5>
<p>So we want a L2 P2MP tech, to start off with eVPN - pioneered by Juniper, uses MP-BGP for control plane traffic as well as MAC and IP locality/distribution for an overlay technology (typically MPLS, PBB, VXLAN) - there are also multiple IETF RFC drafts for this standard, however the limited vendor support (Cisco and Juniper at the time) as well as lack of DC-rack class switches that these features are available on killed this tech off for the requirement.</p>
<p>VXLAN is an L2 encapsulation technology that will route packets over a standard L3 core network using UDP (with a larger MTU to allow for encap - typically 1600 bytes). VXLAN, has an official <a href=https://tools.ietf.org/html/rfc7348>IETF RFC</a> and has been implemented by multiple vendors (VMware, Arista, Cisco, Cumulus on switches with T2/T2+ chipsets, with many more coming like Mellanox and Dell) and very much seems to be the dominant choice for DC networking and such, was the logical choice.</p>
<p>It&rsquo;s worth noting that VXLAN doesn&rsquo;t have a discrete control plane - rather it can use an external controller or flood + learn.</p>
<p>Some networking vendors will only provide VXLAN tunnels if you have an external SDN-style controller, like Big Switch Networks, Dell and Cumulus. Generally this is not a problem when you have a single tenant infrastructure, you could use NSX-MH, BSN or an array of other controllers to provide intelligence about MAC locality and physical/host based VTEP endpoints.</p>
<p>This is not the case in a shared multi-tenant network because different vSphere environments means multiple integration points for MAC awareness and tunnel endpoints for any SDN controller. This feature was not provided by any networking vendor at the time in a <em>commercially and operationally viable</em> form.</p>
<p>So we had found another requirement, we couldn&rsquo;t use a centralised controller at least none in their current forms but still needed P2MP.</p>
<p>Cumulus was ruled out at this stage due to a VXLAN tunnel down behaviour on <a href=https://docs.cumulusnetworks.com/display/DOCS/LNV+VXLAN+Active-Active+Mode>loss of a single ToR switch when using MLAG</a>. This was apparently to stop traffic blackholing, being linux based, it is tricky I&rsquo;m told to view status of individual links within a bond reliably.</p>
<p>Dell was also ruled out as while the DNOS (Force 10) switches at the time had a <code>feature vxlan</code> they didn&rsquo;t allow for tunnels to be created via CLI, only controller based i.e. NSX - however, we have been told by our rep that this is no longer the case in DNOS 9.11 and arbitrary tunnels are now supported.</p>
<p>So that really only left Cisco and Arista - at the time Cisco only supported VXLAN on the 7k and 9k series switches, which didn&rsquo;t lend themselves to Spine and Leaf (now of course they have the Nexus 5600) and the cost was prohibitive as well as some multicast routing performance challenges ruled out Cisco.</p>
<p>Thus, we arrived at Arista who allow for all of the above (they support CLI based flood + learn for MAC addresses and BUM traffic suppression) and have a good external controller story should we choose to move that direction in future - I&rsquo;ve also been informed by our SE they now support L2 and L3 eVPN as a control plane for VXLAN.</p>
<p>The switches chosen were <code>48x 10GbE, 6x 40GbE</code> for the leaf nodes and <code>32x 40GbE</code> for the spine - I will get into link scaling in another article as stated above.</p>
<h4 id=providing-an-l3-core>Providing an L3 core<a hidden class=anchor aria-hidden=true href=#providing-an-l3-core>#</a></h4>
<p>We had our chosen overlay tech and vendor, what about the L3 core?</p>
<p>Typically in a spine and leaf you run a dynamic routing protocol like OSPF or BGP to distribute routes for all node interfaces to each other (VTEPs, loopbacks and P2P links for the spine/leaf fabric).</p>
<p>In this case, it was designed such that there was an AS per rack as well as a spine AS that all rack ASes peered with. This was chosen over a single AS for all leafs and spine as you can have instances in which traffic is dropped when a particular combination of links have an outage due to the default behaviour of BGP to prevent routing loops.</p>
<p>This can be overcome with <code>allowas-in</code> but it is more standard and safer to simply use a different ASN for each rack.</p>
<p>Like most things this is best described with a diagram or two, below you can see two ASNs, one for all leafs and one for the spine - the combination of link outages below would result in the traffic being unroutable due to BGP&rsquo;s built-in loop prevention methods:</p>
<p><picture>
<source srcset=images/DC-Network-BGP-AS-Leaf-Spine.avif type=image/avif>
<source srcset=images/DC-Network-BGP-AS-Leaf-Spine.webp type=image/webp>
<img src=images/DC-Network-BGP-AS-Leaf-Spine.png alt="BGP Network with single ASN for Leafs and Spine" loading=lazy decoding=async>
</picture></p>
<p>However, if we operate the network with an ASN per rack and an ASN for the spine we can see that the traffic can still be routed as there is no problem with the advertisement containing the same ASN as the one it is being advertised to:</p>
<p><picture>
<source srcset=images/DC-Network-BGP-AS-Per-Leaf.avif type=image/avif>
<source srcset=images/DC-Network-BGP-AS-Per-Leaf.webp type=image/webp>
<img src=images/DC-Network-BGP-AS-Per-Leaf.png alt="BGP Network with ASN per Leaf and Spine" loading=lazy decoding=async>
</picture></p>
<p><code>iBGP</code> was used to distribute the loopback and P2P interfaces to the other node at ToR as well provide redundancy should a leaf lose both uplinks to the spine and <code>eBGP</code> was used for the spine to distribute the routes learned from rack ASes to all other peered rack ASes - This provided VTEP visibility for all racks to each other as well as multiple routes to each destination which were then used for load distribution via ECMP.</p>
<p>The VTEP awareness across racks allowed for the creation of VLAN to VNI mappings that could traverse the spine.</p>
<p>It&rsquo;s a given that to improve link utilisation you want a decent hashing algorithm for distribution of traffic, ECMP on Trident2 chipset based switches is by default 5-tuple (<code>src + dest IP</code>, <code>protocol</code>, <code>src + dest port</code>) - you will however need to enable explicitly multi-path BGP with:</p>
<pre><code>maximum-paths [paths] ecmp [max ecmp paths per route to store in table]
</code></pre>
<h4 id=routing>Routing<a hidden class=anchor aria-hidden=true href=#routing>#</a></h4>
<p>So now we have an L3 core, we have L2 adjacency across racks - what about routing?</p>
<p>There is an interesting constraint with the Trident2 chipset - <a href=http://blog.ipspace.net/2014/06/trident-2-chipset-and-nexus-9500.html>you can&rsquo;t route between VLANs that exist on a VNI segment</a> because it would require recirculation back into the chipset after decapsulation (how Arista achieves this with the T2) or a separate chipset specifically to route between VNI segments (Cisco Nexus).</p>
<p>This was actually quite easy to solve - VLANs are stretched up to a pair of routers that come off the edge-leaf and provide all inter-VLAN routing and N/S traffic. Almost all of our customer traffic is E/W within the same VLAN and the traffic that was inter-VLAN is typically between DMZ/LAN and done on-host by a virtual firewall - anything else would traverse the links to the edge-leaf rack.</p>
<p><picture>
<source srcset=images/DC-BGP-Network-NS-Routing.avif type=image/avif>
<source srcset=images/DC-BGP-Network-NS-Routing.webp type=image/webp>
<img src=images/DC-BGP-Network-NS-Routing.png alt="Datacenter Networking N/S Routing" loading=lazy decoding=async>
</picture></p>
<p>If a customer wished to use NSX however then routing could be done on the DLR within the hosts and save on traffic hairpinning as well as provide the value-added services from NSX.</p>
<p>This can also be achieved through the use of anycast gateway with VRFs on Arista switching where routing decisions are made at a ToR level, keeping the traffic within the rack so inter-VLAN routing does not have to traverse the spine or go to a centralised routing point as above. This has some obvious benefits, there are operational overheads involved here as well and at the time was not available from our chosen vendor that met all other requirements so we settled for the centralised routing option.</p>
<p>There is an excellent article on routing between VXLAN segments with MLAG and anycast gateway by <a href=https://eos.arista.com/vxlan-routing-with-mlag/>Arista&rsquo;s technical team here</a>. I will include one diagram from the article however:</p>
<p><picture>
<source srcset=images/AristavVTEPAnycast.avif type=image/avif>
<source srcset=images/AristavVTEPAnycast.webp type=image/webp>
<img src=images/AristavVTEPAnycast.png alt="Arista vVTEP and Anycast Gateway" loading=lazy decoding=async>
</picture></p>
<p>This shows the SVIs at the top of rack with the same IP, providing local routing decisions (as well as remote routing, done on the source ToR switch then sent over VXLAN) and vVTEPs for ARP suppression as well as broadcasts in large topologies. The article above is incredible and I highly recommend you read it if you want a good, in depth look at the exact packet flow in an environment like this.</p>
<h2 id=wrapping-up>Wrapping Up<a hidden class=anchor aria-hidden=true href=#wrapping-up>#</a></h2>
<p>So, after all that - you can see there is a lot to learn when it comes to DC networking, especially ones at scale with L3 involved, but that is not to say they are hard to maintain or operate.</p>
<p>Keep an eye out for articles in the near future on the maths behind why the particular switches were chosen and eventually ESXi networking config for VSAN over the encapsulated physical network.</p>
<p>Big thanks to <a href=https://twitter.com/TefTech_EN>Novosco (now Telefonica Tech UK)</a> for allowing me to publish this article in as much detail as I have and for giving me the opportunity to architect such a solution, I couldn&rsquo;t have done it without the help and input of the rest of the Hosted Platforms team as well as the broader Novosco team!</p>
<p>Why not follow <a href=https://twitter.com/mylesagray>@mylesagray on Twitter</a> for more like this!</p>
</div>
<footer class=post-footer>
<section class="section post-tags">
<div class=content>
<h2>Tagged with</h2>
</div>
<ul class=post-tags>
<li><a href=https://blah.cloud/tags/architecture/>architecture</a></li>
<li><a href=https://blah.cloud/tags/datacenter/>datacenter</a></li>
<li><a href=https://blah.cloud/tags/l2-over-l3/>l2 over l3</a></li>
<li><a href=https://blah.cloud/tags/networking/>networking</a></li>
<li><a href=https://blah.cloud/tags/vxlan/>vxlan</a></li>
</ul>
</section>
<nav class=paginav>
<a class=prev href=https://blah.cloud/virtualisation/migrating-vcsa-embedded-psc-external-psc/>
<span class=title>« Prev Page</span>
<br>
<span>Migrating from VCSA embedded PSC to external PSC</span>
</a>
<a class=next href=https://blah.cloud/personal/vcix6-nv-exam-experience/>
<span class=title>Next Page »</span>
<br>
<span>My VCIX6-NV exam experience</span>
</a>
</nav>
<section class="section related-links">
<div class="columns is-centered">
<div class="column max-800px">
<div class=content>
<h2>Related content</h2>
</div>
<div class="columns related-links-columns">
<div class="column is-one-third">
<div class=card>
<div class=card-image>
<figure class="image is-3by2">
<a href=/infrastructure/designing-networking-platform-iaas-multi-tenancy/>
<picture>
<source srcset=/infrastructure/designing-networking-platform-iaas-multi-tenancy/images/image-1-2.avif type=image/avif>
<source srcset=/infrastructure/designing-networking-platform-iaas-multi-tenancy/images/image-1-2.webp type=image/webp>
<img src=/infrastructure/designing-networking-platform-iaas-multi-tenancy/images/image-1-2_hu5ee588b8a7aca17eb2c43b9d8832010f_66055_240x0_resize_box_3.png alt="High level network architecture for a multi-tenant network" loading=lazy decoding=async>
</picture>
</a>
</figure>
</div>
<div class=card-content>
<a class="title is-5" href=https://blah.cloud/infrastructure/designing-networking-platform-iaas-multi-tenancy/>Designing a networking platform for IaaS multi-tenancy</a>
</div>
</div>
</div>
<div class="column is-one-third">
<div class=card>
<div class=card-image>
<figure class="image is-3by2">
<a href=/infrastructure/multi-tenant-network-challenges/>
<picture>
<source srcset=/infrastructure/multi-tenant-network-challenges/images/Traditional-Process-Flow.avif type=image/avif>
<source srcset=/infrastructure/multi-tenant-network-challenges/images/Traditional-Process-Flow.webp type=image/webp>
<img src=/infrastructure/multi-tenant-network-challenges/images/Traditional-Process-Flow_hub2816e950b5d448800cb97ba9ca36402_27093_240x0_resize_box_3.png alt="ITIL process flow" loading=lazy decoding=async>
</picture>
</a>
</figure>
</div>
<div class=card-content>
<a class="title is-5" href=https://blah.cloud/infrastructure/multi-tenant-network-challenges/>Multi-tenant network challenges</a>
</div>
</div>
</div>
<div class="column is-one-third">
<div class=card>
<div class=card-image>
<figure class="image is-3by2">
<a href=/networks/implementing-multi-tenant-networking-platform-nsx/>
<picture>
<source srcset=/networks/implementing-multi-tenant-networking-platform-nsx/images/Screen-Shot-2017-03-21-at-21.29.14.avif type=image/avif>
<source srcset=/networks/implementing-multi-tenant-networking-platform-nsx/images/Screen-Shot-2017-03-21-at-21.29.14.webp type=image/webp>
<img src=/networks/implementing-multi-tenant-networking-platform-nsx/images/Screen-Shot-2017-03-21-at-21.29.14_hue58c71b348ea89de6b42502ea57e817b_65292_240x0_resize_box_3.png alt="OSPF discovered routes in routing table" loading=lazy decoding=async>
</picture>
</a>
</figure>
</div>
<div class=card-content>
<a class="title is-5" href=https://blah.cloud/networks/implementing-multi-tenant-networking-platform-nsx/>Implementing a multi-tenant networking platform with NSX</a>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section class="section share-icons">
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Designing a modern multi-tenant DC network on twitter" href="https://twitter.com/intent/tweet/?text=Designing%20a%20modern%20multi-tenant%20DC%20network&url=https%3a%2f%2fblah.cloud%2finfrastructure%2fdesigning-modern-private-cloud-network%2f&hashtags=architecture%2cdatacenter%2cl2overl3%2cnetworking%2cvxlan"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Designing a modern multi-tenant DC network on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblah.cloud%2finfrastructure%2fdesigning-modern-private-cloud-network%2f&title=Designing%20a%20modern%20multi-tenant%20DC%20network"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Designing a modern multi-tenant DC network on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblah.cloud%2finfrastructure%2fdesigning-modern-private-cloud-network%2f&title=Designing%20a%20modern%20multi-tenant%20DC%20network&summary=Designing%20a%20modern%20multi-tenant%20DC%20network&source=https%3a%2f%2fblah.cloud%2finfrastructure%2fdesigning-modern-private-cloud-network%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
</div>
</section>
</footer>
<script src=https://utteranc.es/client.js repo=mylesagray/blog-comments issue-term=title theme=preferred-color-scheme crossorigin=anonymous async></script>
</article>
<aside class="hidden lg:block tableOfContentContainer" id=tableOfContentContainer>
<nav id=TableOfContents>
<ul>
<li><a href=#requirement>Requirement</a></li>
<li><a href=#initial-thoughts>Initial Thoughts</a></li>
<li><a href=#engineering>Engineering</a>
<ul>
<li><a href=#the-l2-problem>The L2 Problem</a></li>
<li><a href=#solving-the-l2-problem-with-l3>Solving the L2 problem with L3</a></li>
</ul>
</li>
<li><a href=#wrapping-up>Wrapping Up</a></li>
</ul>
</nav>
</aside>
</div>
</main>
</div>
<footer class=footer>
<span>&copy; 2021 <a href=https://blah.cloud/>Blah, Cloud</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/JPbaU rel=noopener target=_blank>BurgerMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>