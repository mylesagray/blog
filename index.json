[{"content":" As such, it is now gone. See actual good content here. plausible(\"tweet\", { props: { path: document.referrer.replace(/^[^:]+:\\/\\/[^/]+/, '').replace(/#.*/, '') } }); ","permalink":"https://blah.cloud/tweet/","summary":" As such, it is now gone. See actual good content here. plausible(\"tweet\", { props: { path: document.referrer.replace(/^[^:]+:\\/\\/[^/]+/, '').replace(/#.*/, '') } }); ","title":"This \"blog\", should have been a Tweet."},{"content":"Content Highlights Talks  KubeCon North America 2021 - Using GPUs with K8s on VMware VMworld 2021 - The Future of VM Provisioning is Kubernetes  Repos  ANPR Knative - Number Plate Recognition on Knative ArgoCD and K8s bootstrap on ARM Auto-Scaling Machine Learning App on K8s  Publications  Introducing Virtual Machine Provisioning, via Kubernetes Introducing Cloud Native Storage for vSphere  Videos  vSphere with Tanzu - VM Service Feature Deep Dive Cloud Native Runtimes for VMware Tanzu with TriggerMesh Enables an Event-driven Machine Learning App  Podcasts  Introducing VM Service A Closer Look at vSphere with Tanzu  All Content Talks  KubeCon North America 2021 - Using GPUs with K8s on VMware VMworld 2021 - The Future of VM Provisioning is Kubernetes VMware Kubernes User Group Meetings (Co-Chair) - Various Topics KubeCon Europe 2021 - What\u0026rsquo;s New for K8s User on VMWare CNCF Virtual China Summit 2020 - Out-of-tree Cloud Provider and CSI for VMware KubeCon North America 2020 - Best Practises for Running K8s on VMware VMWorld 2020 - Technical Deep Dive on Cloud Native Storage for vSphere KubeCon Europe 2020 - Best Practises for Running K8s on VMware VMworld 2019 EU - vSAN: End-to-End Demos of the Latest vSAN Operational Enhancements VMWorld 2019 EU - Technical Deep Dive on Cloud Native Storage 1.0 VMWorld 2019 US - Technical Deep Dive on Cloud Native Storage for vSphere VMworld 2019 US - Architecting VMware Enterprise PKS on HCI Powered by vSAN VMworld 2019 US - The Definitive Guide to vSphere Storage for Kubernetes VMWorld 2018 EU - NSX and Generic Network Overlays with HCI: Everything You Need to Know VMWorld 2018 US - NSX and Generic Network Overlays with HCI: Everything You Need to Know VMWorld 2018 US - New Ways to Use vRealize Operations and Log Insight for vSAN Environments  Repos  ANPR Knative - Number Plate Recognition on Knative TensorFlow Interence Serving with Docker and S3 TensorFlow ANPR - Model for Number Plate Recognition Cloud Native Runtimes Workshop  Live Workshop   ArgoCD and K8s bootstrap on ARM Tanzu Cluster GitOps Auto-Scaling Machine Learning App on K8s Blog Blog Comments powered by GitHub Issues vSphere with Tanzu Quick Start VM Service Getting Started Guide VMware vSphere CPI and CSI Helm Charts CNA Ninja Installing the vSphere CSI on OpenShift 4.x K8s Operator for VM Provisioning Homebridge Plugin for BlueAir Air Conditioners API for Oil Tank Level Sensing  Publications  Introducing Virtual Machine Provisioning, via Kubernetes Using ReadWriteMany Volumes on TKG Clusters Keeping up with K8s vSphere with Tanzu - Private Registry Support Quick Look: Namespace Self-Service in vSphere with Tanzu Introduction to vSAN Data Persistence Platform Introducing Cloud Native Storage for vSphere Cloud Native Storage Integration for vSphere with Kubernetes Cloud Native Storage and vSAN File Services Integration VMware vSAN for Google Cloud\u0026rsquo;s Anthos GKE On-Prem Why Your Storage System needs Kubernetes Integration Can I use vSAN for both VMs and Containers? How is SPBM different to Tag-Based Placement? vSAN 6.7 - Introducing WSFC support on vSAN Using Webhooks and vRLI to Integrate vSAN Alerts with Slack Migrating to vSAN from Traditional Storage  Videos  vSphere with Tanzu - VM Service Feature Deep Dive Cloud Native Runtimes for VMware Tanzu with TriggerMesh Enables an Event-driven Machine Learning App Getting Started with Cloud Native Runtimes for VMware Tanzu Overview of Cloud Native Runtimes for VMware Tanzu vSphere with Tanzu - Namespace Self-Service Introduction and Demo of vSAN Data Persistence Platform vSAN Data Persistence Platform (DPp) - Maintenance and Failures Cloud Native Storage and vSAN File services Integration Feature in 5: Cloud Native Storage in vSAN 7 Feature in 5: Cloud Native Storage on vSAN StorageMinute: Cloud Native Storage (CNS)] Overview of Cloud Native Storage for vSphere 6.7 U3  Podcasts  Introducing VM Service A Closer Look at vSphere with Tanzu vSphere with Kubernetes vSAN File Services VMware and the Kubernetes Ecosystem Pivotal Container Service (PKS) What\u0026rsquo;s New in vSAN 6.7  ","permalink":"https://blah.cloud/works/","summary":"Content Highlights Talks  KubeCon North America 2021 - Using GPUs with K8s on VMware VMworld 2021 - The Future of VM Provisioning is Kubernetes  Repos  ANPR Knative - Number Plate Recognition on Knative ArgoCD and K8s bootstrap on ARM Auto-Scaling Machine Learning App on K8s  Publications  Introducing Virtual Machine Provisioning, via Kubernetes Introducing Cloud Native Storage for vSphere  Videos  vSphere with Tanzu - VM Service Feature Deep Dive Cloud Native Runtimes for VMware Tanzu with TriggerMesh Enables an Event-driven Machine Learning App  Podcasts  Introducing VM Service A Closer Look at vSphere with Tanzu  All Content Talks  KubeCon North America 2021 - Using GPUs with K8s on VMware VMworld 2021 - The Future of VM Provisioning is Kubernetes VMware Kubernes User Group Meetings (Co-Chair) - Various Topics KubeCon Europe 2021 - What\u0026rsquo;s New for K8s User on VMWare CNCF Virtual China Summit 2020 - Out-of-tree Cloud Provider and CSI for VMware KubeCon North America 2020 - Best Practises for Running K8s on VMware VMWorld 2020 - Technical Deep Dive on Cloud Native Storage for vSphere KubeCon Europe 2020 - Best Practises for Running K8s on VMware VMworld 2019 EU - vSAN: End-to-End Demos of the Latest vSAN Operational Enhancements VMWorld 2019 EU - Technical Deep Dive on Cloud Native Storage 1.","title":"Works"},{"content":"Introduction If you want to learn about the basics and key concepts of ClusterAPI, then check out my post on the Alpha back in June here - it covers the high level concepts and troubleshooting of ClusterAPI, as well as what it offers to you as a user who wants to set up Kubernetes.\nThis blog is a look at what has changed and how you can use ClusterAPI to deploy K8s clusters on vSphere that use CNS and the CSI plugin for storage, that was introduced as part of vSphere 6.7 U3. If you want a video overview of CNS and CSI, check out my YouTube video here.\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   git - brew install git  https://git-scm.com   go - brew install go  https://golang.org   govc - brew tap govmomi/tap/govc \u0026amp;\u0026amp; brew install govmomi/tap/govc  https://github.com/vmware/govmomi/tree/master/govc   kubectl - brew install kubernetes-cli  https://kubernetes.io/docs/tasks/tools/install-kubectl/   kind (Kubernetes-in-Docker) - No brew installer yet  https://github.com/kubernetes-sigs/kind   clusterctl  https://github.com/kubernetes-sigs/cluster-api/releases    Clusterctl installation clusterctl is built currently as part of ClusterAPI upstream, so can be downloaded from there:\ncurl -Lo ./clusterctl-darwin-amd64 https://github.com/kubernetes-sigs/cluster-api/releases/download/v0.2.4/clusterctl-darwin-amd64 chmod +x ./clusterctl-darwin-amd64 mv clusterctl-darwin-amd64 /usr/local/bin/clusterctl Kind installation kind hasn\u0026rsquo;t been bundled into brew, yet - so we need to install it the old-fashioned way (this is for macOS, as an example):\ncurl -Lo ./kind-darwin-amd64 https://github.com/kubernetes-sigs/kind/releases/download/v0.5.1/kind-darwin-amd64 chmod +x ./kind-darwin-amd64 mv ./kind-darwin-amd64 /usr/local/bin/kind Environment Setup The first thing we need is to ensure your vSphere environment is on 6.7 U3, CSI depends on the CNS API in vCenter, which is only present in 6.7 U3 and higher.\nPull down the OS image The next thing we need to do is pull down the guest OS image that will be deployed to build our K8s cluster. The CAPV team have built a number of images for K8s that you can choose from here.\nA point of note - if you are using 6.7U3 and wish to use CSI/CNS - then you need to ensure the VMHW (aka the VMX version) is at 13 or higher, this is done by default on images in the table on the above link that are on K8s v1.15.4 and above, so it is recommended you use one of those. If not, you can always upgrade the template post deploy as in the getting started guide.\nThe images come in two flavours currently, CentOS and Ubuntu, i\u0026rsquo;m downloading and using an Ubuntu 18.04 version with K8s v1.15.4:\nwget https://storage.googleapis.com/capv-images/release/v1.15.4/ubuntu-1804-kube-v1.15.4.ova -P ~/Downloads/ Set up vSphere with govc Fill in the appropriate environment variables for your vSphere environment to allow us to connect with govc (I put this in a file called govcvars.sh):\nexport GOVC_INSECURE=1 export GOVC_URL=vc01.satm.eng.vmware.com export GOVC_USERNAME=administrator@vsphere.local export GOVC_PASSWORD=P@ssw0rd export GOVC_DATASTORE=vsanDatastore export GOVC_NETWORK=\u0026#34;Cluster01-LAN-1-Routable\u0026#34; export GOVC_RESOURCE_POOL=\u0026#39;cluster01/Resources\u0026#39; export GOVC_DATACENTER=DC01 Import the env vars into our shell and connect to the vCenter with govc:\nsource govcvars.sh govc about Now that we\u0026rsquo;re connected to vCenter, let\u0026rsquo;s create some folders for our templates and cluster VMs to live in:\ngovc folder.create /$GOVC_DATACENTER/vm/Templates govc folder.create /$GOVC_DATACENTER/vm/Testing govc folder.create /$GOVC_DATACENTER/vm/Testing/K8s Customise and import the template VM There have been some changes to the OVA and OVF image building process, so if you followed along last time - this is slightly different now. Let\u0026rsquo;s extract the OVF spec from the template and change the Network to the name of your Port Group in vSphere and MarkAsTemplate to true as that\u0026rsquo;s what it\u0026rsquo;s going to end up as anyway - may as well do it on import!\nBecause we left the Name parameter as null, it will automatically be named ubuntu-1804-kube-v1.15.4) and we will use that name for the rest of this blog, so if you changed Name keep and eye out and change those as we go along.\ngovc import.spec ~/Downloads/ubuntu-1804-kube-v1.15.4.ova | python -m json.tool \u0026gt; ubuntu.json Edit the ubuntu.json to reflect your preferences:\n{ \u0026#34;DiskProvisioning\u0026#34;: \u0026#34;thin\u0026#34;, \u0026#34;IPAllocationPolicy\u0026#34;: \u0026#34;dhcpPolicy\u0026#34;, \u0026#34;IPProtocol\u0026#34;: \u0026#34;IPv4\u0026#34;, \u0026#34;NetworkMapping\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;nic0\u0026#34;, \u0026#34;Network\u0026#34;: \u0026#34;Cluster01-LAN-1-Routable\u0026#34; } ], \u0026#34;Annotation\u0026#34;: \u0026#34;Cluster API vSphere image - Ubuntu 18.04 and Kubernetes v1.15.4 - https://github.com/kubernetes-sigs/cluster-api-provider-vsphere/tree/master/build/images\u0026#34;, \u0026#34;MarkAsTemplate\u0026#34;: true, \u0026#34;PowerOn\u0026#34;: false, \u0026#34;InjectOvfEnv\u0026#34;: false, \u0026#34;WaitForIP\u0026#34;: false, \u0026#34;Name\u0026#34;: null } Let\u0026rsquo;s import the template we just downloaded into VC and the folder that we just created:\ngovc import.ova -folder /$GOVC_DATACENTER/vm/Templates -options ubuntu.json ~/Downloads/ubuntu-1804-kube-v1.15.4.ova Using ClusterAPI During the Alpha, we had to build clusterctl from source - no longer! If you followed the instructions above, you should have clusterctl available in your PATH so the following command should show you the help output:\nclusterctl -h Management Cluster Define your K8s Cluster Specification Creating cluster manifests has also changed and is much simpler now, all built into a Docker container for us to use.\nSo, let\u0026rsquo;s define where our cluster should be deployed, the name of it, K8s version, what SSH keys should be added to the guest\u0026rsquo;s trusted store and how many resources it should have by filling in the following environment variables (I put the below in a file called envvars.txt) - change the below to suit your environment:\ncat \u0026lt;\u0026lt;EOF \u0026gt;envvars.txt # K8s attributes export KUBERNETES_VERSION=\u0026#39;1.15.4\u0026#39; # vSphere attributes export VSPHERE_USERNAME=administrator@vsphere.local export VSPHERE_PASSWORD=P@ssw0rd export VSPHERE_SERVER=vc01.satm.eng.vmware.com # vSphere deployment configs export VSPHERE_DATACENTER=DC01 export VSPHERE_DATASTORE=vsanDatastore export VSPHERE_NETWORK=\u0026#34;Cluster01-LAN-1-Routable\u0026#34; export VSPHERE_RESOURCE_POOL=\u0026#34;cluster01/Resources/CAPV\u0026#34; export VSPHERE_FOLDER=\u0026#34;/DC01/vm/Testing/K8s\u0026#34; export VSPHERE_TEMPLATE=\u0026#34;ubuntu-1804-kube-v1.15.4\u0026#34; export VSPHERE_DISK_GIB=60 export VSPHERE_NUM_CPUS=\u0026#34;2\u0026#34; export VSPHERE_MEM_MIB=\u0026#34;2048\u0026#34; export SSH_AUTHORIZED_KEY=\u0026#39;ssh-rsa AAAAB3......w== myles@vmware.com\u0026#39; EOF Let\u0026rsquo;s create the manifest files that will define and create our cluster when we plug them into clusterctl:\ndocker run --rm \\  -v \u0026#34;$(pwd)\u0026#34;:/out \\  -v \u0026#34;$(pwd)/envvars.txt\u0026#34;:/envvars.txt:ro \\  gcr.io/cluster-api-provider-vsphere/release/manifests:latest \\  -c management-cluster This has placed the yaml files in a new directory ./out, so let\u0026rsquo;s use clusterctl to spin up a brand new management K8s cluster:\nCreate the Management Cluster The below command plugs in the manifest files created above in order to define our CAPV management cluster - you can change the yaml files from above to suit your liking, or change things in the command like the name of the cluster.\nclusterctl create cluster \\  --bootstrap-type kind \\  --bootstrap-flags name=capv-cluster-mgmt-01 \\  --cluster ./out/management-cluster/cluster.yaml \\  --machines ./out/management-cluster/controlplane.yaml \\  --provider-components ./out/management-cluster/provider-components.yaml \\  --addon-components ./out/management-cluster/addons.yaml \\  --kubeconfig-out ./out/management-cluster/kubeconfig This will take in the order of 5-10 minutes depending on your environment, it will create a kind single node K8s cluster on your local machine within a Docker container to act as a bootstrap.\nIt then creates another single-node K8s VM on your target vSphere environment with the same configuration, and deletes the kind cluster from your local machine, because it was only there to act as a bootstrap.\nAt this point, clusterctl will spit out the kubeconfig for your management cluster into the ./out/management-cluster/kubeconfig directory and you should be able to connect to your ClusterAPI \u0026ldquo;management\u0026rdquo; cluster:\nExport the newly downloaded kubeconfig file so it\u0026rsquo;s the default for kubectl to use:\nexport KUBECONFIG=./out/management-cluster/kubeconfig Check to see that the ClusterAPI items have been created (i.e. one cluster and one machine) for the management cluster.\nkubectl get clusters kubectl get machines Workload Clusters Define your Workload Cluster Specification With the ClusterAPI management cluster deployed, we can now use it, along with kubectl to create other K8s workload clusters!\nThe workload clusters use much the same process as the management cluster, however it makes sense to look into the yaml files generated in order to do things like define the number of worker nodes and such.\nThis time we\u0026rsquo;ll create some more manifests for our workload cluster (note the name workload-cluster-01):\ndocker run --rm \\  -v \u0026#34;$(pwd)\u0026#34;:/out \\  -v \u0026#34;$(pwd)/envvars.txt\u0026#34;:/envvars.txt:ro \\  gcr.io/cluster-api-provider-vsphere/release/manifests:latest \\  -c workload-cluster-01 If you check out the yaml files that were generated, in particular check out the machinedeployment.yaml file and adjust the number of replicas in the MachineDeployment section as below - this would give you 3 worker nodes in your cluster, instead of the default 1:\napiVersion:cluster.x-k8s.io/v1alpha2kind:MachineDeploymentmetadata:labels:cluster.x-k8s.io/cluster-name:workload-cluster-01name:workload-cluster-01-md-0namespace:defaultspec:replicas:3Create the Workload Cluster Let\u0026rsquo;s use the ClusterAPI management cluster to create our new workload cluster - we do this by passing in the yaml that was just generated to the management cluster, the ClusterAPI controller within the management cluster will then look at the specifications for each and create a new K8s cluster with the number of masters and workers as defined in controlplane.yaml and machinedeployment.yaml files respectively.\nFirst, let\u0026rsquo;s export KUBECONFIG so we are interacting with the management cluster:\nexport KUBECONFIG=./out/management-cluster/kubeconfig Next, let\u0026rsquo;s import the yaml files that define the workload cluster:\nkubectl apply -f ./out/workload-cluster-01/cluster.yaml -f ./out/workload-cluster-01/controlplane.yaml -f ./out/workload-cluster-01/machinedeployment.yaml If we watch ClusterAPI\u0026rsquo;s machines CRD we can see that it will have created a master and three workers if you changed the yaml to my change as above. This will take a few minutes, so it\u0026rsquo;s best to run this command and wait until all machines show Running.\nkubectl get machines -w Once all the machines are Running we will be able to pull down the kubeconfig for that cluster so we can deploy workloads on to it.\nConnecting to the Workload Cluster We\u0026rsquo;ve successfully provisioned our workload cluster, but how do we access and use it?\nGood question, when using ClusterAPI to spin up workload clusters, it needs to put the access credentials (i.e. the kubeconfig file) somewhere, so it puts them in a K8s secret, luckily they are very easy to retrieve and decode to your local machine.\nkubectl get secret workload-cluster-01-kubeconfig -o=jsonpath=\u0026#39;{.data.value}\u0026#39; | { base64 -d 2\u0026gt;/dev/null || base64 -D; } \u0026gt;./out/workload-cluster-01/kubeconfig Notice the workload-cluster-01-kubeconfig secret - this is what we want to connect to our workload cluster, it\u0026rsquo;s very easy to extract and pull this to your local machine. The command pulls the secret value which is base64 encoded in K8s - decodes it from base64 to text and creates a new kubeconfig file in the workload cluster\u0026rsquo;s directory on your laptop.\nLet\u0026rsquo;s apply the addons to our workload cluster (these are mainly just the networking overlay, Calico) - required to let pods talk to one-another - we will first change clusters by exporting KUBECONFIG once again:\nexport KUBECONFIG=./out/workload-cluster-01/kubeconfig kubectl apply -f ./out/workload-cluster-01/addons.yaml And watch as the pods get spun up, when it\u0026rsquo;s all working - everything should list as Running:.\nkubectl get pods -n kube-system -w Deploy some applications Now that the workload cluster is set up, we can deploy some apps to it - because ClusterAPI also takes care of the CSI setup, we can even deploy ones that use persistent storage!\nWe\u0026rsquo;re going to deploy use helm to set up an application called RocketChat on the cluster, which uses two persistent volumes, one for config and one for its MongoDB database.\nConfigure helm Be aware this installation style for helm (granting the tiller pod cluster-admin privileges) is a big security no-no and is just for ease of setup here. For more information on why this is bad, look here, and please don\u0026rsquo;t do this on a production cluster.\nIn this case, it is a throwaway cluster for me, so I will be using these permissions. First create the RBAC role and permissions for the helm service account in another new file called helm-rbac.yaml:\n$ cat \u0026lt;\u0026lt;EOF \u0026gt;helm-rbac.yamlapiVersion:v1kind:ServiceAccountmetadata:name:tillernamespace:kube-system---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:tillerroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:cluster-adminsubjects:- kind:ServiceAccountname:tillernamespace:kube-systemEOFApply the role to the cluster:\nkubectl apply -f helm-rbac.yaml Let\u0026rsquo;s install helm onto the cluster with the service account we provisioned:\nhelm init --service-account tiller Configure a StorageClass We\u0026rsquo;re going to delete the default StorageClass that gets deployed and instead, create our own that uses the CSI plugin that is installed by default with CAPV.\nkubectl delete sc --all Create a new StorageClass yaml that uses the CSI provisioner (and by extension, CNS) - note the provisioner line:\n$ cat \u0026lt;\u0026lt;EOF \u0026gt;sc.yamlkind:StorageClassapiVersion:storage.k8s.io/v1metadata:name:standardannotations:storageclass.kubernetes.io/is-default-class:\u0026#34;true\u0026#34;provisioner:csi.vsphere.vmware.comparameters:storagePolicyName:\u0026#34;vSAN Default Storage Policy\u0026#34;EOFThe above StorageClass uses the vSAN Default Storage Policy within vCenter, but you can change it to your own - the name of the SC in this case is standard and we\u0026rsquo;ll use it deploying a demo app next.\nkubectl apply -f sc.yaml Provision an application We\u0026rsquo;re now in a place where we can provision an application, we\u0026rsquo;re going to use helm to install RocketChat, as discussed above - RocketChat is basically an Open-Source Slack clone that you can run on-prem.\nThe below command tells helm to install RocketChat from the stable/rocketchat repository, give it a name, set the passwords for MongoDB and most critically - use the standard StorageClass that we just imported into the workload cluster to back the PersistentVolumes requested by RocketChat:\nhelm install stable/rocketchat --set persistence.StorageClass=standard,mongodb.mongodbPassword=password,mongodb.mongodbRootPassword=password Verify the volumes got provisioned (this will take a minute before it returns back the \u0026ldquo;Bound\u0026rdquo; status):\n$ kubectl get pv,pvc NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pvc-3c754fc9-f7bb-448f-8f2c-510fedc0cebc 8Gi RWO Delete Bound default/datadir-exacerbated-squirrel-mongodb-secondary-0 standard 19h persistentvolume/pvc-47ad5e4d-4cdd-4c14-9148-5e9a2321bb8e 8Gi RWO Delete Bound default/datadir-exacerbated-squirrel-mongodb-primary-0 standard 19h NAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE default persistentvolumeclaim/datadir-exacerbated-squirrel-mongodb-primary-0 Bound pvc-47ad5e4d-4cdd-4c14-9148-5e9a2321bb8e 8Gi RWO standard 19h default persistentvolumeclaim/datadir-exacerbated-squirrel-mongodb-secondary-0 Bound pvc-3c754fc9-f7bb-448f-8f2c-510fedc0cebc 8Gi RWO standard 19h And the pods for the application should be running:\n$ kubectl get po NAME READY STATUS RESTARTS AGE exacerbated-squirrel-mongodb-arbiter-0 1/1 Running 0 19h exacerbated-squirrel-mongodb-primary-0 1/1 Running 0 19h exacerbated-squirrel-mongodb-secondary-0 1/1 Running 0 19h exacerbated-squirrel-rocketchat-958b577d-v8vzp 1/1 Running 0 19h At this point, we can access the application by port-forwarding to the rocketchat-rocketchat-* pod from the output above (change this to suit your pod name):\nkubectl -port-forward exacerbated-squirrel-rocketchat-958b577d-v8vzp 8888:3000 Access the application on localhost:8888 in your web browser:\nopen http://localhost:8888  \nIn the new CNS UI within vSphere 6.7 U3 - we can see the volumes that have been deployed from this K8s cluster via the CSI plugin:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/kubernetes/clusterapi-for-vsphere-now-with-cns-support/","summary":"Introduction If you want to learn about the basics and key concepts of ClusterAPI, then check out my post on the Alpha back in June here - it covers the high level concepts and troubleshooting of ClusterAPI, as well as what it offers to you as a user who wants to set up Kubernetes.\nThis blog is a look at what has changed and how you can use ClusterAPI to deploy K8s clusters on vSphere that use CNS and the CSI plugin for storage, that was introduced as part of vSphere 6.","title":"ClusterAPI for vSphere, now with CNS support"},{"content":"Introduction We\u0026rsquo;ve covered off prepping and installing K8s on this blog a few different ways; with VM templates built manually, with cloud-init, and with ClusterAPI vSphere. Let\u0026rsquo;s say you\u0026rsquo;ve grown attached to some of the workloads you\u0026rsquo;re running on one of your clusters, naturally. It would be nice to backup and restore those should something go wrong - or even, as was my case, I deployed a distro of K8s on my Raspberry Pi cluster that I wasn\u0026rsquo;t wild about and wanted to move to another - how do you migrate those workloads?\nEnter Velero. Velero (formerly Heptio Ark) is a backup, restore and DR orchestration application for your K8s workloads. In this post i\u0026rsquo;d like to take you through the installation and use of Velero, as well as some test backup and restores so you can kick the tyres on your own clusters and maybe give the team some feedback!\nI\u0026rsquo;m assuming you have a K8s cluster up and running with a working storage system. I mean, otherwise you\u0026rsquo;d have nothing to back up. If not - check the blogs mentioned above to get one running.\nIf you just want to see it running - check out my VMWorld session and go to 19:30\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   git - brew install git  https://git-scm.com   helm - brew install kubernetes-helm  https://helm.sh   kubectl - brew install kubernetes-cli  https://kubernetes.io/docs/tasks/tools/install-kubectl/    Installation and Use Workflow To get Velero running on our cluster there are a few steps we need to run through, at a high level (explaination on these components in a bit):\n Download and install the Velero CLI to our local machine Install Minio on our cluster for use as a backup repo Install Velero on our cluster  Installation Velero CLI The Velero CLI isn\u0026rsquo;t strictly required but it handles a lot of the heavy lifting of creating Velero specific custom resources (CRDs) in K8s that you\u0026rsquo;d have to do manually otherwise, things like backup schedules and all that jazz.\nThe Velero CLI is pre-compiled and available for download on the Velero GitHub page, as stated before i\u0026rsquo;m running macOS so i\u0026rsquo;ll download and move the binary into my PATH (adjust this to suit your OS).\nwget https://github.com/vmware-tanzu/velero/releases/download/v1.1.0/velero-v1.1.0-darwin-amd64.tar.gz tar -zxvf velero-v1.1.0-darwin-amd64.tar.gz mv velero-v1.1.0-darwin-amd64/velero /usr/local/bin/. As long as /usr/local/bin is in your PATH, you\u0026rsquo;ll be able to now run the CLI:\n$ velero version Client: Version: v1.1.0 Git commit: a357f21aec6b39a8244dd23e469cc4519f1fe608 \u0026lt;error getting server version: the server could not find the requested resource (post serverstatusrequests.velero.io)\u0026gt; The error is expected as we haven\u0026rsquo;t yet installed Velero into our cluster - but it shows that the CLI is working. An important thing to note is that when using the Velero CLI, it uses the currently active K8s cluster that\u0026rsquo;s in your terminal session.\nInstalling Minio Velero uses S3 API-compatible object storage as its backup location, that means to create a backup we need something that exposes and S3 API. Minio is a small, easy to deploy S3 object store you can run on-prem.\nFor this example, we\u0026rsquo;re going to run Minio on our K8s cluster, in production you\u0026rsquo;d want your S3 store somewhere else, for reasons that should be obvious.\nTo install Minio we\u0026rsquo;re going to use helm which is a package manager for K8s - this simplifies the installation down to creating a yaml file for the configuration.\nLet\u0026rsquo;s create the yaml file for the setup of Minio with helm (a full list of variables can be found on the chart page in the repo):\n$ cat minio.yamlimage:tag:latestaccessKey:\u0026#34;minio\u0026#34;secretKey:\u0026#34;minio123\u0026#34;service:type:LoadBalancerdefaultBucket:enabled:truename:veleropersistence:size:50GStepping through this, it will deploy the latest version of Minio available, set the username and password to minio and minio123 respectively, expose the service using a LoadBalancer (consequently, you\u0026rsquo;ll need a LoadBalancer of some kind in your cluster - I recommend MetalLB for labs). Next up, we tell it to automatically create a bucket called velero and to persist the data in a 50GB volume.\nIdeally, instead of using Service Type LoadBalancer - you\u0026rsquo;d use an Ingress Controller like Traefik or NginX, but that\u0026rsquo;s the subject for another blog post - an LB will do for a proof of concept.\nI\u0026rsquo;m assuming you have the file saved as minio.yaml - so let\u0026rsquo;s now use helm to deploy this to our cluster.\nhelm install stable/minio --name minio --namespace infra -f minio.yaml This installs Minio to your cluster, in a namespace called infra and the helm deployment is given a name of minio (otherwise you\u0026rsquo;ll get a randomly allocated name).\nIf we run the following, we\u0026rsquo;ll get the IP and Port that Minio will be accessible on outside the cluster - in my case the IP is 10.198.26.3 and is accessible on port 9000:\n$ kubectl get service minio -n infra NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE minio LoadBalancer 10.110.94.210 10.198.26.3 9000:32549/TCP 127m If you substitute your own details into the below and login using minio and minio123 you\u0026rsquo;ll see the Minio UI with the Velero bucket present.\nopen http://10.198.26.3:9000 Ta-da, an S3 compliant object store, running on K8s.\n \nInstalling Velero Velero can be installed either via a helm chart or via the Velero CLI, my preferred method is to use the helm chart as it means I can store the configuration in a yaml file and deploy it repeatably without having to memorise commands.\nIf you want to deploy via the CLI, see the Velero documentation, we are going to use helm here.\nAgain, as with the Minio chart, the first step is to create the configuration yaml file:\n$ cat velero.yamlimage:tag:v1.1.0configuration:provider:awsbackupStorageLocation:name:awsbucket:veleroconfig:region:minios3ForcePathStyle:truepublicUrl:http://10.198.26.3:9000s3Url:http://minio.infra.svc:9000credentials:useSecret:truesecretContents:cloud:|[default] aws_access_key_id = minio aws_secret_access_key = minio123snapshotsEnabled:falseconfigMaps:restic-restore-action-config:labels:velero.io/plugin-config:\u0026#34;\u0026#34;velero.io/restic:RestoreItemActiondata:image:gcr.io/heptio-images/velero-restic-restore-helper:v1.1.0deployRestic:trueSo, it may look a little strange with the provider type aws and such, but that is simply there to allow us to use the S3 backup target - notice that we just use the IP address and port of the Minio service we deployed in the previous step as the URL to send the backups to.\nOne thing i\u0026rsquo;d like to call out is the difference between publicUrl and s3Url - publicUrl is what the Velero CLI will communicate with when it needs to get things like logs and such, the s3Url is what the Velero in-cluster process sends the data and logs to. In this case s3Url is not publically accessible, it uses a Kubernetes in-cluster DNS record (minio.infra.svc:9000) - this says, send the data to service minio in namespace infra and of type service on port 9000.\nBecause the s3Url is only resolvable within the K8s cluster, we must also specify the publicUrl to allow the CLI to also interface with the assets in that object store.\nThe last line may be something you\u0026rsquo;re wondering about - deployRestic tells Velero to deploy the restic data mover to pull bits off the disk from inside the cluster, rather than relying on native snapshotting and diff capabilities and is required for vSphere installations.\nWith all that said, once you\u0026rsquo;ve adjusted the above to suit your environment (likely just publicUrl and s3Url) you can deploy the helm chart.\nhelm install stable/velero --name velero --namespace velero -f velero.yaml With Velero deployed to our cluster, we can now get to creating some backup schedules and test how it all works.\nDeploying a Sample Application As of Velero v1.1.0, CSI volumes are supported, meaning we can backup the contents of PVs on kubernetes clusters running CSI plugins, as well as the manifests that make up that app.\nTo test this out, let\u0026rsquo;s deploy an app - a Slack clone i\u0026rsquo;m awfully fond of called RocketChat - as usual, we\u0026rsquo;ll create the config yaml file first:\n$ cat rocketchat.yamlpersistence:enabled:trueservice:type:LoadBalancermongodb:mongodbPassword:passwordmongodbRootPassword:passwordThis will deploy RocketChat (which uses MongoDB as a database) to our cluster and expose it using another LoadBalancer IP - again, ideally this would be done using an Ingress Controller instead, but for simplicity - we\u0026rsquo;ll do it this way.\nhelm install stable/rocketchat --name rocketchat --namespace rocketchat -f rocketchat.yaml If you watch the pods as this comes up, you should see the arbiter, the primary and then the secondary MongoDB nodes come up, following that - the RocketChat app itself will come up and at that point, will be accessible within the browser:\nkubectl get pod -n rocketchat -w Once all the pods show Running and 1/1 - we can grab the LoadBalancer IP and port and access the app:\n$ kubectl get svc -n rocketchat NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE rocketchat-mongodb ClusterIP 10.102.96.222 \u0026lt;none\u0026gt; 27017/TCP 3m34s rocketchat-mongodb-headless ClusterIP None \u0026lt;none\u0026gt; 27017/TCP 3m34s rocketchat-rocketchat LoadBalancer 10.106.105.16 10.198.26.4 80:30904/TCP 3m34s So, to access this service, as with Minio - sub in your own IP into the following:\nopen http://10.198.26.4 Go through the motions of creating a user account with whatever name and password you like until you get to the main page:\n \nNavigate to the #general channel and upload something or type in some text - this will be the data we want to protect with Velero!\n \nNow, we can\u0026rsquo;t have that data going missing - i\u0026rsquo;m sure you\u0026rsquo;ll agree, so let\u0026rsquo;s back it up with Velero!\nBackup and Restore with Velero Now that we have an application, and data we want to protect - let\u0026rsquo;s tag the PersistentVolumes so Velero will back them up. First - we need to find out what the volumes are called:\n$ kubectl get pvc -n rocketchat NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE datadir-rocketchat-mongodb-primary-0 Bound pvc-dda3e972-e5fa-11e9-a30e-00505691513e 8Gi RWO space-efficient 23m datadir-rocketchat-mongodb-secondary-0 Bound pvc-ddb17d70-e5fa-11e9-a30e-00505691513e 8Gi RWO space-efficient 23m rocketchat-rocketchat Bound pvc-dd633f78-e5fa-11e9-a30e-00505691513e 8Gi RWO space-efficient 23m The first word in the name of each PVC, is the name of the volume - so datadir and rocketchat. Let\u0026rsquo;s tell Velero to backup those datadir volumes by tagging the pods.\n$ kubectl annotate pod -n rocketchat --selector=release=rocketchat,app=mongodb backup.velero.io/backup-volumes=datadir --overwrite pod/rocketchat-mongodb-arbiter-0 annotated pod/rocketchat-mongodb-primary-0 annotated pod/rocketchat-mongodb-secondary-0 annotated The above command looks for all pods in the rocketchat namespace with the tags release=rocketchat and app=mongodb and annotates them with a label backup.velero.io/backup-volumes=datadir - this tells Velero to backup the Persistent Volumes that are consumed with the name datadir.\nSet up a Velero Schedule Now that our app is set up to request Velero backups - let\u0026rsquo;s schedule some - in the below example, we are asking for a backup to be taken every hour and for them to be held for 24 hours each.\nvelero schedule create hourly --schedule=\u0026#34;@every 1h\u0026#34; --ttl 24h0m0s Let\u0026rsquo;s create another that runs daily and retains the backups for 7 days:\nvelero schedule create daily --schedule=\u0026#34;@every 24h\u0026#34; --ttl 168h0m0s If we query Velero, we can now see what schedules are set up:\n$ velero get schedules NAME STATUS CREATED SCHEDULE BACKUP TTL LAST BACKUP SELECTOR daily Enabled 2019-10-03 17:57:43 +0100 BST @every 24h 168h0m0s 23s ago \u0026lt;none\u0026gt; hourly Enabled 2019-10-03 17:56:20 +0100 BST @every 1h 24h0m0s 1m ago \u0026lt;none\u0026gt; Additionally, we can see they\u0026rsquo;ve already taken a backup each, we can query those backups with the following command:\n$ velero get backups NAME STATUS CREATED EXPIRES STORAGE LOCATION SELECTOR daily-20191003165757 Completed 2019-10-03 17:58:33 +0100 BST 6d default \u0026lt;none\u0026gt; hourly-20191003165634 Completed 2019-10-03 17:56:34 +0100 BST 23h default \u0026lt;none\u0026gt; If we wanted to take an ad-hoc backup that can be achieved through the following (in this case, we will only backup the rocketchat namespace):\n$ velero backup create before-disaster --include-namespaces rocketchat Backup request \u0026#34;before-disaster\u0026#34; submitted successfully. Run `velero backup describe before-disaster` or `velero backup logs before-disaster` for more details. As the command says - we can query progress with the following:\nvelero backup describe before-disaster --details Adding the --details option will show us the restic backup status of the persistent volumes at the very bottom:\nRestic Backups: Completed: rocketchat/rocketchat-mongodb-primary-0: datadir rocketchat/rocketchat-mongodb-secondary-0: datadir And now if we go to Minio, in the velero bucket you will see the backups and their contents (they are all encrypted on disk by default):\nopen http://10.198.26.3:9000/minio/velero/backups/before-disaster/  \nSimulating a disaster Now that we have a backup and some scheduled backups, let\u0026rsquo;s delete the rocketchat app - and all it\u0026rsquo;s data off disk and restore it using Velero.\nhelm delete --purge rocketchat This will delete the RocketChat app - but because MongoDB uses a StatefulSet, the data volumes will stick around - as you can see from the CNS UI:\n \nWe can delete these PVs by deleting the namespace too:\nkubectl delete ns rocketchat So, now all our data is truely gone - as evidenced by the CNS UI no longer showing any volumes for the rocketchat filter:\n \nRestoring with Velero Our app is dead, and the data is gone - so it\u0026rsquo;s time to restore it from one of the backups we took - i\u0026rsquo;ll use the ad-hoc one for ease of naming:\n$ velero restore create --from-backup before-disaster --include-namespaces rocketchat Restore request \u0026#34;before-disaster-20191003181320\u0026#34; submitted successfully. Run `velero restore describe before-disaster-20191003181320` or `velero restore logs before-disaster-20191003181320` for more details. Again - let\u0026rsquo;s monitor it with the command from above:\nvelero restore describe before-disaster-20191003181320 --details Once the output of the command shows completed and the Restic Restores at the bottom are done, like below, we can check on our app:\nName: before-disaster-20191003181320 Namespace: velero Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Phase: Completed Backup: before-disaster Namespaces: Included: rocketchat Excluded: \u0026lt;none\u0026gt; Resources: Included: * Excluded: nodes, events, events.events.k8s.io, backups.velero.io, restores.velero.io, resticrepositories.velero.io Cluster-scoped: auto Namespace mappings: \u0026lt;none\u0026gt; Label selector: \u0026lt;none\u0026gt; Restore PVs: auto Restic Restores: Completed: rocketchat/rocketchat-mongodb-primary-0: datadir rocketchat/rocketchat-mongodb-secondary-0: datadir Let\u0026rsquo;s see if the pods are back up and running, and our PVCs are restored in our namespace:\n$ kubectl get po,pvc -n rocketchat NAME READY STATUS RESTARTS AGE pod/rocketchat-mongodb-arbiter-0 1/1 Running 0 3m5s pod/rocketchat-mongodb-primary-0 1/1 Running 0 3m5s pod/rocketchat-mongodb-secondary-0 1/1 Running 0 3m5s pod/rocketchat-rocketchat-7bdf95cb47-86q9t 1/1 Running 0 3m4s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/datadir-rocketchat-mongodb-primary-0 Bound pvc-1d90d0d7-e601-11e9-a30e-00505691513e 8Gi RWO space-efficient 3m5s persistentvolumeclaim/datadir-rocketchat-mongodb-secondary-0 Bound pvc-1d95abc7-e601-11e9-a30e-00505691513e 8Gi RWO space-efficient 3m5s persistentvolumeclaim/rocketchat-rocketchat Bound pvc-1d99ea27-e601-11e9-a30e-00505691513e 8Gi RWO space-efficient 3m5s In the CNS UI - we\u0026rsquo;ll see the volumes again present - this time with some extra velero labels against them:\n \nAnd our app should once be again accessible and our data safe:\nopen http://10.198.26.4  \nTroubleshooting A tip on troubleshooting Velero backups - make liberal use of the logs command:\nvelero restore logs before-disaster-20191003181320 This is where the publicUrl section from the very start matters - if you don\u0026rsquo;t have that populated, your logs won\u0026rsquo;t get displayed to you, so if you\u0026rsquo;re experiencing that, make sure you\u0026rsquo;ve defined that parameter.\nThe logs have a trove of information in them, so if Restic is having trouble pulling data from a volume or such, all that info is in there!\nThis brings us to the end of our look at Velero on vSphere - and in particular the integration with CSI. If you have feedback for the Velero team - please reach out on GitHub and file some issues, whether is enhancements, bugs - or if you just need help. Stay tuned for more K8s goodness in the near future!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/automation/using-velero-for-k8s-backup-and-restore-of-csi-volumes/","summary":"Introduction We\u0026rsquo;ve covered off prepping and installing K8s on this blog a few different ways; with VM templates built manually, with cloud-init, and with ClusterAPI vSphere. Let\u0026rsquo;s say you\u0026rsquo;ve grown attached to some of the workloads you\u0026rsquo;re running on one of your clusters, naturally. It would be nice to backup and restore those should something go wrong - or even, as was my case, I deployed a distro of K8s on my Raspberry Pi cluster that I wasn\u0026rsquo;t wild about and wanted to move to another - how do you migrate those workloads?","title":"Using Velero for K8s Backup and Restore of CSI Volumes"},{"content":"Introduction K8s lifecycle is something people are still struggling with, despite amazing tools out there like kubeadm which take care of the K8s setup itself, we are still lacking something fundamental - they day-0 setup.\nWho/what actually creates the VMs and installs the packages on them so we can get to the stage that we can use kubeadm?\nTypically it\u0026rsquo;s up to the user, and as such can vary wildly - so how can that experience be improved, and even better - totally automated and declarative.\nImagine entering a single command and regardless of your cloud provider - it would take care of VM setup, OS installation and K8s bootstrapping, cluster membership as well as cloud provider setup for storage provisioning.\nCouple that with the ability to expand and delete clusters through the same utility, well, that all sounds pretty compelling doesn\u0026rsquo;t it?\nN.B: Keep in mind this is an early alpha-stage prototype, the final experience will be different to that exhibited below\nThis as was the case with the cloud-init post, is a replacement for part 1 and part 2.\nClusterAPI (CAPI) Enter ClusterAPI, the tool that is going to answer all the above questions. To quote the page itself:\n The Cluster API is a Kubernetes project to bring declarative, Kubernetes-style APIs to cluster creation, configuration, and management.\n Before we get into it, CAPI is still experimental and subject to change but has made tremenduous progress recently with providers implementing CAPI for their own cloud platforms, today we\u0026rsquo;re going to look at ClusterAPI for vSphere (CAPV).\nManagement Clusters and Workload Clusters ClusterAPI makes the distinction between management and workload K8s clusters.\nmanagement clusters are used by you to create workload clusters - think of them as being the control plane for ClusterAPI - you send some yaml files to the management cluster and it will create a workload K8s cluster for you.\nworkload clusters are what they sound like - K8s clusters you run actual workloads on and are provisioned for you via the management cluster.\nWe are going to be deploying a management cluster first, then use it to deploy our workload cluster!\nClusterAPI vSphere (CAPV) ClusterAPI vSphere (CAPV) is a CAPI implementation for vSphere. What that means is - it uses the CAPI framework and translates it into things that vSphere can understand, essentially giving us all the goodness of the CAPI feature-set on vSphere.\nWhile we are here, the work that\u0026rsquo;s being done on CAPV is at a break-neck pace, I have the pleasure of asking quesitons of the team involved and reporting bugs, they are fantastic and stuff is usually fixed in \u0026lt;24 hours!\nSpecial thanks to Andrew Kutz and Andrew Sy Kim for their excellent work, helping me so much along the way and dealing with by bug reports :)\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   git - brew install git  https://git-scm.com   go - brew install go  https://golang.org   govc - brew tap govmomi/tap/govc \u0026amp;\u0026amp; brew install govmomi/tap/govc  https://github.com/vmware/govmomi/tree/master/govc   kubectl - brew install kubernetes-cli  https://kubernetes.io/docs/tasks/tools/install-kubectl/   kind (Kubernetes-in-Docker) - No brew installer yet  https://github.com/kubernetes-sigs/kind    Kind installation kind hasn\u0026rsquo;t been bundled into brew, yet - so we need to install it the old-fashioned way (this is for macOS, as an example):\ncurl -Lo ./kind-darwin-amd64 https://github.com/kubernetes-sigs/kind/releases/download/v0.3.0/kind-darwin-amd64 chmod +x ./kind-darwin-amd64 mv ./kind-darwin-amd64 /usr/local/bin/kind Environment Setup Now that we understand what ClusterAPI does, let\u0026rsquo;s jump into actually using CAPV to deploy a K8s cluster on vSphere!\nPull down the OS image CAPV image templates can be found here and come in two flavours currently, CentOS and Ubuntu, i\u0026rsquo;m downloading and using an Ubuntu 18.04 version with K8s v1.15.0:\nwget https://storage.googleapis.com/capv-images/release/v1.15.0/ubuntu-1804-kube-v1.15.0.ova -P ~/Downloads/ Set up vSphere with govc Fill in the appropriate environment variables for your vSphere environment to allow us to connect with govc (I put this in a file called govcvars.sh):\nexport GOVC_INSECURE=1 export GOVC_URL=vc01.satm.eng.vmware.com export GOVC_USERNAME=administrator@vsphere.local export GOVC_PASSWORD=P@ssw0rd export GOVC_DATASTORE=vsanDatastore export GOVC_NETWORK=\u0026#34;Cluster01-LAN-1-Routable\u0026#34; export GOVC_RESOURCE_POOL=\u0026#39;cluster01/Resources\u0026#39; export GOVC_DATACENTER=DC01 Import the env vars into our shell and connect to the vCenter with govc:\nsource govcvars.sh govc about Now that we\u0026rsquo;re connected to vCenter, let\u0026rsquo;s create some folders for our templates and cluster VMs to live in:\ngovc folder.create /$GOVC_DATACENTER/vm/Templates govc folder.create /$GOVC_DATACENTER/vm/Testing govc folder.create /$GOVC_DATACENTER/vm/Testing/K8s Customise and import the template VM Extract the OVF spec from the template and change the Name, Network and Annotation to your liking - i\u0026rsquo;ve also changed MarkAsTemplate to true as that\u0026rsquo;s what it\u0026rsquo;s going to end up as anyway - may as well do it on import!\nI\u0026rsquo;m going to assume you named it the same as mine (ubuntu-18.04-kube-1.15.0) for the rest of this blog, so if you haven\u0026rsquo;t keep and eye out and change those as we go along.\ngovc import.spec ~/Downloads/ubuntu-1804-kube-v1.15.0.ova | python -m json.tool \u0026gt; ubuntu.json Edit the ubuntu.json to reflect your preferences:\n{ \u0026#34;DiskProvisioning\u0026#34;: \u0026#34;thin\u0026#34;, \u0026#34;IPAllocationPolicy\u0026#34;: \u0026#34;dhcpPolicy\u0026#34;, \u0026#34;IPProtocol\u0026#34;: \u0026#34;IPv4\u0026#34;, \u0026#34;NetworkMapping\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;nic0\u0026#34;, \u0026#34;Network\u0026#34;: \u0026#34;Cluster01-LAN-1-Routable\u0026#34; } ], \u0026#34;Annotation\u0026#34;: \u0026#34;Cluster API vSphere image - Ubuntu 18.04 and Kubernetes - https://github.com/kubernetes-sigs/cluster-api-provider-vsphere/blob/master/docs/machine_images.md\u0026#34;, \u0026#34;MarkAsTemplate\u0026#34;: true, \u0026#34;PowerOn\u0026#34;: false, \u0026#34;InjectOvfEnv\u0026#34;: false, \u0026#34;WaitForIP\u0026#34;: false, \u0026#34;Name\u0026#34;: \u0026#34;ubuntu-18.04-kube-1.15.0\u0026#34; } Let\u0026rsquo;s import the template we just downloaded into VC and the folder that we just created:\ngovc import.ova -folder /$GOVC_DATACENTER/vm/Templates -options ubuntu.json ~/Downloads/ubuntu-1804-kube-v1.15.0.ova Using ClusterAPI Build clusterctl The command line interface that you use with ClusterAPI is called clusterctl, for now (early alpha, remember?) this needs to be built from the git repo, so let\u0026rsquo;s clone it down:\ngit clone git@github.com:kubernetes-sigs/cluster-api-provider-vsphere.git cd cluster-api-provider-vsphere git checkout tags/v0.3.0-beta.0 Build the clusterctl binary by running the following make command in the root folder of the cloned repository:\nGOOS=$(go env GOOS) make clusterctl-in-docker Temporarily add the file that was output to our shell PATH so we can use it:\nexport PATH=\u0026#34;$PATH:$(pwd)/bin\u0026#34; Check it\u0026rsquo;s working by seeing the help output:\nclusterctl -h Management Cluster Define your K8s Cluster Specification clusterctl is good to go - let\u0026rsquo;s define where our cluster should be deployed, the name of it, K8s version and how many resources it should have by filling in the following environment variables (I put the below in a file called mgmt-cluster-vars.sh) - change the below to suit your environment:\n# K8s attributes export CLUSTER_NAME=capv-mgmt-example export KUBERNETES_VERSION=1.15.0 # vSphere attributes export VSPHERE_USER=administrator@vsphere.local export VSPHERE_PASSWORD=P@ssw0rd export VSPHERE_SERVER=vc01.satm.eng.vmware.com # VM deployment options export VSPHERE_DATACENTER=DC01 export VSPHERE_DATASTORE=vsanDatastore export VSPHERE_NETWORK=\u0026#34;Cluster01-LAN-1-Routable\u0026#34; export VSPHERE_RESOURCE_POOL=\u0026#34;cluster01/Resources/CAPV\u0026#34; export VSPHERE_FOLDER=\u0026#34;/$(echo $VSPHERE_DATACENTER)/vm/Testing/K8s/$(echo $CLUSTER_NAME)\u0026#34; export VSPHERE_TEMPLATE=\u0026#34;ubuntu-18.04-kube-1.15.0\u0026#34; export VSPHERE_DISK_GIB=60 export VSPHERE_NUM_CPUS=\u0026#34;2\u0026#34; export VSPHERE_MEM_MIB=\u0026#34;2048\u0026#34; Import the variables into your shell session:\nsource mgmt-cluster-vars.sh Export your SSH public key so that when the VMs are created you\u0026rsquo;ll be able to SSH into them (should you need to debug anything):\nexport SSH_AUTHORIZED_KEY=\u0026#34;$(cat ~/.ssh/id_rsa.pub)\u0026#34; Create a folder for the VMs on vSphere for the management cluster:\ngovc folder.create $VSPHERE_FOLDER Generate the yaml files required for ClusterAPI to spin up our management K8s cluster:\n$ make prod-yaml CAPV_MANAGER_IMAGE=gcr.io/cnx-cluster-api/vsphere-cluster-api-provider:0.3.0-beta.0 hack/generate-yaml.sh done generating ./out/capv-mgmt-example/addons.yaml done generating ./config/default/capv_manager_image_patch.yaml done generating ./out/capv-mgmt-example/cluster.yaml done generating ./out/capv-mgmt-example/machines.yaml done generating ./out/capv-mgmt-example/machineset.yaml Done generating ./out/capv-mgmt-example/provider-components.yaml *** Finished creating initial example yamls in ./out/capv-mgmt-example The files ./out/capv-mgmt-example/cluster.yaml and ./out/capv-mgmt-example/machines.yaml need to be updated with information about the desired Kubernetes cluster and vSphere environment on which the Kubernetes cluster will be created. Enjoy! This has placed the yaml files in a new directory ./out, so let\u0026rsquo;s finally use clusterctl to spin up a brand new management K8s cluster:\nCreate the Management Cluster cd out/ clusterctl create cluster --provider vsphere --bootstrap-type kind --kubeconfig-out $CLUSTER_NAME/kubeconfig -c $CLUSTER_NAME/cluster.yaml -m $CLUSTER_NAME/machines.yaml -p $CLUSTER_NAME/provider-components.yaml -a $CLUSTER_NAME/addons.yaml This will take in the order of 5-10 minutes depending on your environment, it will create a kind single node K8s cluster on your local machine within a Docker container to act as a bootstrap.\nIt then creates another single-node K8s VM on your target vSphere environment with the same configuration, and deletes the kind cluster from your local machine, because it was only there to act as a bootstrap.\nAt this point, clusterctl will spit out the kubeconfig for your management cluster into your current directory and you should be able to connect to your ClusterAPI \u0026ldquo;management\u0026rdquo; cluster:\nExport the newly downloaded kubeconfig file so it\u0026rsquo;s the default for kubectl to use:\nexport KUBECONFIG=$CLUSTER_NAME/kubeconfig Check to see that the ClusterAPI items have been created (i.e. one cluster and one machine) for the management cluster.\nkubectl get clusters kubectl get machines Workload Clusters Define your Workload Cluster Specification With the ClusterAPI management cluster deployed, we can now use it, along with kubectl to create other K8s workload clusters!\nAgain, like with the management cluster, we need to export some environment variables to our shell in order to define what the workload K8s cluster will look like, things like its name, K8s version, where it lives in vSphere as well as the resources assigned to the nodes. I put all this in a file called workload-cluster-01-vars.sh - change the below to suit your needs:\n# K8s attributes export CLUSTER_NAME=workload-cluster-01 export KUBERNETES_VERSION=1.15.0 # vSphere attributes export VSPHERE_USER=administrator@vsphere.local export VSPHERE_PASSWORD=P@ssw0rd export VSPHERE_SERVER=vc01.satm.eng.vmware.com # VM deployment options export VSPHERE_DATACENTER=DC01 export VSPHERE_DATASTORE=vsanDatastore export VSPHERE_NETWORK=\u0026#34;Cluster01-LAN-1-Routable\u0026#34; export VSPHERE_RESOURCE_POOL=\u0026#34;cluster01/Resources/CAPV\u0026#34; export VSPHERE_FOLDER=\u0026#34;/$(echo $VSPHERE_DATACENTER)/vm/Testing/K8s/$(echo $CLUSTER_NAME)\u0026#34; export VSPHERE_TEMPLATE=\u0026#34;ubuntu-18.04-kube-1.15.0\u0026#34; export VSPHERE_DISK_GIB=60 export VSPHERE_NUM_CPUS=\u0026#34;4\u0026#34; export VSPHERE_MEM_MIB=\u0026#34;4096\u0026#34; Like last time, again import the environment variables from above into your shell session and create a vSphere VM folder for the cluster to live in:\nworkload-cluster-01-vars.sh govc folder.create $VSPHERE_FOLDER And generate the yaml file required by ClusterAPI to specify the workload cluster itself - this command will output the files into a directory named after your CLUSTER_NAME variable from above:\n../hack/generate-yaml.sh -c $CLUSTER_NAME Create the Workload Cluster Let\u0026rsquo;s use the ClusterAPI management cluster (note: we are passing in --kubeconfig kubeconfig which correlates to our management cluster) to create our new workload cluster - we do this by passing in the yaml that was just generated to the management cluster, the ClusterAPI controller within the management cluster will then look at the specifications for each and create a new K8s cluster with the number of masters and workers as defined in machines.yaml and machineset.yaml respectively.\nkubectl --kubeconfig capv-mgmt-example/kubeconfig apply -f $CLUSTER_NAME/cluster.yaml kubectl --kubeconfig capv-mgmt-example/kubeconfig apply -f $CLUSTER_NAME/machines.yaml kubectl --kubeconfig capv-mgmt-example/kubeconfig apply -f $CLUSTER_NAME/machineset.yaml We can check to make sure we now have two clusters known to ClusterAPI, a management cluster and the workload cluster we just imported:\n$ kubectl --kubeconfig capv-mgmt-example/kubeconfig get cluster NAME AGE capv-mgmt-example 20m workload-cluster-01 2m10s If we query ClusterAPI\u0026rsquo;s machines CRD we can see that it will have created a master and two workers if you left the generated yaml files as default:\n$ kubectl --kubeconfig capv-mgmt-example/kubeconfig get machines NAME PROVIDERID PHASE capv-mgmt-example-controlplane-1 workload-cluster-01-controlplane-1 workload-cluster-01-machineset-1-cdg7h workload-cluster-01-machineset-1-hrx5p If you like you can change the get to a describe on one of the nodes to view it\u0026rsquo;s full output and events (at the bottom):\n$ kubectl --kubeconfig capv-mgmt-example/kubeconfig describe machine workload-cluster-01-machineset-1-hrx5p Name: workload-cluster-01-machineset-1-hrx5p Namespace: default Labels: cluster.k8s.io/cluster-name=workload-cluster-01 machineset-name=workload-cluster-01-machineset-1 Annotations: \u0026lt;none\u0026gt; API Version: cluster.k8s.io/v1alpha1 Kind: Machine Metadata: Creation Timestamp: 2019-06-27T14:36:44Z Finalizers: foregroundDeletion machine.cluster.k8s.io Generate Name: workload-cluster-01-machineset-1- Generation: 3 Owner References: API Version: cluster.k8s.io/v1alpha1 Block Owner Deletion: true Controller: true Kind: MachineSet Name: workload-cluster-01-machineset-1 UID: 4aca1d8a-d218-4e30-a129-19ec366e00ab Resource Version: 2277 Self Link: /apis/cluster.k8s.io/v1alpha1/namespaces/default/machines/workload-cluster-01-machineset-1-hrx5p UID: ffde77a9-eaf6-4f00-9365-bf833ad55d73 Spec: Metadata: Creation Timestamp: \u0026lt;nil\u0026gt; Provider Spec: Value: API Version: vsphereproviderconfig/v1alpha1 Kind: VsphereMachineProviderConfig Kubeadm Configuration: Init: Local API Endpoint: Advertise Address: Bind Port: 6443 Node Registration: Join: Ca Cert Path: Discovery: Bootstrap Token: API Server Endpoint: 10.198.25.80:6443 Ca Cert Hashes: sha256:46b6094f3affad00fb1fa90e30bacf50113acad054c546ff459e9349ae9f4391 Token: defrcl.o352jo0ulzjrszyq Unsafe Skip CA Verification: false Tls Bootstrap Token: Node Registration: Cri Socket: /var/run/containerd/containerd.sock Kubelet Extra Args: Cloud - Provider: vsphere Node - Labels: node-role.kubernetes.io/node= Name: {{ ds.meta_data.hostname }} Machine Spec: Datacenter: DC01 Datastore: vsanDatastore Disk Gi B: 60 Disks: \u0026lt;nil\u0026gt; Memory MB: 4096 Network: Devices: dhcp4: true Network Name: Cluster01-LAN-1-Routable Num CP Us: 4 Resource Pool: cluster01/Resources/CAPV Template: ubuntu-18.04-kube-1.15.0 Vm Folder: /DC01/vm/Testing/K8s/workload-cluster-01 Metadata: Creation Timestamp: \u0026lt;nil\u0026gt; Versions: Kubelet: 1.15.0 Status: Provider Status: Metadata: Creation Timestamp: \u0026lt;nil\u0026gt; Task Ref: task-414680 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal CreateRequeue 51s (x4 over 2m42s) vsphere-controller requeued Create Normal UpdateSuccess 37s (x2 over 2m42s) vsphere-controller updated machine config \u0026#34;default/workload-cluster-01/workload-cluster-01-machineset-1-hrx5p\u0026#34; Normal UpdateSuccess 37s vsphere-controller updated machine status for machine \u0026#34;default/workload-cluster-01/workload-cluster-01-machineset-1-hrx5p\u0026#34; Normal CreateSuccess 37s vsphere-controller Create success Normal ExistsSuccess 17s (x7 over 2m42s) vsphere-controller Exists success Normal UpdateRequeue 17s (x2 over 37s) vsphere-controller requeued Update Connecting to the Workload Cluster We\u0026rsquo;ve successfully provisioned our workload cluster, but how do we access and use it?\nGood question, when using ClusterAPI to spin up workload clusters, it needs to put the access credentials (i.e. the kubeconfig file) somewhere, so it puts them in a K8s secret, luckily they are very easy to retrieve and decode to your local machine.\nFirst let\u0026rsquo;s query the kubeconfig files held on the management cluster (if yours isn\u0026rsquo;t showing up yet, it only populates after the workload cluster spins up, so check back):\n$ kubectl --kubeconfig capv-mgmt-example/kubeconfig -n default get secrets NAME TYPE DATA AGE capv-mgmt-example-kubeconfig Opaque 1 33m default-token-9nt25 kubernetes.io/service-account-token 3 34m workload-cluster-01-kubeconfig Opaque 1 13m Notice the workload-cluster-01-kubeconfig secret - this is what we want to connect to our workload cluster, it\u0026rsquo;s very easy to extract and pull this to your local machine. The below command pulls the secret value which is base64 encoded in K8s - decodes it from base64 to text and creates a new kubeconfig file named after your workload cluster, in your current directory.\nkubectl --kubeconfig capv-mgmt-example/kubeconfig -n default get secret $CLUSTER_NAME-kubeconfig -o jsonpath=\u0026#39;{.data.value}\u0026#39; | base64 -D \u0026gt; $CLUSTER_NAME/kubeconfig Let\u0026rsquo;s apply the addons to our workload cluster (these are mainly just the networking overlay, Calico) - required to let pods talk to one-another (note: this uses the kubeconfig file we just downloaded to connect to the workload cluster):\nkubectl --kubeconfig $CLUSTER_NAME/kubeconfig apply -f $CLUSTER_NAME/addons.yaml And watch as the pods get spun up, when it\u0026rsquo;s all working - everything should list as Running:.\nkubectl --kubeconfig $CLUSTER_NAME/kubeconfig get pods -n kube-system -w Verify vSphere Cloud Provider Setup Let\u0026rsquo;s ensure the vSphere Cloud Provider is fully setup and functional by querying the cloud-provider ProviderID from the nodes (as long as this returns some values, it\u0026rsquo;s worked):\nkubectl --kubeconfig $CLUSTER_NAME/kubeconfig describe nodes | grep \u0026#34;ProviderID\u0026#34; Deploy some applications Now that the workload cluster is set up, we can deploy some apps to it - because ClusterAPI also takes care of the VCP setup, we can even deploy ones that use persistent storage!\nWe\u0026rsquo;re going to deploy use helm to set up an application called RocketChat on the cluster, which uses two persistent volumes, one for config and one for its MongoDB database.\nConfigure helm Be aware this installation style for helm (granting the tiller pod cluster-admin privileges) is a big security no-no and is just for ease of setup here. For more information on why this is bad, look here, and please don\u0026rsquo;t do this on a production cluster.\nIn this case, it is a throwaway cluster for me, so I will be using these permissions. First create the RBAC role and permissions for the helm service account in another new file called helm-rbac.yaml:\napiVersion:v1kind:ServiceAccountmetadata:name:tillernamespace:kube-system---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:tillerroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:cluster-adminsubjects:- kind:ServiceAccountname:tillernamespace:kube-systemApply the role to the cluster:\n$ kubectl --kubeconfig $CLUSTER_NAME/kubeconfig create -f helm-rbac.yaml serviceaccount/tiller created clusterrolebinding.rbac.authorization.k8s.io/tiller created Let\u0026rsquo;s install helm onto the cluster with the service account we provisioned:\n$ helm --kubeconfig $CLUSTER_NAME/kubeconfig init --service-account tiller $HELM_HOME has been configured at /Users/mylesgray/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure \u0026#39;allow unauthenticated users\u0026#39; policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! Configure a StorageClass Now that helm is installed and running - we need to create a StorageClass to tell K8s where to provision the PersistentVolumes to (more info on StorageClasses and PersistentVolumes here) - i\u0026rsquo;m using vSAN and have a SPBM policy called vSAN Default Storage Policy - my file is called vsan-default-sc.yaml:\nkind:StorageClassapiVersion:storage.k8s.io/v1metadata:name:vsan-defaultannotations:storageclass.kubernetes.io/is-default-class:\u0026#34;true\u0026#34;provisioner:kubernetes.io/vsphere-volumeparameters:storagePolicyName:\u0026#34;vSAN Default Storage Policy\u0026#34;datastore:vsanDatastoreOnce you\u0026rsquo;ve created the above StorageClass file, import it into the workload cluster:\nkubectl --kubeconfig $CLUSTER_NAME/kubeconfig apply -f vsan-default-sc.yml Provision an application We\u0026rsquo;re now in a place where we can provision an application, we\u0026rsquo;re going to use helm to install RocketChat, as discussed above - RocketChat is basically an Open-Source Slack clone that you can run on-prem.\nThe below command tells helm to install RocketChat from the stable/rocketchat repository, give it a name, set the passwords for MongoDB and most critically - use the vsan-default StorageClass that we just imported into the workload cluster to back the PersistentVolumes requested by RocketChat:\nhelm --kubeconfig $CLUSTER_NAME/kubeconfig install --name rocketchat stable/rocketchat --set mongodb.mongodbPassword=rocketchat,mongodb.mongodbRootPassword=rocketchat --set persistence.storageClass=vsan-default --set mongodb.persistence.storageClass=vsan-default Verify the volumes got provisioned (this will take a minute before it returns back the \u0026ldquo;Bound\u0026rdquo; status):\n$ kubectl --kubeconfig $CLUSTER_NAME/kubeconfig get pv,pvc NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pvc-a5e193b2-9804-11e9-8e11-0050569c242e 8Gi RWO Delete Bound default/datadir-rocketchat-mongodb-primary-0 vsan-default 16m persistentvolume/pvc-a5e72e14-9804-11e9-8e11-0050569c242e 8Gi RWO Delete Bound default/datadir-rocketchat-mongodb-secondary-0 vsan-default 16m NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/datadir-rocketchat-mongodb-primary-0 Bound pvc-a5e193b2-9804-11e9-8e11-0050569c242e 8Gi RWO vsan-default 16m persistentvolumeclaim/datadir-rocketchat-mongodb-secondary-0 Bound pvc-a5e72e14-9804-11e9-8e11-0050569c242e 8Gi RWO vsan-default 16m And the pods for the application should be running:\nkubectl --kubeconfig $CLUSTER_NAME/kubeconfig get po NAME READY STATUS RESTARTS AGE rocketchat-mongodb-arbiter-0 1/1 Running 0 57s rocketchat-mongodb-primary-0 1/1 Running 0 57s rocketchat-mongodb-secondary-0 1/1 Running 0 57s rocketchat-rocketchat-5dcf4664c5-x9sl5 1/1 Running 0 57s At this point, we can access the application by port-forwarding to the rocketchat-rocketchat-* pod from the output above (change this to suit your pod name):\nkubectl --kubeconfig $CLUSTER_NAME/kubeconfig port-forward rocketchat-rocketchat-5dcf4664c5-x9sl5 8888:3000 Access the application on localhost:8888 in your web browser:\nopen http://localhost:8888  \nScaling out a Workload Cluster What else can we do with ClusterAPI? How about you\u0026rsquo;ve decided that workload cluster you deployed isn\u0026rsquo;t meaty enough - and you want some more worker nodes? No problem. All we have to do is update the replicas in machineset.yaml to the desired number of workers, by default it\u0026rsquo;s 2 - let\u0026rsquo;s change it to 5.\nsed -i \u0026#39;\u0026#39; \u0026#39;s/replicas: 2/replicas: 5/g\u0026#39; workload-cluster-01/machineset.yaml And deploy the changes to the ClusterAPI management cluster (which will create the new machines in the workload cluster for us):\nkubectl --kubeconfig capv-mgmt-example/kubeconfig apply -f $CLUSTER_NAME/machineset.yaml We can check to make sure it did what we asked by querying the machines that the management cluster is keeping track of:\n$ kubectl --kubeconfig capv-mgmt-example/kubeconfig get machines NAME PROVIDERID PHASE capv-mgmt-cluster-controlplane-1 workload-cluster-01-controlplane-1 workload-cluster-01-machineset-1-255cx workload-cluster-01-machineset-1-8269f workload-cluster-01-machineset-1-96kf4 workload-cluster-01-machineset-1-g8xkx workload-cluster-01-machineset-1-qxvkw And we can watch our workload cluster as the nodes come up (this took around two minutes for me):\n$ kubectl --kubeconfig $CLUSTER_NAME/kubeconfig get nodes -o wide -w NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME workload-cluster-01-controlplane-1 Ready master 41m v1.15.0 10.198.25.80 10.198.25.80 Ubuntu 18.04.2 LTS 4.15.0-52-generic containerd://1.2.5 workload-cluster-01-machineset-1-cdg7h Ready node 39m v1.15.0 10.198.25.81 10.198.25.81 Ubuntu 18.04.2 LTS 4.15.0-52-generic containerd://1.2.5 workload-cluster-01-machineset-1-d69mg Ready node 2m15s v1.15.0 10.198.25.96 10.198.25.96 Ubuntu 18.04.2 LTS 4.15.0-52-generic containerd://1.2.5 workload-cluster-01-machineset-1-h2qjj Ready node 2m58s v1.15.0 10.198.25.83 10.198.25.83 Ubuntu 18.04.2 LTS 4.15.0-52-generic containerd://1.2.5 workload-cluster-01-machineset-1-hrx5p Ready node 39m v1.15.0 10.198.25.82 10.198.25.82 Ubuntu 18.04.2 LTS 4.15.0-52-generic containerd://1.2.5 workload-cluster-01-machineset-1-pbp8w Ready node 2m17s v1.15.0 10.198.25.95 10.198.25.95 Ubuntu 18.04.2 LTS 4.15.0-52-generic containerd://1.2.5 And of course, they all come up with the vSphere Cloud Provider installed, configured and functional:\n$ kubectl --kubeconfig $CLUSTER_NAME/kubeconfig describe nodes | grep \u0026#34;ProviderID\u0026#34; ProviderID: vsphere://421c0e70-107e-32d2-e49f-2a1d9c88455f ProviderID: vsphere://421c5547-dcb0-a0d9-a660-bcc348ad04a6 ProviderID: vsphere://421c93ae-1811-140c-ff5a-dc7c036b5a94 ProviderID: vsphere://421c461e-ab2c-5f55-5c4e-3593fa9c0150 ProviderID: vsphere://421cc8b4-eb7c-74cd-eaaa-5e1cd421a1d6 ProviderID: vsphere://421cd848-5a0c-0bfd-e5ea-f188ce482e9e Troubleshooting Bootstrap Cluster When deploying the initial management cluster, it can be useful to debug and find out where things went wrong if it hung up, there is one main place you can do this, because ClusterAPI uses kind to bootstrap the management cluster, we can query its pods to find out what\u0026rsquo;s going on with provisioning.\nFirst, ensure the kind Docker container is running on your machine:\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8b855d80aff4 kindest/node:v1.14.2 \u0026#34;/usr/local/bin/entr…\u0026#34; 4 seconds ago Up 1 second 58226/tcp, 127.0.0.1:58226-\u0026gt;6443/tcp clusterapi-control-plane Export the kind kubeconfig and connect the the k8s cluster within the docker container and ensure you can connect:\nexport KUBECONFIG=\u0026#34;$(kind get kubeconfig-path --name=\u0026#34;clusterapi\u0026#34;)\u0026#34; kubectl cluster-info Check to make sure all the pods are running:\n$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE cluster-api-system cluster-api-controller-manager-0 1/1 Running 0 49s kube-system coredns-fb8b8dccf-5ztkn 1/1 Running 0 49s kube-system coredns-fb8b8dccf-dbp7m 1/1 Running 0 49s kube-system ip-masq-agent-jwttw 1/1 Running 0 49s kube-system kindnet-hn788 1/1 Running 1 49s kube-system kube-apiserver-clusterapi-control-plane 0/1 Pending 0 3s kube-system kube-proxy-65jmv 1/1 Running 0 49s vsphere-provider-system vsphere-provider-controller-manager-0 1/1 Running 0 49s Once the vsphere-provider-controller-manager-0 pod is running, query the logs to find out what\u0026rsquo;s going on:\nkubectl logs -n vsphere-provider-system vsphere-provider-controller-manager-0 -f Check the above output for errors - they will be fairly obvious and the first character on each line of an error output it E i.e.:\nE0626 12:29:35.675558 1 cluster_controller.go:143] Actuator... Management Cluster If your management cluster deployed fine, but the workload cluster is stuck - you can check it in basically the same way, except this time, just use the management cluster\u0026rsquo;s kubeconfig file:\nkubectl --kubeconfig capv-mgmt-example/kubeconfig logs -n vsphere-provider-system vsphere-provider-controller-manager-0 -f Just the same as the bootstrap cluster, look for lines in the output beginning with E if you are debugging deployment of workload clusters.\nSSH into nodes If you need to dive in a bit further as long as you ran export SSH_AUTHORIZED_KEY=\u0026quot;$(cat ~/.ssh/id_rsa.pub)\u0026quot; as instructed before deploying your management or workload clusters, you can SSH into any of them with key based authorisation:\nssh ubuntu@node-ip-here Then troubleshooting is just the same as it would be for the vSphere Cloud Provider on nodes you\u0026rsquo;ve provisioned yourself.\nIt\u0026rsquo;s important to note here that this should be used only to troubleshoot - a key tenant of ClusterAPI is that the infrastructure is meant to be immutable so SSH-ing in to change things is an anti-pattern. Instead, you should troubleshoot the problem, destroy the cluster, fix the deployment yaml files and re-deploy the cluster so that it is always in a known-good state and is consistent.\nDeleting clusters clusterctl comes with the ability to not only create, setup and expand clusters, but also to delete them. You need a few things passed into clusterctl to do this (for safety) - the kubeconfig and the provider-components.yaml files of the master cluster.\nFor example - If I wanted to delete the master cluster and all the worker clusters it deployed i\u0026rsquo;d run:\nclusterctl delete cluster --bootstrap-type kind --kubeconfig capv-mgmt-example/kubeconfig -p capv-mgmt-example/provider-components.yaml This will take about 5-10 minutes and cascading delete all the clusters you deployed, first it\u0026rsquo;ll delete the machinesets (workers) for each workload cluster, next it\u0026rsquo;ll delete the machines (masters) for the workload clusters and finally it\u0026rsquo;ll delete the management cluster itself - leaving your environment exactly as it was before you deployed anything.\nConclusion Thanks for sticking with me through this whirlwind tour of ClusterAPI and CAPV - there are very exciting developments going on in this area, if you want to know more about the ClusterAPI roadmap or CAPV, check out the links.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/","summary":"Introduction K8s lifecycle is something people are still struggling with, despite amazing tools out there like kubeadm which take care of the K8s setup itself, we are still lacking something fundamental - they day-0 setup.\nWho/what actually creates the VMs and installs the packages on them so we can get to the stage that we can use kubeadm?\nTypically it\u0026rsquo;s up to the user, and as such can vary wildly - so how can that experience be improved, and even better - totally automated and declarative.","title":"First-look: Automated K8s lifecycle with ClusterAPI"},{"content":"This isn\u0026rsquo;t necessarily a follow-on from the other three blogs so far in this series, but more of an alternative to parts one and two. Following on from those I felt that the process could be much more automated, and less \u0026ldquo;ssh into every box and change things manually\u0026rdquo;. After all, the less changes we can make iteratively and imperatively, the more it is programmed or declarative, the better.\nThis blog is one way to do that - I expect to have two or three more methods blogged in the near future that will offer futher options - with a particular focus on day-2.\nSo what are we doing this time, and how is it different?\nThere is a package called cloud-init that comes by default on \u0026ldquo;cloud images\u0026rdquo; of most Linux operating systems these days, it\u0026rsquo;s purpose is to do day-0 setup of operating systems, things like package installations, repository setup, SSH key additions, writing out to files and running arbitrary shell commands at first boot.\nWith that in mind, cloud-init covers basically everything we did in the first part of the series and most of the second, it\u0026rsquo;s much quicker and much more scalable, and quite recently VMware Tools added support for using cloud-init as it\u0026rsquo;s customisation engine as an alternative to the default perl scripting, this means we can deploy one VM template to vSphere and use the built in cloning and customisations specs in vSphere to add networking and hostnames to the new VMs.\ncloud-init relies, for our purposes, on one file called user-data - but can also include a meta-data file, but that is handled in vSphere\u0026rsquo;s case by the customisation specs.\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   kubectl - brew install kubernetes-cli  https://kubernetes.io/docs/tasks/tools/install-kubectl/   Powershell - brew tap caskroom/cask \u0026amp;\u0026amp; brew cask install powershell  https://github.com/PowerShell/PowerShell   PowerCLI - pwsh then Install-Module -Name VMware.PowerCLI -Scope CurrentUser  https://code.vmware.com/web/dp/tool/vmware-powercli   govc - brew tap govmomi/tap/govc \u0026amp;\u0026amp; brew install govmomi/tap/govc  https://github.com/vmware/govmomi/tree/master/govc    Resources Just like in part one, we are going to need the Ubuntu 18.04 LTS Cloud image OVA from Canonical\u0026rsquo;s repo downloaded to our local machine in order to extract the OVF specifications from it, the OVA can be found here:\n https://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.ova  Setup govc With the OVA downloaded, we need to configure a few variables for govc to connect to our vCenter, handily, rather than having to define them on the CLI for every command, we can just export them as variables to our current shell.\nI created a file called govcvars.sh with the following content - create one for yourself filling in the relevant details:\n$ cat govcvars.sh export GOVC_INSECURE=1 # Don\u0026#39;t verify SSL certs on vCenter export GOVC_URL=10.198.16.4 # vCenter IP/FQDN export GOVC_USERNAME=administrator@vsphere.local # vCenter username export GOVC_PASSWORD=P@ssw0rd # vCenter password export GOVC_DATASTORE=vsanDatastore # Default datastore to deploy to export GOVC_NETWORK=\u0026#34;Cluster01-LAN-1-Routable\u0026#34; # Default network to deploy to export GOVC_RESOURCE_POOL=\u0026#39;cluster01/Resources\u0026#39; # Default resource pool to deploy to export GOVC_DATACENTER=DC01 # I have multiple DCs in this VC, so i\u0026#39;m specifying the default here Next, we need to load the variables into our current shell session:\nsource govcvars.sh At this point we should be able to connect to and query our vCenter:\n$ govc about Name: VMware vCenter Server Vendor: VMware, Inc. Version: 6.7.0 Build: 13639324 OS type: linux-x64 API type: VirtualCenter API version: 6.7.2 Product ID: vpx UUID: dc0eaa5c-3460-49ef-aeb2-09e886ad333a Extract the image spec Extract the OVF spec from the OVA Use govc to pull the OVF spec from the Ubuntu OVA we just downloaded, for customisation (this will output the spec to a file in your current directory called ubuntu.json):\ngovc import.spec ~/Downloads/ubuntu-18.04-server-cloudimg-amd64.ova | python -m json.tool \u0026gt; ubuntu.json Customise the OVF spec This is where we diverge from part one, we are going to fill in only two fields here and the rest will be encoded in our user-data file that we\u0026rsquo;ll get to in a bit.\nBelow, I only changed three things; hostname, Network and Name. These correlate to the in-guest name of the VM, the vSphere Port Group the VM will be attached to for networking on deployment, and the name of the VM when deployed (note: this is not the hostname of the VM, just the VM name itself).\nNote, I have just cleared the hostname value, this is important and will be populated later by the vSphere customisation spec at clone-time.\n$ cat ubuntu.json { \u0026#34;DiskProvisioning\u0026#34;: \u0026#34;thin\u0026#34;, \u0026#34;IPAllocationPolicy\u0026#34;: \u0026#34;dhcpPolicy\u0026#34;, \u0026#34;IPProtocol\u0026#34;: \u0026#34;IPv4\u0026#34;, \u0026#34;PropertyMapping\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;instance-id\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;id-ovf\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;hostname\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;seedfrom\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;public-keys\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;user-data\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;NetworkMapping\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;VM Network\u0026#34;, \u0026#34;Network\u0026#34;: \u0026#34;Cluster01-LAN-1-Routable\u0026#34; } ], \u0026#34;MarkAsTemplate\u0026#34;: false, \u0026#34;PowerOn\u0026#34;: false, \u0026#34;InjectOvfEnv\u0026#34;: false, \u0026#34;WaitForIP\u0026#34;: false, \u0026#34;Name\u0026#34;: \u0026#34;Ubuntu1804Template\u0026#34; } With that set up, it\u0026rsquo;s time to start building out our user-data file which does the bulk of the operating system setup and prep.\nBuilding the user-data file cloud-init has a very rich set of built-in supported primitives for OS setup, you can see a mostly complete list here (it is also extensible via plugins).\nA note before we get into this - \u0026ldquo;cloud-images\u0026rdquo; are not meant to be logged into with a password ever, you are expected to use SSH public-key authentication. So you will need to grab your SSH public key for the upcoming work.\nYou can get your SSH public key by running cat ~/.ssh/id_rsa.pub - note if you run this command and you don\u0026rsquo;t get an output - you probably need to generate an SSH key with ssh-keygen.\nAll of the below sections should be added to a single file called user-data on your local system, we will be encoding it as a single entity later on, but as you follow, just keep appending all the sections together in that one file.\nSetting up users and groups user-data is entirely written in yaml, so spacing and indentation is critical here.\nThe below snippet is actually very simple, it adds a group to the OS called docker and changes the default user ubuntu to add a trusted SSH public key, as well as add it to the sudo group with no-password escalation, adds the user to the docker group that was just created and sets the default shell for the user to bash.\nNote, you can add multiple SSH keys to a user for login (say if you have two laptops) by simply adding another line item under the ssh-authorized-keys key.\nThis is where you would want to take the output of cat ~/.ssh/id_rsa.pub and insert it into the code - you can see the SSH public key for my laptop below as an example.\ngroups:- dockerusers:- default- name:ubuntussh-authorized-keys:- ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDcxQcNS5vzxHn2sdHHw/nTHWiME5OWv1i3cvMdqMUWKhPSv7uHCTz3Q4kot8UvdD/jIDOktIpDlayVeXkxAuMzIB0lbVEku1mjLyDQ0syGVSAvj4BkH2uLp0Hybc97U0PQHYgLy60d2l8c96qajPHxRmDYRKbCQaNxQeafxwlQUzr615RvzjOgt5v7zhdZ+V5pIDH2Amf/rRiPrq0NLTYShpoRwtFeS4bQtG5mHfDDvzg+Jh1Sxt63oB0AGy0ORv7GzSDlqraFADxOwFnKz0/fbVKeauFCFXRKrral+PSRgbr39cVJHykaYVDw9D3nKMZqDKITRXAJiWAEES91yk6nikAwgyXup+wpiymMmgUq60ASHgpTqWbtPdEZAsjtlhJXSDit+iWS1yrdLg5ayza8PAr5YijT0g+xMkJXudxgGOr913Oty04Fxk61n3kcjadsbt5hjc3QWxK0Rj0jJK9HwV2sn8lHVdvSfwOkgZLH7WH4E2IBGQVm+4Cd8RLMsAev5tnWGIiSLl2uRi63+mKwynIriSAAdWurrs11Q36qYrdwPK2XXq/MvUcTnm3yXSLjeSLWMmdoyqiLqxerOiBcMRbTwvVwfe73UJXdLPbfA0xqAB/gTg2NxmcAI/F3OEWMRM4/PsqPS2t/VAL993OdSshHGtT30AP86G+vuHuecw== mylesg@vmware.comsudo:ALL=(ALL) NOPASSWD:ALLgroups:sudo, dockershell:/bin/bashAdding apt repositories and installing packages Next up, as we\u0026rsquo;re making a base image for Kubernetes cluters, we are going to add two repositories - one for Kubernetes and one for Docker. I found the easiest way to add them is by using the keyid rather than the GPG key in it\u0026rsquo;s entirety, it\u0026rsquo;s much smaller and less error prone.\nThe documentation for each module is here: apt, package_upgrade, packages.\nTo briefly go over what\u0026rsquo;s happening below: we are adding the two repositories for K8s and Docker to apt and trusting them by adding the GPG key ids for each. Next up, we tell the OS to upgrade all packages on boot and finally, we tell the OS to install four packages; kubelet, kubectl, kubeadm and docker-ce at specific target versions (in this case, for K8s v1.14.2 and the supported Docker runtime version).\nThe neat thing about this is, if you ever want to change the base packages that come on your OS (like when kubernetes or docker get upgraded) - you would simply update the version strings next to each package and deploy the OVA again with the new spec attached, rather than having to rebuild an image manually and in its entirety via SSH.\napt:sources:kubernetes:source:\u0026#34;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026#34;keyserver:\u0026#34;hkp://keyserver.ubuntu.com:80\u0026#34;keyid:BA07F4FBdocker:arches:amd64source:\u0026#34;deb https://download.docker.com/linux/ubuntu bionic stable\u0026#34;keyserver:\u0026#34;hkp://keyserver.ubuntu.com:80\u0026#34;keyid:0EBFCD88package_upgrade:truepackages:- [kubelet, 1.14.3-00]- [kubectl, 1.14.3-00]- [kubeadm, 1.14.3-00]- [docker-ce, \u0026#39;5:18.09.6~3-0~ubuntu-bionic\u0026#39;]Writing the kubeadm and vsphere.conf template files This section may look unwieldy and complex, but it\u0026rsquo;s actually one of the simplest to understand. In this instance we are using the write_files module and specifying a file path as well as the content to go inside that file, simple!\nThere are four files in total here:\nThe first one /etc/docker/daemon.json to create the Docker daemon config as-per the K8s docs.\nNext up, /etc/kubernetes/kubeadminitmaster.yaml for the kubeadm master initialisation where we specify things like the token to use for cluster membership and kubeadm join operations, the K8s version to install, the cloud-provider name and config location as well as the pod networking overlay subnet. For further explaination on these, check out my previous article on this.\nThe third file is /etc/kubernetes/kubeadminitworker.yaml which tells the worker nodes how to join the K8s cluster, by specifying the same token as in the last file, the same cloud-provider configuration and introduces the discovery.yaml file, which tells the workers what IP address to access the master on and what credentials to use to log into it (more on that in a little bit).\nUp to this point, you could have copied and pasted the below config verbatim with zero ill-effect. The fourth file however, requires a little customisation. This is the cloud-provider config file for the vSphere Cloud Provider and you\u0026rsquo;ll need to fill in your own environment details here. It will live at /etc/kubernetes/vsphere.conf.\nYou\u0026rsquo;ll probably notice that the config looks almost identical as the govcvars.sh file from above, and that\u0026rsquo;s because it\u0026rsquo;s the same environment! So fill this section in with details like your vCenter IP, username, password, Datacenter name, Resource pool and network. A full rundown of the config options can be found here.\nwrite_files:- content:|{ \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34; }, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34; }path:/etc/docker/daemon.json- content:|apiVersion: kubeadm.k8s.io/v1beta1 kind: InitConfiguration bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: y7yaev.9dvwxx6ny4ef8vlq ttl: 0s usages: - signing - authentication nodeRegistration: kubeletExtraArgs: cloud-provider: \u0026#34;vsphere\u0026#34; cloud-config: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; --- apiVersion: kubeadm.k8s.io/v1beta1 kind: ClusterConfiguration kubernetesVersion: v1.14.3 apiServer: extraArgs: cloud-provider: \u0026#34;vsphere\u0026#34; cloud-config: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; extraVolumes: - name: cloud hostPath: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; mountPath: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; controllerManager: extraArgs: cloud-provider: \u0026#34;vsphere\u0026#34; cloud-config: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; extraVolumes: - name: cloud hostPath: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; mountPath: \u0026#34;/etc/kubernetes/vsphere.conf\u0026#34; networking: podSubnet: \u0026#34;10.244.0.0/16\u0026#34;path:/etc/kubernetes/kubeadminitmaster.yaml- content:|apiVersion: kubeadm.k8s.io/v1beta1 discovery: file: kubeConfigPath: discovery.yaml timeout: 5m0s tlsBootstrapToken: y7yaev.9dvwxx6ny4ef8vlq kind: JoinConfiguration nodeRegistration: kubeletExtraArgs: cloud-provider: vspherepath:/etc/kubernetes/kubeadminitworker.yaml- content:|[Global] user = \u0026#34;administrator@vsphere.local\u0026#34; password = \u0026#34;P@ssw0rd\u0026#34; port = \u0026#34;443\u0026#34; insecure-flag = \u0026#34;1\u0026#34; [VirtualCenter \u0026#34;10.198.16.4\u0026#34;] datacenters = \u0026#34;DC01\u0026#34; [Workspace] server = \u0026#34;10.198.16.4\u0026#34; datacenter = \u0026#34;DC01\u0026#34; default-datastore = \u0026#34;vsanDatastore\u0026#34; resourcepool-path = \u0026#34;cluster01/Resources\u0026#34; folder = \u0026#34;k8s\u0026#34; [Disk] scsicontrollertype = pvscsi [Network] public-network = \u0026#34;Cluster01-LAN-1-Routable\u0026#34;path:/etc/kubernetes/vsphere.confSome system-prep commands and housekeeping Because the system is going to be booted once on import to set up VMware Tools and customisation specs - we need to run a few commands to clean up any uniqueness in the OS as well as set up some K8s-specific pre-requisites.\nRunning arbitrary commands The below runcmd module allows us to use cloud-init to run commands on the OS boot, they usually run last in the chain after the other modules.\nTo run through them in order we are:\n Turning off Swap on the OS Persisting the swapoff operation by removing it from the filesystem mounts Creating a Docker daemon systemd file location Reloading the systemd config files Restarting the docker service Allowing IPv4 bridge traffic to traverse iptables (required by most CNIs) Allowing IPv6 bridge traffic to traverse iptables (required by most CNIs) Enabling vSphere customiation to call cloud-init - reference Don\u0026rsquo;t clear /tmp on reboot for customisation - reference Clear the machine-id to ensure the cloned VMs get unique IDs and IP addresses.  With all the commands run, we post a final_message to state the system is prepped and how long it took.\nAnd finally, we shutdown the VM via the power_state module when everything is run, allowing a max of 30s for processes to terminate.\nruncmd:- swapoff --all- sed -ri \u0026#39;/\\sswap\\s/s/^#?/#/\u0026#39; /etc/fstab- mkdir -p /etc/systemd/system/docker.service.d- systemctl daemon-reload- systemctl restart docker- sysctl net.bridge.bridge-nf-call-iptables=1- sysctl net.bridge.bridge-nf-call-ip6tables=1- \u0026#39;echo \u0026#34;disable_vmware_customization: false\u0026#34; \u0026gt;\u0026gt; /etc/cloud/cloud.cfg\u0026#39;- sed -i \u0026#39;s/D \\/tmp 1777 root root -/#D \\/tmp 1777 root root -/g\u0026#39; /usr/lib/tmpfiles.d/tmp.conf- echo -n \u0026gt; /etc/machine-idfinal_message:\u0026#34;The system is prepped, after $UPTIME seconds\u0026#34;power_state:timeout:30mode:poweroffWith your user-data fully built, if you like you can validate it using the Ubuntu cloud-init tool as below - this step is optional, but it\u0026rsquo;s worth doing to make sure it parses correctly:\ncloud-init devel schema --config-file my-user-data-file.txt Encoding the data and deploying the template Now that our full user-data file is built (full example here) we need to encode it in base64 to allow us to put it into the ubuntu.json file at the start (almost forgot about that, didn\u0026rsquo;t ya?).\nEncoding with base64 This is very easy, to verify it gets encoded properly, we\u0026rsquo;ll run a decode and the output should be the same as your user-data file - spacing and all.\nbase64 user-data | base64 -D # Note - on Linux it\u0026#39;s lowercase -d If all is well, run it again without the decode and copy the base64 encoded string it outputs:\nbase64 user-data Adding the base64 to ubuntu.json With the output from above copied, paste it into the user-data section of the ubuntu.json file in the Value field. You can see my finished ubuntu.json example here.\nIt essentially looks something like this (but a lot longer):\n{ \u0026#34;Key\u0026#34;: \u0026#34;user-data\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;I2Nsb3VkLWNvbmZpZwpjaHBhc3N3ZDoKICAgIGxpc3Q6IHwKICAgICAgdWJ1bnR1OlZNd2FyZTEhCiAgICBleHBpcmU6IGZh...Y29uZHMiCnBvd2VyX3N0YXRlOgogIHRpbWVvdXQ6IDMwCiAgbW9kZTogcG93ZXJvZmY=\u0026#34; }, Deploy the template VM Now that the ubuntu.json is complete and includes all our user-data options encoded in base64, it\u0026rsquo;s time to deploy the template VM all the other will be cloned from.\nImport the OVA Deploy the OVA with the spec attached:\ngovc import.ova -options=ubuntu.json ~/Downloads/ubuntu-18.04-server-cloudimg-amd64.ova Note: When deploying you\u0026rsquo;ll see this output, that is expected and can be safely ignored:\nWarning: Line 107: Unable to parse \u0026#39;enableMPTSupport\u0026#39; for attribute \u0026#39;key\u0026#39; on element \u0026#39;Config\u0026#39;. Update the VM to have a larger disk and more CPUs and RAM:\ngovc vm.change -vm Ubuntu1804Template -c 4 -m 4096 -e=\u0026#34;disk.enableUUID=1\u0026#34; govc vm.disk.change -vm Ubuntu1804Template -disk.label \u0026#34;Hard disk 1\u0026#34; -size 60G Power on the VM and allow customisation to run (it\u0026rsquo;ll auto-shut down when done, as we specified in user-data) this should take around 3-4 minutes, maximum:\ngovc vm.power -on=true Ubuntu1804Template Wait for the VM to shut down and mark the VM as a template for cloning:\nuntil govc vm.info -json Ubuntu1804Template | jq -r \u0026#39;.VirtualMachines[].Runtime.PowerState\u0026#39; | grep -q \u0026#34;poweredOff\u0026#34;; do sleep 5; done govc vm.markastemplate Ubuntu1804Template vSphere customisation spec At this point we need to create our vSphere Customisation Spec we talked about at the start, this is very simple and currently requires PowerShell and PowerCLI, but this functionality may get included in govc if there is enough interest.\nStart up PowerShell and create a guest customisation spec\npwsh I am connecting to my vCenter from above, creating a customisation spec called Ubuntu and using my internal DNS servers as well as domain name and setting the hostname to be the same as the VM name (advised) - but customise whichever way you see fit:\n\u0026gt; Connect-VIServer 10.198.16.4 -User administrator@vsphere.local -Password P@ssw0rd \u0026gt; New-OSCustomizationSpec -Name Ubuntu -OSType Linux -DnsServer 10.198.16.1,10.198.16.2 -DnsSuffix satm.eng.vmware.com -Domain satm.eng.vmware.com -NamingScheme vm Name Description Type  OSType LastUpdate Server ---- ----------- ---- ------ ---------- ------ Ubuntu Persistent Linux 27/01/2019 21:43:40 10.198.17.160 \u0026gt; exit Deploy some VMs With that done, we can now clone as we see fit.\nI\u0026rsquo;d recommend you deploy a test VM first, just to make sure the customisation works as you expect - if not, see my \u0026ldquo;Troubleshooting\u0026rdquo; section at the bottom of this blog.\ngovc vm.clone -vm Ubuntu1804Template -customization=Ubuntu customisation-test I\u0026rsquo;m going to create a single master and three workers by specifying the template VM and the vSphere customisation spec we just defined above. The last command will check for IP addresses for the new nodes every 10 seconds:\ngovc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-master01 govc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-worker01 govc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-worker02 govc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-worker03 watch -n 10 \u0026#34;govc find / -type m -name \u0026#39;k8s*\u0026#39; | xargs govc vm.ip -a -v4 -wait 10m\u0026#34; Move the VMs into a folder Let\u0026rsquo;s move the VMs into the folder that was specified in the vsphere.conf above, for cleanliness. You\u0026rsquo;ll need to adjust this to match your datacenter and folder names:\ngovc folder.create /DC01/vm/k8s govc object.mv /DC01/vm/k8s-\\* /DC01/vm/k8s Run kubeadm Now that the VMs are deployed, we can SSH into them and set up K8s. At this point the setup is basically identical to the \u0026ldquo;Initialising the clusterwith kubeadm\u0026rdquo; sectino of part two of the series, but i\u0026rsquo;ve condensed the outputs and included the broad steps here for brevity.\nInitialise the master First, SSH into the master node (on whatever IP you got from above):\nssh ubuntu@10.198.25.84 Run the kubeadm initialisation using the file that was part of our user-data:\nsudo kubeadm init --config /etc/kubernetes/kubeadminitmaster.yaml Import the kubeconfig file from the master:\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Ensure the master initialised:\n$ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8s-master01 Ready master 14m v1.14.3 10.198.25.84 10.198.25.84 Ubuntu 18.04.2 LTS 4.15.0-51-generic docker://18.9.6 Deploy flannel pod overlay networking so the pods can communicate with each other.\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml Check to make sure the pods are all in the status Running:\n$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-fb8b8dccf-jwrr9 1/1 Running 0 12m kube-system coredns-fb8b8dccf-ktqf4 1/1 Running 0 12m kube-system etcd-k8s-master01 1/1 Running 0 11m kube-system kube-apiserver-k8s-master01 1/1 Running 0 11m kube-system kube-controller-manager-k8s-master01 1/1 Running 0 11m kube-system kube-flannel-ds-amd64-d8fhm 1/1 Running 0 77s kube-system kube-proxy-kfmbr 1/1 Running 0 12m kube-system kube-scheduler-k8s-master01 1/1 Running 0 11m Export the master node config used to point the workers being joined to the master:\nkubectl -n kube-public get configmap cluster-info -o jsonpath=\u0026#39;{.data.kubeconfig}\u0026#39; \u0026gt; discovery.yaml On your laptop Copy the discovery.yaml to your local machine with scp.\nscp ubuntu@10.198.25.84:~/discovery.yaml discovery.yaml Then upload it to the worker nodes.\nscp discovery.yaml ubuntu@10.198.25.92:~/discovery.yaml scp discovery.yaml ubuntu@10.198.25.93:~/discovery.yaml scp discovery.yaml ubuntu@10.198.25.94:~/discovery.yaml Join the workers to the cluster SSH into each worker node and run the following to join them to the K8s cluster:\nsudo kubeadm join --config /etc/kubernetes/kubeadminitworker.yaml Verify setup Back on the master node, check that all nodes have joined the cluster:\nubuntu@k8s-master01:~$ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8s-master01 Ready master 20m v1.14.3 10.198.25.84 10.198.25.84 Ubuntu 18.04.2 LTS 4.15.0-51-generic docker://18.9.6 k8s-worker01 Ready \u0026lt;none\u0026gt; 61s v1.14.3 10.198.25.92 10.198.25.92 Ubuntu 18.04.2 LTS 4.15.0-51-generic docker://18.9.6 k8s-worker02 Ready \u0026lt;none\u0026gt; 61s v1.14.3 10.198.25.93 10.198.25.93 Ubuntu 18.04.2 LTS 4.15.0-51-generic docker://18.9.6 k8s-worker03 Ready \u0026lt;none\u0026gt; 61s v1.14.3 10.198.25.94 10.198.25.94 Ubuntu 18.04.2 LTS 4.15.0-51-generic docker://18.9.6 Verify the providerID is set on all the nodes for the VCP to operate correctly:\nubuntu@k8s-master01:~$ kubectl describe nodes | grep \u0026#34;ProviderID\u0026#34; ProviderID: vsphere://421cb10a-b42b-dedc-a4ba-ff772488c565 ProviderID: vsphere://421ca947-60a0-464d-ba72-996fc96c6c92 ProviderID: vsphere://421c9702-358e-8253-0c21-faac1e95748b ProviderID: vsphere://421cb1a3-946d-b7b6-9286-1d021a0b7ba4 Detatch the OVFSpec ISO An interesting tidbit is that when using cloud-init through OVF properties, a small ISO is mounted into each VM that contains the spec itself, this needs to be disconnected before any reboots to avoid double-prepping and hostname resets on reboot.\nEject the OVF ISO:\ngovc device.cdrom.eject -vm k8s-master01 govc device.cdrom.eject -vm k8s-worker01 govc device.cdrom.eject -vm k8s-worker02 govc device.cdrom.eject -vm k8s-worker03 In a separate terminal run this to force the eject:\ngovc vm.question -vm k8s-master01 -answer 0 govc vm.question -vm k8s-worker01 -answer 0 govc vm.question -vm k8s-worker02 -answer 0 govc vm.question -vm k8s-worker03 -answer 0 Conclusion So there we have the second of two methods for VM templating on vSphere - this one is much more prescriptive, scalable and easier to operationalise and we\u0026rsquo;ve gone from nothing to a K8s cluster in this single blog post.\nGo on to part three of the series here and deploy some apps!\nTroubleshooting I learned a LOT about OS customisation during this exercise, a lot of it I didn\u0026rsquo;t want to know. However, most importantly I learned how to troubleshoot it. So below are a few places you can look for guidance when something isn\u0026rsquo;t working.\nVMware Guest OS Customisation Overview VMware GOSC has two methods for setting up the deployed OS; cloud-init and custom perl scripts that are part of VMTools. cloud-init being the preferred method from now and hence, the existence of this article.\nWhen a VM is cloned via a Customisation Spec as above and with the disable_vmware_customisation: false set in /etc/cloud/cloud.cfg and /tmp set to not clear, as we did in the user-data above, vSphere hands off the details specified in the spec (like VM name, DNS domain, DNS servers) to cloud-init within the guest OS to carry out the customisation making it more reliable and easier to maintain.\nvSphere There are a few places to look if your VMs fail to prep correctly, the first of which is in vSphere itself, when the VMs are cloned if they ever come up with their network disconnected and never get an IP, check the Monitor -\u0026gt; Events tab and see what error occurs here. A successful deployment will have the following in the log (a failed one tells you to check the log in the VM):\n \nIn-guest If you are consistently having VMs come up without networks, either not connected to the port group, or no IP (you shouldn\u0026rsquo;t if you followed the above guide) - throw in your 2c at the following GitHub issue.\nCritically: do not change the open-vm-tools systemd unit file when using cloud-init as the customisation engine (like we are). I got caught up here for days. Don\u0026rsquo;t repeat my mistakes - this advice is everywhere, including in VMware KBs but is ONLY relevant if using the perl scripts, which we aren\u0026rsquo;t.\nThe VMTools customisation log, which handles the handoff of the VMware GOSC spec to cloud-init is located at /var/log/vmware-imc/toolsDeployPkg.log and is very useful if you have customisation problems. I have included a successful log here.\nIf you see Customization command failed: Failed to create bus connection: No such file or directory in the log, GOSC is using perl instead of cloud-init and is likely either because disable_vmware_customisation: false is not in /etc/cloud/cloud.cfg, or, you edited the open-vm-tools systemd unit file to change the startup order as mentioned above.\ncloud-init cloud-init has a number of tools and logs, but the most useful for debugging will be /var/log/cloud-init-output.log it will tell you what modules ran and whether they were successful for not.\nI have found that occasionally, using sudo cloud-init collect-logs and extracting the resulting tar file is very useful for figuring out everything it\u0026rsquo;s doing.\nReferences Some extra stuff that really helped me along the course of this learning exercise:\n https://apple.stackexchange.com/a/229457/314650 https://serverfault.com/a/922051/74265 https://medium.com/@andreidascalu/how-to-test-cloud-init-setup-locally-ae05a2fefcf  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/using-cloud-init-for-vm-templating-on-vsphere/","summary":"This isn\u0026rsquo;t necessarily a follow-on from the other three blogs so far in this series, but more of an alternative to parts one and two. Following on from those I felt that the process could be much more automated, and less \u0026ldquo;ssh into every box and change things manually\u0026rdquo;. After all, the less changes we can make iteratively and imperatively, the more it is programmed or declarative, the better.\nThis blog is one way to do that - I expect to have two or three more methods blogged in the near future that will offer futher options - with a particular focus on day-2.","title":"Using cloud-init for VM templating on vSphere"},{"content":"Using the VCP As of the last part in the series we have a fully up and running k8s cluster with the vSphere Cloud Provider installed! Let\u0026rsquo;s make sure it works and is provisioning storage for us by deploying a StorageClass and a test app.\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   helm - brew install kubernetes-helm  https://helm.sh   kubectl - brew install kubernetes-cli  https://kubernetes.io/docs/tasks/tools/install-kubectl/    vCenter In vCenter you should already have a Storage Policy created for whatever datastore(s) you are using, this can be with richer policy primitives when using vSAN (things like RAID method, numbers of replicas, etc) or if using standard NFS/VMFS datastores, tag-based placement works as well.\nI am using the \u0026ldquo;vSAN Default Storage Policy\u0026rdquo; as below, which does what it says on the tin, is a default policy that infers RAID-1 mirroring and single failure tolerance.\n \nKubernetes Put the below into a new yaml file (i\u0026rsquo;m calling mine vsan-default-storage-policy.yaml) - it will create a new StorageClass in k8s called vsan-default that maps to the vSAN SPBM policy vSAN Default Storage Policy.\nNote the annotation storageclass.kubernetes.io/is-default-class: \u0026quot;true\u0026quot; means that anything deployed that requires a PersistentVolume that doesn\u0026rsquo;t specify a StorageClass will use this one as its fallback. In other words, it\u0026rsquo;s the catch-all.\nkind:StorageClassapiVersion:storage.k8s.io/v1metadata:name:vsan-defaultannotations:storageclass.kubernetes.io/is-default-class:\u0026#34;true\u0026#34;provisioner:kubernetes.io/vsphere-volumeparameters:storagePolicyName:\u0026#34;vSAN Default Storage Policy\u0026#34;datastore:vsanDatastoreApply it to the cluster:\nkubectl create -f vsan-default-storage-policy.yaml Let\u0026rsquo;s deploy a stateful app to test it with, for this to keep things simple, we will use helm (think of it as an application manager, for K8s). Be aware this installation style for helm (granting the tiller pod cluster-admin privileges) is a big security no-no and is just for ease of setup here. For more information on why this is bad, look here, and please don\u0026rsquo;t do this on a production cluster.\nIn this case, it is a throwaway cluster for me, so I will be using these permissions. First create the RBAC role and permissions for the helm service account in another new file called helm-rbac.yaml:\napiVersion:v1kind:ServiceAccountmetadata:name:tillernamespace:kube-system---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:tillerroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:cluster-adminsubjects:- kind:ServiceAccountname:tillernamespace:kube-systemApply the role to the cluster:\n$ kubectl create -f helm-rbac.yaml serviceaccount/tiller created clusterrolebinding.rbac.authorization.k8s.io/tiller created Let\u0026rsquo;s install helm onto the cluster with the service account we provisioned:\n$ helm init --service-account tiller $HELM_HOME has been configured at /Users/mylesgray/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure \u0026#39;allow unauthenticated users\u0026#39; policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! And update helm from the chart repositories\n$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Skip local chart repository ...Successfully got an update from the \u0026#34;incubator\u0026#34; chart repository ...Successfully got an update from the \u0026#34;istio.io\u0026#34; chart repository ...Successfully got an update from the \u0026#34;gitlab\u0026#34; chart repository ...Successfully got an update from the \u0026#34;openfaas\u0026#34; chart repository ...Successfully got an update from the \u0026#34;stable\u0026#34; chart repository Update Complete. ⎈ Happy Helming!⎈ At last, let\u0026rsquo;s deploy the chart for mongodb to test our installation (which will use our default StorageClass we just created)\n$ helm install --name test-mongodb stable/mongodb NAME: test-mongodb LAST DEPLOYED: Sat Jan 26 20:54:53 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Secret NAME TYPE DATA AGE test-mongodb Opaque 1 2s ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-mongodb Pending vsan-default 2s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE test-mongodb ClusterIP 10.98.144.241 \u0026lt;none\u0026gt; 27017/TCP 2s ==\u0026gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE test-mongodb 1 1 1 0 2s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE test-mongodb-646b949fd4-xjxdb 0/1 Pending 0 2s NOTES: ** Please be patient while the chart is being deployed ** MongoDB can be accessed via port 27017 on the following DNS name from within your cluster: test-mongodb.default.svc.cluster.local To get the root password run: export MONGODB_ROOT_PASSWORD=$(kubectl get secret --namespace default test-mongodb -o jsonpath=\u0026#34;{.data.mongodb-root-password}\u0026#34; | base64 --decode) To connect to your database run the following command: kubectl run --namespace default test-mongodb-client --rm --tty -i --restart=\u0026#39;Never\u0026#39; --image bitnami/mongodb --command -- mongo admin --host test-mongodb --authenticationDatabase admin -u root -p $MONGODB_ROOT_PASSWORD To connect to your database from outside the cluster execute the following commands: kubectl port-forward --namespace default svc/test-mongodb 27017:27017 \u0026amp; mongo --host 127.0.0.1 --authenticationDatabase admin -p $MONGODB_ROOT_PASSWORD Check to make sure the PersistentVolume and PersistentVolumeClaim deployed successfully, they should show a status of Bound if they have. (You may need to run this a few times while the volume provisions and gets mounted)\n$ kubectl get pv,pvc NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pvc-64941983-21b5-11e9-b851-005056b9750f 8Gi RWO Delete Bound default/test-mongodb vsan-default 63m NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/test-mongodb Bound pvc-64941983-21b5-11e9-b851-005056b9750f 8Gi RWO vsan-default 63m Monitor the app\u0026rsquo;s deployment and wait for all items to show as Running\n$ kubectl get all NAME READY STATUS RESTARTS AGE pod/test-mongodb-646b949fd4-cz65g 1/1 Running 0 62m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 3h20m service/test-mongodb ClusterIP 10.97.102.136 \u0026lt;none\u0026gt; 27017/TCP 62m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/test-mongodb 1/1 1 1 62m NAME DESIRED CURRENT READY AGE replicaset.apps/test-mongodb-646b949fd4 1 1 1 62m Verify the app works by testing access from the master node by spinning up a client container\n# Export the password set during deployment export MONGODB_ROOT_PASSWORD=$(kubectl get secret --namespace default test-mongodb -o jsonpath=\u0026#34;{.data.mongodb-root-password}\u0026#34; | base64 --decode) # Connect a client container to your server container kubectl run --namespace default test-mongodb-client --rm --tty -i --restart=\u0026#39;Never\u0026#39; --image bitnami/mongodb --command -- mongo admin --host test-mongodb --authenticationDatabase admin -u root -p $MONGODB_ROOT_PASSWORD # Show databases \u0026gt; show dbs admin 0.000GB config 0.000GB local 0.000GB \u0026gt; exit At this stage it is worth installing the kubernetes dashboard as well, for some visibility.\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml Create a user (ServiceAccount) for accessing the UI with a new yaml file called ui-user.yaml (as you can see, I called mine myles)\napiVersion:v1kind:ServiceAccountmetadata:name:mylesnamespace:kube-systemCreate a cluster-role for the user (myles) such that is has cluster-admin privileges - my file is called clusterrolebinding.yaml\napiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:mylesroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:cluster-adminsubjects:- kind:ServiceAccountname:mylesnamespace:kube-systemImport both configs into K8s\nkubectl create -f ui-user.yaml kubectl create -f clusterrolebinding.yaml Notice, we didn\u0026rsquo;t create a password - they are generated automatically by K8S, so let\u0026rsquo;s get the access token for the user we just created (change the grep section from myles in the command to reflect the username you used in ui-user.yaml above) - you will need to copy and paste the token: output from the command.\n$ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep myles | awk \u0026#39;{print $1}\u0026#39;) Name: myles-token-2mkr6 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: myles kubernetes.io/service-account.uid: 95920d01-21c9-11e9-b851-005056b9750f Type: kubernetes.io/service-account-token Data ==== token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJteWxlcy10b2tlbi0ybWtyNiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJteWxlcyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6Ijk1OTIwZDAxLTIxYzktMTFlOS1iODUxLTAwNTA1NmI5NzUwZiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpteWxlcyJ9.YzVRG6Dt_p4_r7Uc7tCAEXjRG8xaB5HqeSO9DdcaXQWf6mqGhH2ahiXI3XdkqOm2725NHEJUsErD8GrJpGYnL_od15Zvxhn1D4VZr3Q3ds-nJ0IK2KS_ArXj3bypO6sjAEBb7bXviuWxge0bLlkurnuLYQSa9lrijHe95AGJnNrDi66Dr1eQoE4deJrjX7Bxm6ef2tikl6lCRA69Q57glQFBQm2aIvOUvR3y5b16vIVMQ6dJcnSE1EjB-G0n0lLRUzPij2nNU7IvmUBEzIbY2jFBxYiY8PEi0sMB2MZSitnW7DbMlZ5Yb8anHsX2XJbixl-VoDkMJuyujzwIc6vs8Q ca.crt: 1025 bytes namespace: 11 bytes Create a proxy session to K8s to access the UI - note: by default, the dashboard is not accessible external to the cluster more detail on how to do that here\nkubectl proxy \u0026amp; Then access the dashboard (details on how to authenticate are available here):\nopen http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ Change the access mode to token and paste in the output we copied above, profit\n \nAt this point you can browse around the K8s dashboard, view the ReplicaSet that helm created for mongodb, view the PersistentVolume created for us automatically from the StorageClass we defined and a lot more.\nFeel free to have a look around, dive back into helm and deploy some more apps!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/kubernetes/using-the-vsphere-cloud-provider-for-k8s-to-dynamically-deploy-volumes/","summary":"Using the VCP As of the last part in the series we have a fully up and running k8s cluster with the vSphere Cloud Provider installed! Let\u0026rsquo;s make sure it works and is provisioning storage for us by deploying a StorageClass and a test app.\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.","title":"Using the vSphere Cloud Provider for K8s to dynamically deploy volumes"},{"content":"Intro In the last installment we created an Ubuntu 18.04 LTS image to use to clone VMs from for spinning up our K8s nodes, we then cloned four VMs out, one as the master and three to be used as workers.\nThis time we are going to step through installing all the necessary K8s components on each of the nodes (kubeadm, kubectl and kubelet), the container runtime (Docker) and configuring the vSphere Cloud Provider for Kubernetes using kubeadm to bootstrap the cluster. We have a lot to cover, so let\u0026rsquo;s get to it!\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   govc - brew tap govmomi/tap/govc \u0026amp;\u0026amp; brew install govmomi/tap/govc  https://github.com/vmware/govmomi/tree/master/govc   kubectl - brew install kubernetes-cli  https://kubernetes.io/docs/tasks/tools/install-kubectl/   tmux (optional) - brew install tmux  https://github.com/tmux/tmux    Optional use of tmux If you want to speed things up and type the same commands to multiple sessions at once (there is going to be a lot or repetition otherwise), use tmux to open a SSH session to each of the IP addresses for your VMs (for more info see here)\ntmux new\\; split-window\\; split-window\\; split-window\\; select-layout even-vertical # Use ctrl b, then the arrow keys to cycle through the tmux panes and SSH to each box independently ssh ubuntu@vm.ip.address.here If you followed my tutuorial last time and all your boxes are named in the k8s* pattern, you can use the below command to get their IP addresses\ngovc find / -type m -name \u0026#39;k8s*\u0026#39; | xargs govc vm.info | grep \u0026#39;Name:\\|IP\u0026#39; Once you have SSH\u0026rsquo;d in to each box independently, you can turn on synchronisation\nctrl b, shift :, set synchronize-panes on I did up a quick asciinema to illustrate setup and use:\n\nSetting up VMs with K8s components On all nodes Install the container runtime (in our case Docker)\n# Install Docker CE # Update the apt package index sudo apt update ## Install packages to allow apt to use a repository over HTTPS sudo apt install ca-certificates software-properties-common apt-transport-https curl -y ## Add Docker’s official GPG key curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - ## Add docker apt repository. sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs)\\ stable\u0026#34; # Install docker ce (latest supported for K8s 1.13 is Docker 18.06) sudo apt update \u0026amp;\u0026amp; sudo apt install docker-ce=18.06.1~ce~3-0~ubuntu -y # Setup daemon parameters, like log rotation and cgroups sudo tee /etc/docker/daemon.json \u0026gt;/dev/null \u0026lt;\u0026lt;EOF { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34; }, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34; } EOF sudo mkdir -p /etc/systemd/system/docker.service.d # Restart docker. sudo systemctl daemon-reload sudo systemctl restart docker Install the K8s components\n# Add the K8s repo to apt curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - echo \u0026#34;deb https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list \u0026gt;/dev/null # Install kubelet, kubectl and kubeadm for cluster spinup sudo apt update sudo apt install kubelet kubeadm kubectl -y # Hold K8s packages at their installed version so as not to upgrade unexpectedly on an apt upgrade sudo apt-mark hold kubelet kubeadm kubectl We will be using flannel for pod networking in this example, so the below needs to be run on all nodes to pass bridged IPv4 traffic to iptables chains:\nsudo sysctl net.bridge.bridge-nf-call-iptables=1 Enabling the VMware vSphere Cloud Provider On the master(s) Create your vsphere.conf file with vCenter details Edit the below command to fill in your vCenter details before running.\nIf you don\u0026rsquo;t have a folder created with your kubernetes node VMs added we can do that quickly with govc (note, change vSAN-DC to your Datacenter name in vCenter):\ngovc folder.create /vSAN-DC/vm/k8s govc object.mv /vSAN-DC/vm/k8s-\\* /vSAN-DC/vm/k8s Details on syntax can be found here. It is important to note, whatever VM folder you specify below needs to be pre-created in your vCenter, in my case the folder is called k8s.\nsudo tee /etc/kubernetes/vsphere.conf \u0026gt;/dev/null \u0026lt;\u0026lt;EOF [Global] user = \u0026#34;administrator@vsphere.local\u0026#34; password = \u0026#34;Admin!23\u0026#34; port = \u0026#34;443\u0026#34; insecure-flag = \u0026#34;1\u0026#34; [VirtualCenter \u0026#34;10.198.17.154\u0026#34;] datacenters = \u0026#34;vSAN-DC\u0026#34; [Workspace] server = \u0026#34;10.198.17.154\u0026#34; datacenter = \u0026#34;vSAN-DC\u0026#34; default-datastore = \u0026#34;vsanDatastore\u0026#34; resourcepool-path = \u0026#34;vSAN-Cluster/Resources\u0026#34; folder = \u0026#34;k8s\u0026#34; [Disk] scsicontrollertype = pvscsi [Network] public-network = \u0026#34;VM Network\u0026#34; EOF Activate the vSphere Cloud Provider in our kubeadm init config file. Additionally, as we are deploying flannel as our overlay network for pods and it requires the below subnet CIDR in order for the overlay to work.\nsudo tee /etc/kubernetes/kubeadminitmaster.yaml \u0026gt;/dev/null \u0026lt;\u0026lt;EOFapiVersion:kubeadm.k8s.io/v1beta1kind:InitConfigurationbootstrapTokens:- groups:- system:bootstrappers:kubeadm:default-node-tokentoken:y7yaev.9dvwxx6ny4ef8vlqttl:0susages:- signing- authenticationnodeRegistration:kubeletExtraArgs:cloud-provider:\u0026#34;vsphere\u0026#34;cloud-config:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;---apiVersion:kubeadm.k8s.io/v1beta1kind:ClusterConfigurationkubernetesVersion:v1.13.3apiServer:extraArgs:cloud-provider:\u0026#34;vsphere\u0026#34;cloud-config:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;extraVolumes:- name:cloudhostPath:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;mountPath:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;controllerManager:extraArgs:cloud-provider:\u0026#34;vsphere\u0026#34;cloud-config:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;extraVolumes:- name:cloudhostPath:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;mountPath:\u0026#34;/etc/kubernetes/vsphere.conf\u0026#34;networking:podSubnet:\u0026#34;10.244.0.0/16\u0026#34;EOFRestart the kubelet daemon to reload the configuration\nsudo systemctl daemon-reload sudo systemctl restart kubelet Initialising the cluster with kubeadm On all nodes Firstly, verify that connectivity to the required gcr.io registries is working by pulling the containers required by kubeadm\n$ sudo kubeadm config images pull [config/images] Pulled k8s.gcr.io/kube-apiserver:v1.13.2 [config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.13.2 [config/images] Pulled k8s.gcr.io/kube-scheduler:v1.13.2 [config/images] Pulled k8s.gcr.io/kube-proxy:v1.13.2 [config/images] Pulled k8s.gcr.io/pause:3.1 [config/images] Pulled k8s.gcr.io/etcd:3.2.24 [config/images] Pulled k8s.gcr.io/coredns:1.2.6 On the master node(s) Initialise kubeadm with the config file from above which includes our vSphere Cloud Provider and Flannel CIDR configurations.\n$ sudo kubeadm init --config /etc/kubernetes/kubeadminitmaster.yaml [init] Using Kubernetes version: v1.13.0 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [10.198.17.177 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [10.198.17.177 127.0.0.1 ::1] [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.198.17.177] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [controlplane] Adding extra host path mount \u0026#34;cloud\u0026#34; to \u0026#34;kube-apiserver\u0026#34; [controlplane] Adding extra host path mount \u0026#34;cloud\u0026#34; to \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [controlplane] Adding extra host path mount \u0026#34;cloud\u0026#34; to \u0026#34;kube-apiserver\u0026#34; [controlplane] Adding extra host path mount \u0026#34;cloud\u0026#34; to \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [controlplane] Adding extra host path mount \u0026#34;cloud\u0026#34; to \u0026#34;kube-apiserver\u0026#34; [controlplane] Adding extra host path mount \u0026#34;cloud\u0026#34; to \u0026#34;kube-controller-manager\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s [apiclient] All control plane components are healthy after 23.503056 seconds [uploadconfig] storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.13\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [patchnode] Uploading the CRI Socket information \u0026#34;/var/run/dockershim.sock\u0026#34; to the Node API object \u0026#34;k8s-master\u0026#34; as an annotation [mark-control-plane] Marking the node k8s-master as control-plane by adding the label \u0026#34;node-role.kubernetes.io/master=\u0026#39;\u0026#39;\u0026#34; [mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: p8iv6v.zu8eofjtbc9r54dd [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstraptoken] creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes master has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of machines by running the following on each node as root: kubeadm join 10.198.17.177:6443 --token p8iv6v.zu8eofjtbc9r54dd --discovery-token-ca-cert-hash sha256:398f667fb3a6ffe6296e4d07c825834b54cce73bacf58641915cf79a1d1895f7 A lot of text will output as it spins up the cluster components, if all is successful, we can start using the cluster now by importing the kubeconfig.\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You can also use it on external systems by copying the output from the below command into your local computer\u0026rsquo;s ~/.kube/config file:\nsudo cat /etc/kubernetes/admin.conf Let\u0026rsquo;s deploy our flannel pod overlay networking so the pods can communicate with each other.\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml Check to make sure the pods are all in the status Running:\n$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-86c58d9df4-fqbdm 1/1 Running 0 2m19s kube-system coredns-86c58d9df4-zhpj6 1/1 Running 0 2m19s kube-system etcd-k8s-master 1/1 Running 0 2m37s kube-system kube-apiserver-k8s-master 1/1 Running 0 68s kube-system kube-controller-manager-k8s-master 1/1 Running 0 2m36s kube-system kube-flannel-ds-amd64-8cst6 1/1 Running 0 26s kube-system kube-proxy-6grkv 1/1 Running 0 2m19s kube-system kube-scheduler-k8s-master 1/1 Running 0 2m36s Export the master node config used to point the workers being joined to the master:\nkubectl -n kube-public get configmap cluster-info -o jsonpath=\u0026#39;{.data.kubeconfig}\u0026#39; \u0026gt; discovery.yaml On your laptop Copy the discovery.yaml to your local machine with scp.\nscp ubuntu@10.198.17.177:~/discovery.yaml discovery.yaml Then upload it to the worker nodes.\nscp discovery.yaml ubuntu@10.198.17.189:~/discovery.yaml scp discovery.yaml ubuntu@10.198.17.190:~/discovery.yaml scp discovery.yaml ubuntu@10.198.17.191:~/discovery.yaml On the worker nodes To check and make sure the discovery.yaml file was copied correctly, do a quick cat.\ncat ~/discovery.yaml Then create the worker node kubeadm config yaml file (notice it\u0026rsquo;s using our discovery.yaml as the input for master discovery) and the token is the same as we put in the master kubeadminitmaster.yaml configuration above and we specify the cloud-provider as vsphere for the workers:\nsudo tee /etc/kubernetes/kubeadminitworker.yaml \u0026gt;/dev/null \u0026lt;\u0026lt;EOFapiVersion:kubeadm.k8s.io/v1alpha3kind:JoinConfigurationdiscoveryFile:discovery.yamltoken:y7yaev.9dvwxx6ny4ef8vlqnodeRegistration:kubeletExtraArgs:cloud-provider:vsphereEOFAnd now we should be able to join our workers to the cluster.\n$ sudo kubeadm join --config /etc/kubernetes/kubeadminitworker.yaml [preflight] Running pre-flight checks [discovery] Trying to connect to API Server \u0026#34;10.198.17.177:6443\u0026#34; [discovery] Created cluster-info discovery client, requesting info from \u0026#34;https://10.198.17.177:6443\u0026#34; [discovery] Requesting info from \u0026#34;https://10.198.17.177:6443\u0026#34; again to validate TLS against the pinned public key [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \u0026#34;10.198.17.177:6443\u0026#34; [discovery] Successfully established connection with API Server \u0026#34;10.198.17.177:6443\u0026#34; [join] Reading configuration from the cluster... [join] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [kubelet] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.13\u0026#34; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Activating the kubelet service [tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap... [patchnode] Uploading the CRI Socket information \u0026#34;/var/run/dockershim.sock\u0026#34; to the Node API object \u0026#34;k8s-worker1\u0026#34; as an annotation This node has joined the cluster: *Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run \u0026#39;kubectl get nodes\u0026#39; on the master to see this node join the cluster. Verify setup Now, as the output says above, back on the master check that all nodes have joined the cluster\nubuntu@k8s-master:~$ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8s-master Ready master 4m44s v1.13.2 10.198.17.177 10.198.17.177 Ubuntu 18.04.1 LTS 4.15.0-43-generic docker://18.6.0 k8s-worker1 Ready \u0026lt;none\u0026gt; 33s v1.13.2 10.198.17.174 \u0026lt;none\u0026gt; Ubuntu 18.04.1 LTS 4.15.0-43-generic docker://18.6.0 k8s-worker2 Ready \u0026lt;none\u0026gt; 32s v1.13.2 10.198.17.175 \u0026lt;none\u0026gt; Ubuntu 18.04.1 LTS 4.15.0-43-generic docker://18.6.0 k8s-worker3 Ready \u0026lt;none\u0026gt; 32s v1.13.2 10.198.17.176 \u0026lt;none\u0026gt; Ubuntu 18.04.1 LTS 4.15.0-43-generic docker://18.6.0 Verify the providerID is set on all the nodes for the VCP to operate correctly:\nubuntu@k8s-master:~$ kubectl describe nodes | grep \u0026#34;ProviderID\u0026#34; ProviderID: vsphere://420f0d85-cf4a-c7a7-e52d-18e9b4b71dec ProviderID: vsphere://420fc2b2-64ab-a477-f7b1-37d4e6747abf ProviderID: vsphere://420f2d75-37bd-8b56-4e2f-421cbcbbb0b2 ProviderID: vsphere://420f7ec3-2dbd-601e-240b-4ee6d8945210 We now have a fully up and running k8s cluster with the vSphere Cloud Provider installed! Check out part 3 where we install the K8s dashboard and show how the integration with the vSphere Cloud Provider really works!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/","summary":"Intro In the last installment we created an Ubuntu 18.04 LTS image to use to clone VMs from for spinning up our K8s nodes, we then cloned four VMs out, one as the master and three to be used as workers.\nThis time we are going to step through installing all the necessary K8s components on each of the nodes (kubeadm, kubectl and kubelet), the container runtime (Docker) and configuring the vSphere Cloud Provider for Kubernetes using kubeadm to bootstrap the cluster.","title":"Setting up K8s and the vSphere Cloud Provider using kubeadm"},{"content":"Intro I have been experimenting a lot over the past 18 months with containers and in particular, Kubernetes, and one of the core things I always seemed to get hung up on was part-zero - creating the VMs to actually run K8s. I wanted a CLI only way to build a VM template for the OS and then deploy that to the cluster.\nIt turns out that with Ubuntu 18.04 LTS (in particular the cloud image OVA) there are a few things need changed from the base install (namely cloud-init) in order to make them play nice with OS Guest Customisation in vCenter.\nThis post is a guide through making those changes.\nPrerequisites Tools I am using macOS, so will be using the brew package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.\nFor each tool I will list the brew install command and the link to the install instructions for other OSes.\n brew  https://brew.sh   Powershell - brew tap caskroom/cask \u0026amp;\u0026amp; brew cask install powershell  https://github.com/PowerShell/PowerShell   PowerCLI - pwsh then Install-Module -Name VMware.PowerCLI -Scope CurrentUser  https://code.vmware.com/web/dp/tool/vmware-powercli   govc - brew tap govmomi/tap/govc \u0026amp;\u0026amp; brew install govmomi/tap/govc  https://github.com/vmware/govmomi/tree/master/govc    Resources We are going to need the Ubuntu 18.04 LTS Cloud image OVA from Canonical\u0026rsquo;s repo downloaded to our local machine in order to extract the OVF specifications from it, the OVA can be found here:\n https://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.ova  Setup With the OVA downloaded, we need to configure a few variables for govc to connect to our vCenter, handily, rather than having to define them on the CLI for every command, we can just export them as variables to our current shell.\nI created a file called govcvars.sh with the following content - create one for yourself filling in the relevant details:\n$ cat govcvars.sh export GOVC_INSECURE=1 # Don\u0026#39;t verify SSL certs on vCenter export GOVC_URL=10.198.17.84 # vCenter IP/FQDN export GOVC_USERNAME=administrator@vsphere.local # vCenter username export GOVC_PASSWORD=Admin\\!23 # vCenter password export GOVC_DATASTORE=vsanDatastore # Default datastore to deploy to export GOVC_NETWORK=\u0026#34;VM Network\u0026#34; # Default network to deploy to export GOVC_RESOURCE_POOL=\u0026#39;*/Resources\u0026#39; # Default resource pool to deploy to Next, we need to load the variables into our current shell session:\nsource govcvars.sh At this point we should be able to connect to and query our vCenter:\n$ govc about Name: VMware vCenter Server Vendor: VMware, Inc. Version: 6.7.0 Build: 10244857 OS type: linux-x64 API type: VirtualCenter API version: 6.7.1 Product ID: vpx UUID: 1bd33d4e-555f-4d8b-9b77-8d155f612155 Building the image Extract the OVF spec from the OVA Use govc to pull the OVF spec from the Ubuntu OVA we just downloaded, for customisation (this will output the spec to a file in your current directory called ubuntu.json):\ngovc import.spec ~/Downloads/ubuntu-18.04-server-cloudimg-amd64.ova | python -m json.tool \u0026gt; ubuntu.json Customise the OVF spec I changed hostname, public-keys, Password, Network and Name. It is necessary to set public-keys as Ubuntu cloud images (which the OVAs are) only allow SSH key auth from first-boot - no password-only auth.\nYou can get your SSH public key by running cat ~/.ssh/id_rsa.pub - note if you run this command and you don\u0026rsquo;t get an output - you probably need to generate an SSH key with ssh-keygen.\n$ cat ubuntu.json { \u0026#34;DiskProvisioning\u0026#34;: \u0026#34;thin\u0026#34;, \u0026#34;IPAllocationPolicy\u0026#34;: \u0026#34;dhcpPolicy\u0026#34;, \u0026#34;IPProtocol\u0026#34;: \u0026#34;IPv4\u0026#34;, \u0026#34;PropertyMapping\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;instance-id\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;id-ovf\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;hostname\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;Ubuntu1804Template\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;seedfrom\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;public-keys\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;ssh-rsa [[[[[YOUR PUBLIC KEY]]]] mylesg@vmware.com\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;user-data\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;VMware1!\u0026#34; } ], \u0026#34;NetworkMapping\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;VM Network\u0026#34;, \u0026#34;Network\u0026#34;: \u0026#34;VM Network\u0026#34; } ], \u0026#34;MarkAsTemplate\u0026#34;: false, \u0026#34;PowerOn\u0026#34;: false, \u0026#34;InjectOvfEnv\u0026#34;: false, \u0026#34;WaitForIP\u0026#34;: false, \u0026#34;Name\u0026#34;: \u0026#34;Ubuntu1804Template\u0026#34; } Deploy the OVA Deploy the OVA with the customised OVF spec (you can pass the OVA URL to the below command instead of the file on your system, but it will first download to your local computer, then upload to the vCenter, it doesn\u0026rsquo;t hand off the download operation so is no faster).\ngovc import.ova -options=ubuntu.json ~/Downloads/ubuntu-18.04-server-cloudimg-amd64.ova Change the VM size to 4 vCPUs, 4GB RAM, 60GB disk and set the disk.enableUUID=1 flag (needed for disk identification from the vSphere Cloud Provider in Kubernetes)\ngovc vm.change -vm Ubuntu1804Template -c 4 -m 4096 -e=\u0026#34;disk.enableUUID=1\u0026#34; govc vm.disk.change -vm Ubuntu1804Template -disk.label \u0026#34;Hard disk 1\u0026#34; -size 60G Power on the VM\ngovc vm.power -on=true Ubuntu1804Template Customise the VM for templating Get the VM\u0026rsquo;s IP address in order to SSH to it:\n$ watch -n 10 govc vm.info Ubuntu1804Template Name: Ubuntu1804Template Path: /vSAN-DC/vm/Discovered virtual machine/Ubuntu1804Template UUID: 42392966-8d21-ceda-5f23-28584c18703b Guest name: Ubuntu Linux (64-bit) Memory: 1024MB CPU: 2 vCPU(s) Power state: poweredOn Boot time: 2019-01-25 18:28:21.978093 +0000 UTC IP address: 10.198.17.85 Host: 10.198.17.31 SSH to the new guest VM (should auth automatically as you put in your SSH key above in the OVF spec) - you will be prompted to change your password:\nssh ubuntu@10.198.17.85 SSH to the box again to re-auth and update apt\nssh ubuntu@10.198.17.85 sudo apt update sudo apt install open-vm-tools -y sudo apt upgrade -y sudo apt autoremove -y We are going to disable cloud-init and instead rely on VMware Guest Customisation specs:\n# cleans out all of the cloud-init cache, disable and remove cloud-init customisations sudo cloud-init clean --logs sudo touch /etc/cloud/cloud-init.disabled sudo rm -rf /etc/netplan/50-cloud-init.yaml sudo apt purge cloud-init -y sudo apt autoremove -y We have to disable a few startup params and adjust the open-vm-tools startup order to allow customisation to work:\n# Don\u0026#39;t clear /tmp sudo sed -i \u0026#39;s/D \\/tmp 1777 root root -/#D \\/tmp 1777 root root -/g\u0026#39; /usr/lib/tmpfiles.d/tmp.conf # Remove cloud-init and rely on dbus for open-vm-tools sudo sed -i \u0026#39;s/Before=cloud-init-local.service/After=dbus.service/g\u0026#39; /lib/systemd/system/open-vm-tools.service Cleanup the VM for templating\n# cleanup current ssh keys so templated VMs get fresh key sudo rm -f /etc/ssh/ssh_host_* # add check for ssh keys on reboot...regenerate if neccessary sudo tee /etc/rc.local \u0026gt;/dev/null \u0026lt;\u0026lt;EOL #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will \u0026#34;\u0026#34; on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. test -f /etc/ssh/ssh_host_dsa_key || dpkg-reconfigure openssh-server exit 0 EOL # make the script executable sudo chmod +x /etc/rc.local # cleanup apt sudo apt clean # reset the machine-id (DHCP leases in 18.04 are generated based on this... not MAC...) echo \u0026#34;\u0026#34; | sudo tee /etc/machine-id \u0026gt;/dev/null # disable swap for K8s sudo swapoff --all sudo sed -ri \u0026#39;/\\sswap\\s/s/^#?/#/\u0026#39; /etc/fstab # cleanup shell history and shutdown for templating history -c history -w sudo shutdown -h now Mark the VM as a template Mark the VM as a template to so you can clone from it in vSphere:\ngovc vm.markastemplate Ubuntu1804Template Define a VM Guest Customisation spec VM Guest Customisation specs can\u0026rsquo;t be created from govc right now see here for details - I have submitted some documentation for this features, so hopefully in future we won\u0026rsquo;t need PowerShell or PowerCLI at all.\nStart up PowerShell and create a guest customisation spec\npwsh \u0026gt; Connect-VIServer 10.198.17.160 -User administrator@vsphere.local -Password Admin!23 \u0026gt; New-OSCustomizationSpec -Name Ubuntu -OSType Linux -DnsServer 10.198.16.1,10.198.16.2 -DnsSuffix satm.eng.vmware.com -Domain satm.eng.vmware.com -NamingScheme vm Name Description Type  OSType LastUpdate Server ---- ----------- ---- ------ ---------- ------ Ubuntu Persistent Linux 27/01/2019 21:43:40 10.198.17.160 \u0026gt; exit Deploy some clones Clone the Kubernetes VMs from this template using the Ubuntu customisation spec we just defined in order to customise the VM name, domain, DNS, etc.\ngovc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-master govc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-worker1 govc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-worker2 govc vm.clone -vm Ubuntu1804Template -customization=Ubuntu k8s-worker3 In a new terminal, watch for the VM IP addresses (refreshes every 30 seconds):\nwatch -n 30 \u0026#34;govc find / -type m -name \u0026#39;k8s*\u0026#39; | xargs govc vm.info | grep \u0026#39;Name:\\|IP\u0026#39;\u0026#34; End That\u0026rsquo;s it - you now have a base Ubuntu 18.04 LTS Cloud template to clone from - and as a bonus we\u0026rsquo;ve deployed four VMs from it for use in a Kubernetes cluster as part of the next chapter!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/kubernetes/creating-an-ubuntu-18-04-lts-cloud-image-for-cloning-on-vmware/","summary":"Intro I have been experimenting a lot over the past 18 months with containers and in particular, Kubernetes, and one of the core things I always seemed to get hung up on was part-zero - creating the VMs to actually run K8s. I wanted a CLI only way to build a VM template for the OS and then deploy that to the cluster.\nIt turns out that with Ubuntu 18.04 LTS (in particular the cloud image OVA) there are a few things need changed from the base install (namely cloud-init) in order to make them play nice with OS Guest Customisation in vCenter.","title":"Creating an Ubuntu 18.04 LTS cloud image for cloning on VMware"},{"content":"I had a question last week from Bozo Popovic during our EMEA field SE training session on vSAN operations relating to SPBM support for service providers that use vCloud Director in their environments.\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  Next up Mr. @mylesagray giving a #vSAN operations overview to our EMEA field at the @vmwarevsan workshop this morning pic.twitter.com/48seQc8i7d\n\u0026mdash; Cormac Hogan (@CormacJHogan) November 30, 2017 I am stating this for clarity - since the vCD 9.0 release we have supported native SPBM compatibility for vCloud Director. SPBM policies can be adopted into vCD and assigned to PVDCs and to tenants via Org VDCs.\nWithin vCenter you create your SPBM policies as normal, you can see in my lab I have two vSAN policies: vSAN Default Storage Policy and vSAN High Throughput.\n \nMoving to vCloud Director then, navigate to Manage \u0026amp; Monitor -\u0026gt; vSphere Resources -\u0026gt; Storage Policies and you will see your SPBM policies available listed here.\n \nThis is an obvious departure from the previous architecture of vCD datastores where tags were assigned to datastores and objects were placed directly on to them, as vSAN is a single datastore vCD required the awareness that objects on the same datastore could have different storage policies.\nTo assign resources to a PVDC in order to allow tenants access to the resource you need to navigate to Manage \u0026amp; Monitor -\u0026gt; Cloud Resources -\u0026gt; Provider VDCs -\u0026gt; {Your PVDC} -\u0026gt; Storage Policies.\n \nFrom here you click on the green + icon and select the relevant SPBM policy available in vCenter to have it utilised by the Provider VDC. You can now allocate this SPBM policy to the tenant Org VDCs that are children of the Provider VDC. Again, navigate to the Org VDC and go to the Storage Policies tab and click the green + icon to move a policy into the Org VDC for consumption by the tenant.\n \nAt this point the tenant can configure VMs with disparate SPBM policies for individual disks/the whole VM if they wish, during their provisioning cycle, or retrospectively change policies via the VM properties window in vCloud Director.\n \nThis includes changing from a traditional tag-based datastore to a vSAN based SPBM policy, which will automatically kick off a Storage vMotion in the background for that resource.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/cloud/vsan-spbm-vcloud-director/","summary":"I had a question last week from Bozo Popovic during our EMEA field SE training session on vSAN operations relating to SPBM support for service providers that use vCloud Director in their environments.\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  Next up Mr. @mylesagray giving a #vSAN operations overview to our EMEA field at the @vmwarevsan workshop this morning pic.","title":"vSAN SPBM and vCloud Director"},{"content":"After deploying a vSAN cluster, the need sometimes arises to make changes to its network configuration, such as migrating the vmkernel network of the cluster to a new subnet. This requirement may appear for example when changing the network in which the vSAN cluster is running, or even, in a more complex scenario such as when a standalone vSAN needs to be converted to a stretched cluster.\nIn these sorts of situations, complications may be encountered if the subnet in use for the vSAN vmkernel ports cannot be routed to the network as a whole, as it is in use elsewhere in the organization, and is currently isolated in an L2 segment. In this situation, the only option is to migrate hosts into a different subnet to achieve to a stretched cluster architecture. This requirement comes to the surface as it is necessary for the vSAN vmkernel ports to have routable access to the witness VM on a separate site, as such, L2 isolated segments are not appropriate.\nIn this post, we will examine some of the networking implications that may arise if you need to make changes to an existing cluster, such as when converting a standalone vSAN cluster into a stretched cluster configuration, or when migrating a vSAN to a new subnet.\nThere have been a few questions around how one would migrate from an isolated subnet to another subnet without requiring application downtime; the answer is quite simple. VMware supports running two vSAN vmkernel ports simultaneously on a vSAN cluster, as long as the subnets are disparate - It is essential, however, to distinguish between a configuration with multiple discrete vSAN vmkernel ports on separate subnets and multiple vSAN vmkernel ports on the same subnet, the latter of which is not supported.\nIt is advisable before you carry out the changes that isolation addresses for the stretched cluster\u0026rsquo;s HA mechanism are put in place. Read more on using vSAN with vSphere HA here.\nIf you are utilizing a VDS for network connectivity, it is recommended that you first add a new vmkernel port into the VDS for the new subnet that is routable throughout your infrastructure and tag it for the vSAN service. If you are using a VSS instead, you can add each new vmkernel interface manually. It is a good idea to verify connectivity from host-to-host using vmkping over the newly created vSAN vmkernel port before enacting any changes.\nIt is possible to verify the vmkernel ports that a host is using for vSAN by entering the command line on the hosts and running:\nesxcli vsan network list The test setup in this example is as follows:\n10.0.1.0/24 - Old unroutable vSAN network 10.198.16.0/20 - New routable vSAN network vmk1 - Old vSAN vmkernel port vmk8 - New vSAN vmkernel port Below you can see the new interface we will be migrating all hosts to (h1-h6) is vmk8 and in the 10.198.16.0/20 subnet and the old interface vmk1 with associated subnet 10.0.1.0/24.\n \nIn the example below, vmk8 is the newly created vmkernel port on host h1 and 10.198.16.241 is the new vmkernel interface tagged with vSAN traffic on host h2.\n[root@h1:~] vmkping -I vmk8 10.198.16.241 PING 10.198.16.241 (10.198.16.241): 56 data bytes 64 bytes from 10.198.16.241: icmp_seq=0 ttl=64 time=0.106 ms 64 bytes from 10.198.16.241: icmp_seq=1 ttl=64 time=0.099 ms You can check connectivity from each host to every other host if you wish to verify connectivity on this new vmkernel interface throughout the cluster.\nNow that the networking infrastructure is in place, we can proceed to begin the migration of hosts into a stretched cluster configuration and alter the required network settings.\nPut the first host in the cluster into maintenance mode (in our case, host h1) selecting “Ensure data accessibility” or “Full data evacuation” as you see fit. In this example, I am using “Ensure data accessibility” as the hosts will be returning quickly after the changes are made.\n \nOnce the host has successfully entered maintenance mode - navigate to Configure -\u0026gt; Networking -\u0026gt; VMkernel Adapters in the vSphere Web Client, select the old vmkernel interface (in our case, as listed above, this is vmk1) and delete it, confirm the deletion when prompted.\n \nSelect the host again and exit maintenance mode, at this point if you wish you can verify vSAN Object Health in the Health UI by navigating to the cluster, then Monitor -\u0026gt; vSAN -\u0026gt; Health and run a Retest.\nAll objects should be in the “Healthy” state at this point, note; you may see some alerts in the Health UI. In particular, relating to vSAN unicast checks from the migrated host(s) to the pending hosts’ old vSAN vmkernel ports, this alert is expected as that subnet is not routable - vSAN traffic will still flow via the new vmkernel ports created earlier.\n \nWith that process defined for one host, you can now “walk” all other hosts in the cluster into the new subnet, by repeating the above steps for every host. The steps can be summarized as so:\n Put host into maintenance mode Specify your preferred data evacuation mode Allow host to enter maintenance mode fully Remove original vSAN vmkernel port Take host out of maintenance mode  Once all hosts in the cluster have been migrated in this fashion, recheck the vSAN Health UI and run a Retest, this time all checks should come back “Healthy” as we have removed all the old vmkernel ports from the hosts.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/migrating-vsan-vmkernel-ports-new-subnet/","summary":"After deploying a vSAN cluster, the need sometimes arises to make changes to its network configuration, such as migrating the vmkernel network of the cluster to a new subnet. This requirement may appear for example when changing the network in which the vSAN cluster is running, or even, in a more complex scenario such as when a standalone vSAN needs to be converted to a stretched cluster.\nIn these sorts of situations, complications may be encountered if the subnet in use for the vSAN vmkernel ports cannot be routed to the network as a whole, as it is in use elsewhere in the organization, and is currently isolated in an L2 segment.","title":"Migrating vSAN vmkernel ports to a new subnet"},{"content":"I was recently rebuilding part of my lab infrastructure, and as part of it, I wanted to migrate my vCD cells from two IPs each to a single IP (as this feature was added in vCD 8.10) for both the web UI and the console proxy.\nIt simplifies provisioning, potential routing problems, and load-balancer configuration by having a single IP but separate ports for each service. Adding both services to a single IP is not new, Tomas Fjota wrote about it here, however, there was some detail missing from his article to allow it to work behind a load-balancer.\nSo, first up I am going to assume you already have both your vCD cells up and operational as from the install guide. Now we are going to quiesce the cells and shut them down:\ncd /opt/vmware/vcloud-director/bin/ ./cell-management-tool -u administrator cell --quiesce true ./cell-management-tool -u administrator cell --shutdown Now we need to edit the global.properties file:\nnano /opt/vmware/vcloud-director/etc/global.properties In here we will change the existing lines:\nvcloud.cell.ip.primary = 10.0.3.229 consoleproxy.host.https = 10.0.3.231 To the same IP as each other:\nvcloud.cell.ip.primary = 10.0.3.229 consoleproxy.host.https = 10.0.3.229 And add the following to the bottom of the file (insert your external load-balanced address for the last property):\nconsoleproxy.port.https = 8443 vcloud.http.port.standard = 80 vcloud.http.port.ssl = 443 consoleproxy.external.address = vcd-prx.mylesgray.io:8443 You might be wondering about the consoleproxy.external.address property, you can set the console address in the vCD UI - so why add it here, right? Because if you try to add it in the UI, you get this error:\n \nHowever, if we add it in our global.properties file, then restart the cells we can avoid the UI based checks, the cell will start up and bind the console proxy to this port.\nStartup the cells again:\nservice vmware-vcd start You should see two ports bound to the same address if you run netstat:\n[root@vcd01 ~]# netstat -tlpn | grep java | grep 443 tcp 0 0 ::ffff:10.0.3.229:8443 :::* LISTEN 16190/java tcp 0 0 ::ffff:10.0.3.229:443 :::* LISTEN 16190/java If you check in the UI, it will now list the console proxy address as what we put in global.properties, even though the UI would not let us do this:\n \nNow, if you log in as a tenant and launch a console, then right click anywhere and hit \u0026ldquo;Inspect\u0026rdquo; you should see the console calls to the WebSocket on TCP/8443 as we configured:\n \nA final note on load-balancer configuration across cells - I run a Kemp LB and have two separate virtual services running, one for each port. Both services were required to be in L7 SSL-offload/termination mode and were configured to re-encrypt traffic to the backend cells for console proxy sessions to establish successfully:\n \nAlso noteworthy, HTTP headers cannot be used for session persistence on the console proxy virtual service as these are raw TCP streams, not HTTPS/HTTP. Attempting to use HTTP headers for session persistence or traffic redirection will cause the TCP socket establishment to fail.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/cloud/vcloud-director-console-proxy-ui-single-ip/","summary":"I was recently rebuilding part of my lab infrastructure, and as part of it, I wanted to migrate my vCD cells from two IPs each to a single IP (as this feature was added in vCD 8.10) for both the web UI and the console proxy.\nIt simplifies provisioning, potential routing problems, and load-balancer configuration by having a single IP but separate ports for each service. Adding both services to a single IP is not new, Tomas Fjota wrote about it here, however, there was some detail missing from his article to allow it to work behind a load-balancer.","title":"vCloud Director console proxy and UI on a single interface"},{"content":"I had a power outage recently that took out my entire lab in a very ungraceful manner - everything, well mostly everything, came back up without a hitch - but NSX was acting a bit weird, so I decided to redeploy the NSX Controllers.\nI removed all 3 controllers and tried redeploying but ended up with the error \u0026ldquo;No IPs left in pool NSX-Controllers\u0026rdquo;. If you\u0026rsquo;re familiar with NSX, then you know when creating both controllers and VTEPs you\u0026rsquo;re required to configure IP Pools in NSX Manager to allocate IP addresses from.\nWhat has happened in this instance is, I removed the controllers, but for some reason, NSX Manager was not made aware of these changes and now the IPs are showing as used when in fact they\u0026rsquo;re free - hence, orphaned.\nI went API diving and found this could be resolved with a few calls in POSTman - if you don\u0026rsquo;t fancy the API PDF in its 450-page glory, I recommend running Platypus in Docker on your workstation, or you can access a hosted version here.\nIt provides a Swagger instance for a nice overview of the available APIs and their responses:\n \nSo, let\u0026rsquo;s get down to it - you want to query the IPPool IDs on your instance:\nGET https://{{nsxmanagerIP}}/api/2.0/services/ipam/pools/scope/globalroot-0 Then from the response body, we want the objectId associated with the NSX-Controllers IP Pool object:\n\u0026lt;ipamAddressPools\u0026gt; \u0026lt;ipamAddressPool\u0026gt; \u0026lt;objectId\u0026gt;ipaddresspool-1\u0026lt;/objectId\u0026gt; \u0026lt;objectTypeName\u0026gt;IpAddressPool\u0026lt;/objectTypeName\u0026gt; \u0026lt;vsmUuid\u0026gt;421190C6-9A73-BBBC-B646-11767FC2B08D\u0026lt;/vsmUuid\u0026gt; \u0026lt;nodeId\u0026gt;532eeed7-4e72-419b-84a2-6e9c212e1810\u0026lt;/nodeId\u0026gt; \u0026lt;revision\u0026gt;1\u0026lt;/revision\u0026gt; \u0026lt;type\u0026gt; \u0026lt;typeName\u0026gt;IpAddressPool\u0026lt;/typeName\u0026gt; \u0026lt;/type\u0026gt; \u0026lt;name\u0026gt;NSX-Controllers\u0026lt;/name\u0026gt; ...... From this, we can query the \u0026ldquo;active\u0026rdquo; IP addresses in the pool (though you probably know these already):\nGET https://{{nsxmanagerIP}}/api/2.0/services/ipam/pools/ipaddresspool-1/ipaddresses And then we can delete each offending IP:\nDELETE https://{{nsxmanagerIP}}/api/2.0/services/ipam/pools/ipaddresspool-1/ipaddresses/10.0.3.170 If successful you should now be able to re-deploy your controllers with the IP Pool as before and see the following output in POSTman for each DELETE:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;boolean\u0026gt;true\u0026lt;/boolean\u0026gt; Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/removing-orphaned-ips-nsx-using-rest-api/","summary":"I had a power outage recently that took out my entire lab in a very ungraceful manner - everything, well mostly everything, came back up without a hitch - but NSX was acting a bit weird, so I decided to redeploy the NSX Controllers.\nI removed all 3 controllers and tried redeploying but ended up with the error \u0026ldquo;No IPs left in pool NSX-Controllers\u0026rdquo;. If you\u0026rsquo;re familiar with NSX, then you know when creating both controllers and VTEPs you\u0026rsquo;re required to configure IP Pools in NSX Manager to allocate IP addresses from.","title":"Removing orphaned IPs from NSX using REST API"},{"content":"Over the last 9 months, a lot has happened in my life; I have a nice titanium plate in my shoulder now courtesy of a major car accident. I changed roles at Novosco from Infrastructure Engineer to Cloud Technologist - focusing more on R\u0026amp;D and emerging platforms, and I helped out Frank Denneman and Niels Hagoort in editing their best-selling vSphere 6.5 Host Deep Dive book.\nThrough the course of the time off I had as a result of now being part-Iron Man, it gave me a lot of time to think about what\u0026rsquo;s important to me and what I enjoy, as I\u0026rsquo;m sure most people do every few years. Though my role at Novosco had evolved and I had learned a great deal and met some awesome people, I felt I needed a new challenge, something to keep me engaged and learning.\nAfter a few years in the customer space, then 3 years with Novosco - a VAR, ISV, and MSP, I am making the move to a vendor. This seemed somewhat inevitable to me as the only place to go when you want to keep learning is to the people at the forefront of creating what it is you are consistently learning about. Being able to shape future iterations of products that many organisations use is an exhilarating prospect.\nAnd with that - I\u0026rsquo;m proud to say I\u0026rsquo;m joining some of the industry greats; Jase McCarty, John Nicholson, Pete Flecha, Jeff Hunter, Pete Koehler and of course their wrangler, Ken Werneberg. In the place that forged the giants of Cormac Hogan, Duncan Epping, Frank Denneman and Rawlinson Rivera.\nHello, VMware, SABU and my new role as Senior Technical Marketing Architect!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/customer-partner-vendor/","summary":"Over the last 9 months, a lot has happened in my life; I have a nice titanium plate in my shoulder now courtesy of a major car accident. I changed roles at Novosco from Infrastructure Engineer to Cloud Technologist - focusing more on R\u0026amp;D and emerging platforms, and I helped out Frank Denneman and Niels Hagoort in editing their best-selling vSphere 6.5 Host Deep Dive book.\nThrough the course of the time off I had as a result of now being part-Iron Man, it gave me a lot of time to think about what\u0026rsquo;s important to me and what I enjoy, as I\u0026rsquo;m sure most people do every few years.","title":"Customer, Partner, Vendor."},{"content":"Over the last 6-9 months, I have been reviewing the vast majority of a new book just released to print by Frank Denneman and Niels Hagoort - The vSphere 6.5 Host Resources Deep Dive.\n \nThis book is, without a doubt, the most in-depth look at host design I have ever read, we are not talking about standard best practices here, though those are in there too. More, low-level understanding of why best practices exist and even challenging some existing perceptions and paradigms about why technologies should be used and more importantly, how they should be utilised.\nThe blurb from the book does speak for itself, and I have to tell you - I learned a lot reading this book - about how CPUs work, QPI speeds, high/low core count procs, non-local memory access, right down to on-die cache snooping protocols. How storage protocols, drivers and busses work as well as the vmkernel level tuning of all four components of host resourcing.\n This book explains the concepts and mechanisms behind the physical resource components and the VMkernel resource schedulers, which enables you to:\n Optimize your workload for current and future Non-Uniform MemoryAccess (NUMA) systems. Discover how vSphere Balanced Power Management takes advantage of the CPU Turbo Boost functionality, and why High Performance does not. How the 3-DIMMs per Channel configuration results in a 10-20% performance drop. How TLB works and why it is bad to disable large pages in virtualized environments. Why 3D XPoint is perfect for the vSAN caching tier. What queues are and where they live inside the end-to-end storage data paths. Tune VMkernel components to optimize performance for VXLAN network traffic and NFV environments. Why Intel\u0026rsquo;s Data Plane Development Kit significantly boosts packet processing performance.   This book is a bit of a monster. It comes in at almost 600 pages and it is going to take you a while to absorb all of its content - but it does convey the information clearly in a logical manner that can be easily understood, and that\u0026rsquo;s what you want from highly technical content like this. The diagrams are excellent and easy to follow - the guys have outdone themselves here, and complex concepts or topics are broken down into easy to manage sections.\nSo get out there and buy it, I cannot recommend it enough, buy some for your team - whatever, just go forth, and learn!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/vsphere-6-5-host-resources-deep-dive/","summary":"Over the last 6-9 months, I have been reviewing the vast majority of a new book just released to print by Frank Denneman and Niels Hagoort - The vSphere 6.5 Host Resources Deep Dive.\n \nThis book is, without a doubt, the most in-depth look at host design I have ever read, we are not talking about standard best practices here, though those are in there too. More, low-level understanding of why best practices exist and even challenging some existing perceptions and paradigms about why technologies should be used and more importantly, how they should be utilised.","title":"vSphere 6.5 Host Resources Deep Dive"},{"content":"Out of morbid curiosity (and lack of IPv4 public address space available to me), I decided I wanted to enable IPv6 in my lab. However, before taking the plunge there, I would try it out on my residential ADSL line, I use the same brand of firewall there as in my lab so the experience should be largely transferable.\nSo for a bit of context; I have a Zen Internet ADSL line (I saw the fiber van around the cabinet recently so maybe that will change) - auth to the provider is done via PPPoE on IPv4.\nI had a hell of a time getting this working. Otherwise, it would not be a blog post, so let\u0026rsquo;s get right into the config snippets.\nI am going to assume you have your IPv4 internet line already configured with PPPoE and that it is working, so all we do here is retrofit the IPv6 portion. Zen send you an email with your IPv6 details for your account like the below:\n \nYou only care about the PD Prefix portion as the ND Prefix portion is issued to your WAN interface automatically by SLAAC once you set address mode to PPPoE.\nLog into your Fortigate with SSH and enter the vdom context you are using then edit the WAN interface:\nconfig system interface edit \u0026#34;wan1\u0026#34; config ipv6 set ip6-mode pppoe set ip6-allowaccess ping set dhcp6-prefix-delegation enable set dhcp6-prefix-hint 2a02:xxxx:yyyy::/48 set autoconf enable end next end A breakdown of the above:\n set ipv6-mode pppoe - Tells the unit to grab an address via pppoe (this is issued automatically and is within the ND Prefix from the email). set ip6-allowaccess ping - Simply, allow ping access on WAN. set dhcp6-prefix-delegation enable - This tells the Fortigate to accept DHCPv6 prefix delegation (essentially how IPv6 addresses are issued by ISPs to non-edge devices). set dhcp6-prefix-hint 2a02:xxxx:yyyy::/48 - This is the PD Prefix from the email/issued by your provider set autoconf enable - Allow configuration of interface address automatically via SLAAC  Next up we need to take care of the LAN side, this is where the majority of the problems I had laid, mainly because I was blindly copying the Fortigate documentation without thinking about what the parameters did.\nconfig system interface edit \u0026#34;internal\u0026#34; config ipv6 set ip6-mode delegated set ip6-allowaccess ping https ssh snmp set ip6-send-adv enable set ip6-manage-flag enable set ip6-upstream-interface \u0026#34;wan1\u0026#34; set ip6-subnet ::1/64 config ip6-delegated-prefix-list edit 1 set upstream-interface \u0026#34;wan1\u0026#34; set autonomous-flag enable set onlink-flag enable set subnet ::/64 next end end next end Again, a breakdown of the above (note none of the LAN config has been nulled, it works as-is):\n set ip6-mode delegated - Tells the interface to get its IP via protocol delegation set ip6-allowaccess ping https ssh snmp - Allows access to the firewall via these protocols set ip6-send-adv enable - Allow IPv6 routing advertisements to be sent from this interface. set ip6-manage-flag enable - Required to tell end devices to receive IPv6 addresses via DHCPv6 and not SLAAC (more info) set ip6-upstream-interface \u0026quot;wan1\u0026quot; - This informs the Fortigate from what interface it should have its address delegated set ip6-subnet ::1/64 - Tells the interface to take the first address in the delegated /64  We then need to configure a delegated prefix list - this is used to hand out addresses via DHCPv6 on this interface:\n config ip6-delegated-prefix-list - Enter context command edit 1 - You can have multiple prefix lists, but we just use one here set upstream-interface \u0026quot;wan1\u0026quot; - As above, tells the list where to have its addresses delegated from set autonomous-flag enable - Allows clients to construct their global IPv6 address from their 64-bit interface identifier with the prefix scope provided in the RA set onlink-flag enable - Treat the prefix in the RA as \u0026ldquo;on-link\u0026rdquo;/L2 connected (typically only link-local FE80 addresses) set subnet ::/64 - Use the first /64 in the /48 prefix for address allocation  Now that we have the interfaces set up we need to configure our DHCPv6 server:\nconfig system dhcp6 server edit 1 set interface \u0026#34;internal\u0026#34; set upstream-interface \u0026#34;wan1\u0026#34; set ip-mode delegated set dns-server1 2001:4860:4860::8888 set dns-server2 2001:4860:4860::8844 next end A line-by-line breakdown is unnecessary at this stage. Firstly, we enter the dhcp6 server context and create a single entry, we tell the DHCP server to listen on the internal interface and to use wan1 as it is upstream interface for addresses and to operate in delegated mode as in the other config portions.\nThe only real difference here is the DNS servers; I have the Fortigate advertise the Google IPv6 DNS servers with the DHCP advertisements it sends.\nYou now need to reboot your firewall (I am not joking, seriously, it does not work otherwise).\nA little testing to see what\u0026rsquo;s happening (note: the only interfaces we care about getting global IPv6 addresses are ppp1 and internal):\n# diag ipv6 address list dev=18 devname=internal flag=P scope=0 prefix=64 addr=2a02:xxxx:yyyy::1 dev=23 devname=ppp1 flag= scope=0 prefix=64 addr=2a02:wwww:zzzz:aaa::1 preferred=1736 valid=17936 The ppp1 interface should have an address from the ND Prefix given to you by your provider - this is, as mentioned before, completely automatic.\nThe internal interface should have an address from the PD Prefix given to you by the provider - as you can see above it has the first interface in the /64 as we defined in the config; addr=2a02:xxxx:yyyy::1.\nA quick ping6 to Google:\n# exec ping6 ipv6.google.com PING ipv6.google.com(2a00:1450:4009:811::200e) 56 data bytes 64 bytes from 2a00:1450:4009:811::200e: icmp_seq=1 ttl=58 time=20.9 ms 64 bytes from 2a00:1450:4009:811::200e: icmp_seq=2 ttl=58 time=21.0 ms 64 bytes from 2a00:1450:4009:811::200e: icmp_seq=3 ttl=58 time=21.2 ms 64 bytes from 2a00:1450:4009:811::200e: icmp_seq=4 ttl=58 time=21.1 ms 64 bytes from 2a00:1450:4009:811::200e: icmp_seq=5 ttl=58 time=21.7 ms --- ipv6.google.com ping statistics --- 5 packets transmitted, 5 packets received, 0% packet loss, time 4038ms rtt min/avg/max/mdev = 20.968/21.234/21.777/0.317 ms Now configure some firewall policies remember IPv6 requires no NAT at all, ever. I am enabling all traffic outbound and all ICMPv6 inbound:\nconfig firewall policy6 edit 1 set name \u0026#34;Default out\u0026#34; set srcintf \u0026#34;internal\u0026#34; set dstintf \u0026#34;wan1\u0026#34; set srcaddr \u0026#34;all\u0026#34; set dstaddr \u0026#34;all\u0026#34; set action accept set schedule \u0026#34;always\u0026#34; set service \u0026#34;ALL\u0026#34; set logtraffic all next edit 2 set name \u0026#34;Allow ICMP in\u0026#34; set srcintf \u0026#34;wan1\u0026#34; set dstintf \u0026#34;internal\u0026#34; set srcaddr \u0026#34;all\u0026#34; set dstaddr \u0026#34;all\u0026#34; set action accept set schedule \u0026#34;always\u0026#34; set service \u0026#34;ALL_ICMP6\u0026#34; set logtraffic all next end All good! Now you should be able to access ipv6-test.com from your browser and have all tests pass, and you see your local computer\u0026rsquo;s IPv6 address.\n \nJust for giggles, I set up blah.cloud as dual-stack, so a quick dig command from our local workstation:\nmyles.gray$ dig @2001:4860:4860::8888 blah.cloud AAAA ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.8.3-P1 \u0026lt;\u0026lt;\u0026gt;\u0026gt; @2001:4860:4860::8888 blah.cloud AAAA ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 52567 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;blah.cloud. IN AAAA ;; ANSWER SECTION: blah.cloud. 119 IN AAAA 2400:cb00:2048:1::6819:f124 blah.cloud. 119 IN AAAA 2400:cb00:2048:1::6819:f224 ;; Query time: 48 msec ;; SERVER: 2001:4860:4860::8888#53(2001:4860:4860::8888) ;; WHEN: Sun Jun 18 17:17:16 2017 ;; MSG SIZE rcvd: 84 There we have it a fully operational IPv6 implementation with prefix delegation on Fortigate.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/enabling-ipv6-dhcpv6-pd-pppoe-fortigate/","summary":"Out of morbid curiosity (and lack of IPv4 public address space available to me), I decided I wanted to enable IPv6 in my lab. However, before taking the plunge there, I would try it out on my residential ADSL line, I use the same brand of firewall there as in my lab so the experience should be largely transferable.\nSo for a bit of context; I have a Zen Internet ADSL line (I saw the fiber van around the cabinet recently so maybe that will change) - auth to the provider is done via PPPoE on IPv4.","title":"Enabling IPv6 with DHCPv6-PD and PPPoE on a Fortigate"},{"content":"Pulls back a table of Job name vs configured retention for Backup type jobs:\nGet-VBRJob | ? {$_.jobtype -eq \u0026#34;Backup\u0026#34;} | Select-Object -Property @{N=\u0026#34;Job Name\u0026#34;; E={$_.name}}, @{N = \u0026#34;Storage Retention\u0026#34;; E={$_.GetOptions().BackupStorageOptions.RetainCycles}} | Format-Table -AutoSize ","permalink":"https://blah.cloud/command-line-fu/veeam-backup-job-retention-powershell-one-liner/","summary":"Pulls back a table of Job name vs configured retention for Backup type jobs:\nGet-VBRJob | ? {$_.jobtype -eq \u0026#34;Backup\u0026#34;} | Select-Object -Property @{N=\u0026#34;Job Name\u0026#34;; E={$_.name}}, @{N = \u0026#34;Storage Retention\u0026#34;; E={$_.GetOptions().BackupStorageOptions.RetainCycles}} | Format-Table -AutoSize ","title":"Veeam Backup job retention PowerShell one-liner"},{"content":"So we have covered the typical challenges of a multi-tenant network and designed a solution to one of these, it\u0026rsquo;s time to get down to the bones of it and do some configuration! Let\u0026rsquo;s implement it in the lab, I have set up an NSX ESG Cust_1-ESG and an NSX DLR control VM Cust_1-DLR with the below IP configuration:\n \nI have also enabled OSPF as a NSSA (area 51) between the ESG and the DLR control VM and specified to redistribute connected routes attached to the DLR:\n \nAbove you can see the protocol address is that of the DLR control VM interface and not the same as the forwarding address (kernel LIF) as we discussed earlier the need for a /29 subnet. Below you can see the route redistribution configured on the DLR:\n \nOn the ESG then, I have configured three interfaces:\n Cust_1-DMZ - an \u0026ldquo;Internal\u0026rdquo; interface to be completely firewalled from the DLR but still advertise a route Cust_1-Transit - an \u0026ldquo;Internal\u0026rdquo; transit interface/network towards the DLR Cust_1-VRF - an \u0026ldquo;Uplink\u0026rdquo; attached to a vDS Portgroup and such, a physical VLAN used as another transit interface towards the upstream routing.   \nThe ESG is configured with two OSPF areas, Area 51 - towards the DLR and Area 0 - towards the upstream routing as shown below:\n \nYou can also see from the above I have enabled \u0026ldquo;Default Originate\u0026rdquo; which advertises a default route to its neighbour (in this case, the DLR), this means we don\u0026rsquo;t need to add a static route to the DLR for default routing and keeps things cleaner.\nBelow you can see the route redistribution for the ESG is set to \u0026ldquo;connected\u0026rdquo; routes also, this is to ensure the DMZ network is advertised to neighbours.\n \nIt is important to note here that as Area 51 (between the DLR and the ESG) is a NSSA type, that any routes it advertises will be re-advertised automatically into Area 0 (a \u0026ldquo;normal\u0026rdquo; area) by the ESG - this means they will be picked up by the upstream routing as well.\nUpstream Routing The complete IP addressing and OSPF area configuration can be seen below:\n \nSo now, to advertise routes into the physical network the Cust_1-VRF interface on the ESG is uplinked into a vDS Portgroup that is a physical transit VLAN into the customer VRF. In my case I have used VLAN 2001 as my upstream SVI in Cust_1\u0026rsquo;s VRF on the router.\nThe following is how the customer VRF and OSPF instance were configured on my upstream router (a Cisco Nexus 3064PQ):\n!Customer VLAN for OSPF and transit vlan 2001 name Customer_1-Transit-Default-GW !VRF Config vrf context customer_1 description Customer_1 VRF !SVI membership in VRF, OSPF config and VRRP config interface Vlan2001 no shutdown vrf member customer_1 ip address 192.168.200.1/30 ip router ospf customer_1 area 0.0.0.0 vrrpv3 1 address-family ipv4 address 192.168.200.1 primary !OSPF instance for the customer and push default route to ESG router ospf customer_1 vrf customer_1 default-information originate always Above we are configuring the VRF context for customer_1, creating a SVI from VLAN 2001, giving it an IP address of 192.168.200.1/30 (the other side of the ESG transit network), configuring an OSPF instance for that customer and then assigning it to Area 0 in the SVI we just created.\nWe also configure a VRRP address for the SVI of 192.168.200.1 to allow for failover between the two routers should one fail.\nThe routes learned by the VRF via OSPF are automatically redistributed into my lab \u0026ldquo;faux-MPLS\u0026rdquo; as they would in a production environment via BGP and pushed throughout the core network to the physical Fortigate edge-firewalls used for gateway to the internet as it would be in a real MPLS network.\nVerification Demo If you want the \u0026ldquo;ta-da networking\u0026rdquo; moment, I\u0026rsquo;ve made a quick video to prove the immediacy and usefulness of the exercise:\n \nSome commentary on what is going on above:\n I have created a Logical Switch and added it to the Cust_1-DLR as an interface as you would for any subnet. I have disabled the interface on the DLR I kick off a ping from the physical edge-firewall (no echo) You can see the subnet doesn\u0026rsquo;t show up in the routing table of the MPLS\u0026rsquo;s physical edge-firewall I then enable the interface on the DLR and we check the routing table of the MPLS firewall The firewall is now aware - automatically, about the subnet addition I have just made in NSX Focus is moved back to the ping from the firewall to the new subnet, which is now responding  For reference here is all the components involved in this:\n \nThe edge-firewall lives in the red highlighted area above, on the side of the MPLS entirely owned by the service provider that we have no control over. We are then adding a logical switch inside the virtual infrastructure highlighted in blue and it is distributed right up to the network\u0026rsquo;s edge - entirely automatically. Awesome.\nManual Verification Some manual verification/debugging can also be done to ensure that everything is working as we configured, to verify everything is working we can look at the routing table at each stage and check the routes present against what we expect. Firstly on the DLR:\n \nWe can see that it is getting a default route as advertised via the ESG (with the Default Information setting enabled), as well as a route to the 10.10.10.0/24 - Cust_1-DMZ network. There are two \u0026ldquo;connected\u0026rdquo; networks - as expected, the Cust_1-Servers network and the Cust_1-Transit network. We also get advertised the 192.168.200.0/30 network which is listed as OSPF inter-area as it lives inside the Cust_1-VRF network off the ESG inside OSPF Area 0. So all working as expected here.\nOn the ESG:\n \nThe ESG is receiving its default route from the default-information originate always statement on the upstream router\u0026rsquo;s OSPF config. There is a NSSA route for the 172.16.0.0/24 - Cust_1-Servers which is advertised up from the DLR and there are three connected routes, for the Cust_1-DMZ, Cust_1-Transit and Cust_1-VRF networks as expected.\nAnd on the upstream router:\nsw3# sh ip route vrf customer_1 10.10.10.0/24, ubest/mbest: 1/0 *via 192.168.200.2, Vlan2001, [110/0], 4d19h, ospf-customer_1, type-2 10.20.30.0/24, ubest/mbest: 1/0 *via 192.168.200.2, Vlan2001, [110/1], 00:11:13, ospf-customer_1, type-2 172.16.0.0/24, ubest/mbest: 1/0 *via 192.168.200.2, Vlan2001, [110/1], 4d19h, ospf-customer_1, type-2 192.168.0.0/29, ubest/mbest: 1/0 *via 192.168.200.2, Vlan2001, [110/41], 4d19h, ospf-customer_1, inter 192.168.200.0/30, ubest/mbest: 1/0, attached *via 192.168.200.1, Vlan2001, [0/0], 6w5d, direct 192.168.200.1/32, ubest/mbest: 2/0, attached *via 192.168.200.1, Vlan2001, [0/0], 6w5d, local *via 192.168.200.1, Vlan2001, [0/0], 6w5d, vrrpv3 192.168.254.0/30, ubest/mbest: 1/0, attached *via 192.168.254.2, Vlan2002, [0/0], 08:12:21, direct 192.168.254.2/32, ubest/mbest: 1/0, attached *via 192.168.254.2, Vlan2002, [0/0], 08:12:21, local Above we can see that we are receiving routes from the ESG for the Cust_1-DMZ, Cust_1-Servers, Cust_1-Test (behind the DLR) and Cust_1-Transit networks and that Cust_1-VRF is directly connected. Proving that our routes are being pushed up from the DLR on the hosts into the physical network\u0026rsquo;s routing table for that customer\u0026rsquo;s VRF.\nThat\u0026rsquo;s it, we can now trivially add Logical Switches to the customer DLR or ESG and have the rest of the MPLS network know about them automatically as demoed above!\nThis naturally leads us on to some very interesting possibilities for failover, workload portability between datacenters and other such things that I\u0026rsquo;ll be writing about and demoing soon.\nThanks for taking the time to read!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/implementing-multi-tenant-networking-platform-nsx/","summary":"So we have covered the typical challenges of a multi-tenant network and designed a solution to one of these, it\u0026rsquo;s time to get down to the bones of it and do some configuration! Let\u0026rsquo;s implement it in the lab, I have set up an NSX ESG Cust_1-ESG and an NSX DLR control VM Cust_1-DLR with the below IP configuration:\n \nI have also enabled OSPF as a NSSA (area 51) between the ESG and the DLR control VM and specified to redistribute connected routes attached to the DLR:","title":"Implementing a multi-tenant networking platform with NSX"},{"content":"Based on my last post, you\u0026rsquo;ll understand some of the challenges that are faced with traditional approaches to datacenter networking so let\u0026rsquo;s get into the high-level conceptual design here of how we might solve one of these problems. Most service providers have or are at least familiar with using MPLS for customer segregation in a WAN scope as I alluded to in my previous datacenter networking article. What we want to do is simplify the provisioning and distribution of subnets to a customer\u0026rsquo;s virtual environment, all the way up to the WAN.\nConceptual Design The endgame here is - if we add a VM, or indeed a Logical switch to NSX that all the other sites in the MPLS for that customer know about it without us having to touch a thing. This gives us our first step in achieving a fully automated networking platform.\nTypically, static routes are added to customer virtual routing domains (VRFs) that tell the MPLS what subnets exist behind each site if they\u0026rsquo;re not directly connected to the customer provided equipment (CPE). You can of course use dynamic routing with a router behind the CPE, but again - manual configuration of Switch Virtual Interfaces (SVIs), not as robust as automating it all.\n \nAbove we can see the desired outcome, a Logical Switch is added to NSX for a particular customer and that subnet is automatically distributed, from the host, into the customer VRF and to all of that customer\u0026rsquo;s sites on the MPLS.\nLogical Design With the concept in mind, let\u0026rsquo;s map out what this looks like logically, I had done up a diagram recently for Mark Brookfield (virtualhobbit) on how such a solution might look for his lab so i\u0026rsquo;m going to take liberty and put it in here:\n \nAt the bottom, we have our hosts, with the Distributed Logical Router and Distributed Firewall (DLR/DFW) on top - they are connected to the Edge Services Gateway (ESG) via a Logical Interface (LIF) - the DLR control VM can be seen off to the side (it\u0026rsquo;s not a data-plane component, just control-plane for routing updates and such).\nThere is an ESG in the data path between the DLR and the upstream routers/CPE which provides the customer VRFs and gateway to the WAN.\nPhysical Design This is where the fun begins - i\u0026rsquo;m going to start with a diagram that you can refer back to as we go through these concepts below:\n \nLet\u0026rsquo;s start at the bottom as that\u0026rsquo;s where our routing decisions will largely take place and where new routes will originate from.\nDistributed Logical Router  \nWhen you add Logical Switches to the DLR and you have OSPF/BGP peering northbound to the ESG enabled, these subnets will automatically be advertised upstream - this is essential in allowing an infrastructure like this to scale.\nThe DLR provides in-kernel routing between VMs, if VMs are resident inside a single host and are on different subnets, they will route entirely inside the kernel, thus cutting out any northbound traffic leaving the host.\nIf VMs are in different subnets and are also on two separate hosts, obviously, traffic will have to leave the source host. The packet is encapsulated in a VXLAN header and will be delivered and routed in the kernel on the other host, still appearing as if it came from the same L2 segment as it originated from - thanks to the encapsulation.\nThis also saves on excessive North/South traffic on the Top of Rack (ToR) to Spine switches by simply pushing the traffic to the NSX VTEP VLAN, being switched at the ToR and then back down to the other host. In itself this alone greatly helps with oversubscription ratios on ToR -\u0026gt; Spine links due to reduced N/S traffic and can mean racks can be made more dense owing to higher oversubscription ratios.\nThe DLR is also the place where VLAN to VXLAN bridging takes place in the kernel if you bridge any VXLAN segments to physical VLANs (In this case, vDS PortGroups) then it will be done on-host at line rate.\nBelow we can see a typical spine and leaf that utilises routing at the edge of the network:\n \nWith NSX in play; rather than needing to be routed centrally and transit across a number of switches and routers, thus consuming bandwidth on the Spine and Leaf interconnects and suffering an increased Round Trip Time, the packets are encapsulated by the VTEP on the source host, pushed to the ToR, switched and sent down to the host where that packet is destined and then routed in the kernel. See how the data path no longer traverses the Spine and Leaf interconnects for the same operation?\n \nThis is of course possible if you use VRFs and anycast gateway on your ToR switches - the packet would be sent to the ToR, routed, then sent to the corresponding host - I mentioned this in my previous DC networking article towards the end. This approach does however introduce a lot of complexity into the physical network and some very specialist configuration and debugging skills. It is operationally very heavy, high touch for subnet changes, complex and carries with it the appropriate risk. Not to mention you need relatively high-end switches. This approach also does not allow for some nice features that NSX adds (multi-site firewall/policy rules, failover, integrations with other high level virtualisation aware solutions, etc).\nDLR to ESG  \nThere are a few operations that go on between the DLR and the ESG - there will need to be a point-to-point transit network (typically a Logical Switch) that is a /29 subnet to provide N/S connectivity from the kernel LIFs to the default gateway or routes advertised by the ESG.\nTypically when I deploy dynamic routing between the DLR and the ESG I will use OSPF - the ESGs do come by default with two OSPF areas (`` - a \u0026ldquo;normal\u0026rdquo; area and 51 - a \u0026ldquo;NSSA\u0026rdquo; type), the NSSA will point towards the DLR and will allow the DLR to advertise routes into the ESG - area 0 is then pointed northbound on a transit link (usually a physical VLAN), to the upstream routers/CPE and will provide routing advertisements to the customer\u0026rsquo;s VRF in the MPLS switch/router.\nI\u0026rsquo;d like to highlight here the distinction between a /30 and a /29 between the DLR and the ESG - there is a lot of misinformation out there about this particular scenario and I want to clear it up.\nIf you are using a dynamic routing between the DLR and the ESG you must use a /29 subnet for your transit network, this is because while the DLR and ESG both have a LIF in same subnet - this is only used for data-plane traffic. The DLR kernel module\u0026rsquo;s LIF itself does not listen for dynamic routing advertisements. That is the job of the DLR Control VM as in the above diagram.\nThe DLR Control VM listens for and sends OSPF and BGP routing advertisements - it is not in the data-path but it still needs to be on the same subnet as the DLR and ESG LIFs to be updated with, and make, the routing advertisements - given a /30 subnet only has 2 usable addresses, that is obviously no good as we need one for the ESG LIF, one for the DLR kernel LIF and one for the DLR control VM interface.\nA point to point logical switch with dynamic routing between the ESG and the DLR should like like the below:\n \nIf however, you aren\u0026rsquo;t using dynamic routing between the DLR and the ESG, you can use a /30 as the DLR Control VM doesn\u0026rsquo;t need an interface in the subnet in order to update the DLR control plane.\nEdge Services Gateway  \nThe ESG provides in-path routing, NAT and L7 data services like Load balancing, SSL-VPN, IPSec, L2VPN. It is the boundary between the two OSPF areas as stated above and provides all N/S traffic in and out of a customer environment, as such, it is important to deploy them as a HA pair.\nESGs have the ability to use Equal Cost Multi-Pathing (ECMP) to statefully select traffic paths to/from both the DLR and northbound routers - this has the advantage that if a customer is pushing more than 10Gbps of traffic, you can scale out an ESG cluster and provide better performance across multiple paths.\nThe ESG can be configured to advertise a default route to the DLR (default-information originate) as well as redistribute routes learned statically, as connected, or via OSPF or BGP. The ESG is where we will focus the configuration of the routing into the customer VRFs on the upstream routers.\nUpstream Routing  \nSo this is not in NSX-scope but is a critical component of this architecture - in order to have any changes we make at an NSX level distributed to customer sites and provide multi-tenancy we need to have the upstream routers support VRF, this means we can have multiple routing tables with overlapping subnets on the same router but are kept separated and distinct.\nTo make sure there are no SPOF on the upstream the design would mandate a stack or pair of devices that are VRRP capable - this means that if a single device fails the other assumes its identity with a virtual MAC address and all traffic will continue to flow normally.\nThe link between the ESG and this upstream routing will also be a point-to-point /30 link - this differs from the transit link between the ESG and the DLR you\u0026rsquo;ll remember.\nThe reason behind this difference is that while the DLR Control VM is not in the data-path, the ESG is. As such, the ESG LIFs can also send/receive routing updates as well as normal traffic so there is no need for an \u0026ldquo;out of band\u0026rdquo; routing address.\nTo advertise routes learned from NSX via the ESG the router must be configured such that OSPF area 0 is configured within the customer\u0026rsquo;s VRF and is peered with the ESG meaning any routes learned via OSPF on the router will be added to the routing table in the customer\u0026rsquo;s VRF. This is actually the same process that you would use even if you are not using MPLS and rather are routing upstream to another Autonomous System via BGP and your routers are part of the public internet.\nConclusion You should be able to see from the above that implementing a solution like this has great value in automation terms, leading to more reliable, consistent environment configuration that will scale well, in the next article I will be covering the actual implementation of the above design and demoing the capability.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/designing-networking-platform-iaas-multi-tenancy/","summary":"Based on my last post, you\u0026rsquo;ll understand some of the challenges that are faced with traditional approaches to datacenter networking so let\u0026rsquo;s get into the high-level conceptual design here of how we might solve one of these problems. Most service providers have or are at least familiar with using MPLS for customer segregation in a WAN scope as I alluded to in my previous datacenter networking article. What we want to do is simplify the provisioning and distribution of subnets to a customer\u0026rsquo;s virtual environment, all the way up to the WAN.","title":"Designing a networking platform for IaaS multi-tenancy"},{"content":"As of late, I have been getting my feet wet in more networking things - Firstly out of necessity, but it has grown into a genuine area of interest to me. I have a homelab that I like to simulate a production working environment in, so I had a nice opportunity to lab up what a possible multi-tenant IaaS architecture might look like using NSX.\nNSX fundamentally changes how customer environments for service providers are designed - it moves the complexity away from the physical network and up into the hypervisor management layer, let\u0026rsquo;s be honest anything that limits touching the physical infra is good, right? The complexity is not gone - it still exists, but now it is easily automate-able. More automation = less human error.\nFirstly, it allows for very easy automation for setup and modification of an entire customer platform through the use of NSX, vCenter, vCloud Director and their respective APIs and if applicable, upstream switches (NX-OS API for example) and secondly, it protects against a misconfiguration taking down an entire environment\u0026hellip;\nWho has ever forgotten add in switchport trunk vlan allow add [number]\u0026hellip;?\nRight - let\u0026rsquo;s move on :)\nChallenges If we think about a traditional service provider network and the challenges associated with it, there is usually high-touch on shared networking components (Top of Rack switches, routers, firewalls) this critical infrastructure is typically highly regulated and controlled due to the non-standard nature of the changes and the impact they may have. We can address this risk in some ways, Change Approval Boards (CABs), shadowing and other measures. All these factors have an effect on the cost of operating the service, ability to address demand and general customer experience and satisfaction.\nProcess Flow  \nA procedure for an operation (like for example, when you want to add a subnet to a customer\u0026rsquo;s network) goes something like the following. It would need to be scoped, a request for change would need to be drawn up by the engineer, it would need to run through a CAB meeting for approval, it would need scheduled (typically out of hours due to risk mitigation), the engineer would need to execute and there may even be a tie-in with the network team/MPLS provider to advertise that subnet from the site to the rest of their network - which in turn would likely have its change control process. This process all adds further delays, cost and risk.\nTo achieve the level of agility such that a customer could log into for example a web portal, provision a new VM, as well as its associated network and, have that available across all their sites and services instantly, is not something that exists in such an environment.\nSolutions What happens when you change this environment from one where individual components that support multiple customers are modified - to one that; uses a set, unchanging config for the underlying shared infrastructure? Instead of changing the common components, the services that run on top of that infrastructure are customer specific and operate in a pre-determined manner? This predictability means that these changes can be executed without much if any lead time. Predictability and automation mitigate risk due to changes being uniform and templated and relaxes regulation to the point where no change control for the above actions is required.\nMoving to an SDN approach also has the advantage of allowing some things that are not possible, or may just be possible with very specialist kit and engineers in a traditional multi-tenant network setting.\nIf for example, you have two datacenters (primary and DR), and you need to invoke a DR action on a subset - or indeed the whole infrastructure. In the physical networking world, it is very costly and operationally intensive to make sure configuration is mirrored on each site (think firewall rules, policies, routes, services) and kept up to date with the possibly rapidly changing landscape of the primary site, not to mention the chance of human error.\nWhen using SDN - in particular, I will call out NSX, things like Firewall Rules are bound to VMs and are replicated across sites, so if you do a partial failover, the traffic is still policed as it were on the primary site with no extra configuration. If you do a full site failover, and you are using dynamic routing that advertises routes northbound to a corporate network, when using NSX these routes can be auto-populated as subnets become active inside the virtual infrastructure on the DR site.\nThat is what I hope to achieve with this blog series - prove that software defined is the way to go for virtualised datacenter workloads when used in a service provider setting through simple demonstrations of what is achievable with this technology.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/multi-tenant-network-challenges/","summary":"As of late, I have been getting my feet wet in more networking things - Firstly out of necessity, but it has grown into a genuine area of interest to me. I have a homelab that I like to simulate a production working environment in, so I had a nice opportunity to lab up what a possible multi-tenant IaaS architecture might look like using NSX.\nNSX fundamentally changes how customer environments for service providers are designed - it moves the complexity away from the physical network and up into the hypervisor management layer, let\u0026rsquo;s be honest anything that limits touching the physical infra is good, right?","title":"Multi-tenant network challenges"},{"content":"I had a bit of a storage outage in my lab due to a funky behaviour on the Synology that I use as primary storage for all my VMs:\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  Today I Learned: Adding IP address to interfaces on Synology causes reboots :/ Lab now in not such great shape. 80 VMs with APD. #vExpert\n\u0026mdash; Myles Gray (@mylesagray) November 13, 2016 Most stuff came back up or could at least be trivially fixed (like VCSA, PSCs, etc) you can edit the GRUB boot string and force into /bin/bash then run fsck from there.\nOne VM that doesn\u0026rsquo;t allow the GRUB string to be edited or both to be paused in any way is the NSX manager, that was a problem given I was presented with this upon boot:\n \n/dev/sda2: UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY. This is not a good situation, a corrupt FS and no way to force into a shell.\nA quick cry for advice on the vExpert Slack and it was decided booting into a live CD and trying to mount and repair the filesystems from there was the way to go.\nSo I downloaded the Ubuntu Desktop installer ISO (the server installer does not have fsck present) - transferred the ISO to my NFS datastore and mounted to the NSX Manager VM. If you\u0026rsquo;re going to do this, make sure you force BIOS boot mode on the VM and put boot from CD-ROM at the top of the list.\n \nNext, reboot into the Ubuntu ISO and choose \u0026ldquo;Try Ubuntu\u0026rdquo; when presented with the option to try or install.\nOnce the live environment is up - run Terminal and then type ls -l /dev/sd* to list all discovered partitions.\n \nThen you run sudo fsck /dev/sda2 and hit y when prompted to fix any errors found on the filesystem. At this stage your filesystem should be \u0026ldquo;clean\u0026rdquo;, so if you run sudo fsck /dev/sda2 again it should show up as so:\n \nUnmount the ISO from the VM, change the boot order back to normal and you should be good to go again:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/recovering-nsx-manager-corrupt-filesystem/","summary":"I had a bit of a storage outage in my lab due to a funky behaviour on the Synology that I use as primary storage for all my VMs:\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  Today I Learned: Adding IP address to interfaces on Synology causes reboots :/ Lab now in not such great shape.","title":"Recovering NSX Manager with corrupt filesystem"},{"content":"On a bit of a shorter note to my previous article/novella - I have been moving my lab to a bit more of an \u0026ldquo;enterprise\u0026rdquo; style architecture - deploying SRM was in the way for that, so I had the need to set up another vCenter, however this gave the opportunity to move to a multi-PSC, multi-VC architecture.\nThere is quite some complexity in my lab with regard to vCenter and its integrations, I have running in production vRO, NSX and vCD - it\u0026rsquo;s also plugged into VIO and VR, so naturally I really don\u0026rsquo;t want to reinstall all these components and reconfigure them as a lot of work has gone in, in particular with NSX, dynamic peering etc set up with upstream routers and its integration with vCD.\nI found a great KB for such a migration from a vCenter with an embedded PSC to one with an external PSC.\nSo, my current setup:\n \nAnd the final goal (this will likely expand to multiple PSCs in future):\n \nThe first step is to deploy an external PSC only and link it to the already existing vC with embedded PSC, so download the VCSA install ISO, choose install then deploy to your existing vCenter server (in my case: vc01.lab.mylesgray.io) - Choose Install Platform Services Controller:\n \nThen you want to join it to the existing SSO domain:\n \nThen choose to add to the existing SSO site:\n \nGo ahead and deploy the rest of the PSC through the wizard and confirm it comes up okay in your existing vCenter:\n \nNow the fun part, we need to log into the existing vCenter with SSH and reconfigure SSO to point to the new external PSC. I\u0026rsquo;ve filled out the below command with the params relevant to my environment:\nvc01:~ # cmsso-util reconfigure --repoint-psc psc01.lab.mylesgray.io --username administrator --domain-name vsphere.local --passwd MySSOPasswordHere Validating Provided Configuration ... Validation Completed Successfully. Executing reconfiguring steps. This will take few minutes to complete. Please wait ... Stopping all the services ... All services stopped. Starting vmafd service. Successfully joined the external PSC psc01.lab.mylesgray.io Cleaning up... Cleanup completed Starting all the services ... Started all the services. The vCenter Server has been successfully reconfigured and repointed to the external Platform Services Controller psc01.lab.mylesgray.io. Next we should verify that it reconfigured correctly:\nvc01:~ # /usr/lib/vmware-vmafd/bin/vmafd-cli get-ls-location --server-name localhost https://psc01.lab.mylesgray.io:443/lookupservice/sdk You will need to join the PSC to AD again if your vC was previous AD joined to maintain any windows based SSO you may have had as identity services have obviously moved to the PSC now. This can be found at:\nHome -\u0026gt; Administration -\u0026gt; System Configuration -\u0026gt; Nodes -\u0026gt; [Choose your PSC] -\u0026gt; Manage -\u0026gt; Settings -\u0026gt; Active Directory -\u0026gt; Join...\n \nOnce joined to your AD again, reboot the PSC and your permissions will be restored across all VC objects.\nNow we can go ahead and install our second vCenter server, jump into the VCSA install process again but this time choose to deploy a vCenter Server with external PSC:\n \nThen we need to fill in our newly deployed PSC\u0026rsquo;s FQDN, SSO user and password then carry on through the install process.\n \nDeployment can take a while depending on your storage. Once the second VC comes up, it should show up in your primary VC server under the following directory:\nHome -\u0026gt; Administration -\u0026gt; System Configuration -\u0026gt; Nodes\n \nIf you can log into both VCs with integrated windows SSO, you know you\u0026rsquo;ve done a good job, oh and when you see this:\n \nPlease note: any configurations that directly reference the SSO lookup url will need changed to the new PSC FQDN - NSX and VR are examples of such.\nAny questions, drop me a line below, until next time!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/migrating-vcsa-embedded-psc-external-psc/","summary":"On a bit of a shorter note to my previous article/novella - I have been moving my lab to a bit more of an \u0026ldquo;enterprise\u0026rdquo; style architecture - deploying SRM was in the way for that, so I had the need to set up another vCenter, however this gave the opportunity to move to a multi-PSC, multi-VC architecture.\nThere is quite some complexity in my lab with regard to vCenter and its integrations, I have running in production vRO, NSX and vCD - it\u0026rsquo;s also plugged into VIO and VR, so naturally I really don\u0026rsquo;t want to reinstall all these components and reconfigure them as a lot of work has gone in, in particular with NSX, dynamic peering etc set up with upstream routers and its integration with vCD.","title":"Migrating from VCSA embedded PSC to external PSC"},{"content":"Over the last 12 months my posting has been dialled back, this isn\u0026rsquo;t for lack of wanting or ideas, mainly a lack of time and mental bandwidth. Reason being, I have been designing and implementing a new cloud platform (namely \u0026ldquo;STC\u0026rdquo;) for my employer, Novosco - as with any new service or product this requires an element of discretion - but now is the time to let slip some of the detail on what makes the service tick!\nBoilerplate caveat: any views or opinions expressed in this post or on this blog in general are my own and not that of my employer.\nRequirement Back when this project kicked off the brief was \u0026ldquo;make something scale-out, with dedicated kit per tenant in which they can manage their own virtualisation environment as if it were on-prem, BYO Licensing, BYO Backup, BYO Disaster Recovery\u0026rdquo;.\nWe like the idea of Bring Your Own X for this product\nSo, scale out, but dedicated hardware per tenant and we have to be able to spin these up at will, without much lead time and allow them to manage everything on their environment.\nInitial Thoughts The obvious solution for this kind of request is to go the whole \u0026ldquo;SDDC\u0026rdquo; road; SDS, SDN, the works, but then commercially it becomes ridiculous, plus SDN tech like NSX doesn\u0026rsquo;t allow for vmkernel traffic to be encapsulated, not that this is a blocker but, it doesn\u0026rsquo;t help - so maybe we can meet halfway?\nIf we have a SDS stack; ScaleIO, SpringPath, VSAN, \u0026hellip;Maxta - just some hyperconverged node style SDS solution with a more traditional networking stack - could it be commercially viable and yet still meet the requirements we set out with?\nProblems are obviously going to rear their heads when you have a dedicated compute environment that allows the ability to install BYO-anything on said environment, the focus very quickly becomes the shared components - in this case, networking.\nI will go into the physical topology in another article as well as the decisions and math that led to it, just know that it is a 10/40GbE Spine and Leaf design with redundant ToR switching that is shared between customer environments.\nEngineering Generally when people want to separate customers that use the same networking kit; VLANs are the first port of call - but as a wise man once told me:\n Friends don\u0026rsquo;t let friends build large L2 networks\n This is easy to say, but why?\nThe L2 Problem A few reasons, large L2 is certainly do-able, and a great many SPs do maintain and manage large L2 networks, so what\u0026rsquo;s the problem?\nLoops Looping and L2 networking are inseparable, there is always a pub argument to be had. Where multiple links to the same devices cause continuous looping of BUM (Broadcast, Unknown Unicast, Multicast) traffic.\nThere are of course remedies to this, MC-LAG, Bonding, Spanning Tree in any flavour will kill off the problems with looping on a multi-link switch to switch level - these of course come with their own limitations; link utilisation and load balancing being primary of which, with link aggregation of all flavours being more band-aid type solutions than \u0026ldquo;solving the L2 problem\u0026rdquo; - after all, you still need spanning tree even if you bond all your links to stop topological loops, and you still only have 4096 VLANs.\nYou can get into some pretty ugly config when you spin up a STP instance per VLAN (a-la MST/PVST) or you have a single instance and just lose half your bandwidth (or more).\nBut\u0026hellip; What if the looping device only has a single link and doesn\u0026rsquo;t participate in spanning tree?\nThat\u0026rsquo;s right, you can have a loop on an STP enabled network from a device with only a single NIC. VMware\u0026rsquo;s vSwitching (both standard and distributed) are cases of such, or at least with VMs configured incorrectly they can be.\nRead this KB - it is the harbinger of doom when it comes to L2 scenarios you never want to encounter.\nEngineering around a situation like this is extremely difficult - it largely becomes T\u0026amp;Cs and user education. That is not to say it cannot be mitigated at least to a degree. Ivan at IPSpace makes some very good arguments with reference to VMware\u0026rsquo;s BPDU position and vSwitch implementation that will further help you understand the problem should you not see it so far (he has diagrams!).\nI would also highly recommends his webinars on DC networking topologies on this topic if you\u0026rsquo;re interested in the engineering behind them.\nForged transmits, port security, BDPU filter and BPDU guard can all be used to mitigate these to a degree for your specific scenario but won\u0026rsquo;t stop the loops - the KB does a good job in dealing with these cases, as a service provider it is hard to determine if any of these cases are true unless you have visibility over the workloads operating on the environment, we do, thankfully - however, if you don\u0026rsquo;t there are behaviours and conditions you can view as \u0026ldquo;acceptable risks\u0026rdquo; should someone not follow the ToS.\n What is the maximum speed/pps my link can loop at (the link to the host\u0026rsquo;s speed)? What traffic volume can my spine uplinks/switch take? Is it acceptable that if the customer violates Terms of Use that their environment is \u0026ldquo;DoS\u0026rsquo;d\u0026rdquo; by BPDU Guard on the switches? Is it acceptable to request in the user manual if a customer wants to deploy an SSL-VPN appliance on the service they should contact the SP first for guidance?  In some cases it may be acceptable to the SP that when a customer violates the ToS their environment stability is at risk as long as it does not affect other customers using the shared components. Your position is entirely up to you but a combination of the above usually makes a good compromise.\nLink Utilisation Second to looping, there is link utilisation, which actually is where a lot of the solutions to looping actually lie. It also happens to be where most vendors have their secret-sauce flavour of link aggregation (Dell - VLT, Brocade - VCS, Cisco - FabricPath), there is of course an open standard for this, TRILL operates at layer 2/3 using a modified link-state routing protocol (IS-IS), but as of yet there is limited vendor support.\nThese all solve a Layer 2 problem, but with the caveat of proprietary tech, increased expense and eventually redundancy when an open standard takes over.\nSo, with that in mind, why use a large L2 \u0026ldquo;fabric\u0026rdquo; for your datacenter network - especially given it is a band-aide making Ethernet do things it was never meant to?\nLimitations on Scale We all know there is a VLAN limit of 4096, to most this might not seem like much of a limit and generally it isn\u0026rsquo;t - but when you are dealing with multi-tenancy and separation on a per-tenant level where they may have an allocation of 30-50 VLANs each, that has to do transit links, LANs, DMZs, storage, interconnects - it doesn\u0026rsquo;t add up to much when building out a scalable datacenter.\nOperational Risk A result of all the above, particularly loops is the risk involved from an operational standpoint - in a large scale L2 network there is always risk involved, Murphy\u0026rsquo;s law and all that. You just need a switch that is not participating in STP, or indeed one with the wrong bridge ID to case a world of pain - granted you can say that about almost any switching environment, but L2 problems tend to be quite catastrophic.\nSolving the L2 problem with L3 You know what solves all of the above? Layer 3 - no loops (let\u0026rsquo;s ignore routing loops for now), fully utilised links from point to point when using a routed core with OSPF/BGP and ECMP selection with 5-tuple hashing for traffic distribution.\nHowever, L2 adjacency is handy sometimes; like when you have a single tenant\u0026rsquo;s compute cluster split across racks (remember, L3 routed Spine/Leaf). We start off with a DC looking like this, but we get an order for 3 new nodes - normally we would have to waste the space left in Rack 1 to provide L2 adjacency when there is a L3 boundary between racks:\n \nIf this is the case the L2 networks need to be accessible in both racks, if you vMotion a VM from one to another or DRS does it, it still needs to be contactable by all other VMs in that broadcast domain.\nSo is there a way to get all the benefits as a service provider from a big L3 routed core network, with the ability to fully utilise all our links and have no loops - but still provide L2 adjacency and segregation to tenants across racks?\nL2 over L3  \nSure, let\u0026rsquo;s provide L2 over L3, there is a lot of tech out there to skin this particularly unlucky cat, most in use by telcos providing services like VPLS (typically using pseudo-wire tech AToM, GRE, L2TPv3) but sticking with a purely datacenter context the common options are VXLAN and EVPN.\nOverlays allow us to do some very cool stuff, take the instance above where we have an L3 boundary between racks, but we have a customer that wants to come on with 3 nodes, to do this across racks, we need to provide L2 adjacency to the customer LAN networks to allow the VMs to move around easily - if we encapsulate the L2 traffic and route it across the L3 core we can decapsulate the packet on the destination ToR switch and the L2 traffic will continue as if it were in the same rack as below.\n \nThis of course can scale across multiple racks, as it is point to multi-point technology, allowing for us to stretch a given L2 network across a \u0026ldquo;limitless\u0026rdquo; number of racks, so we can mix and match customer nodes anywhere within the datacenter:\n \n#TechnologyShowdown So we want a L2 P2MP tech, to start off with eVPN - pioneered by Juniper, uses MP-BGP for control plane traffic as well as MAC and IP locality/distribution for an overlay technology (typically MPLS, PBB, VXLAN) - there are also multiple IETF RFC drafts for this standard, however the limited vendor support (Cisco and Juniper at the time) as well as lack of DC-rack class switches that these features are available on killed this tech off for the requirement.\nVXLAN is an L2 encapsulation technology that will route packets over a standard L3 core network using UDP (with a larger MTU to allow for encap - typically 1600 bytes). VXLAN, has an official IETF RFC and has been implemented by multiple vendors (VMware, Arista, Cisco, Cumulus on switches with T2/T2+ chipsets, with many more coming like Mellanox and Dell) and very much seems to be the dominant choice for DC networking and such, was the logical choice.\nIt\u0026rsquo;s worth noting that VXLAN doesn\u0026rsquo;t have a discrete control plane - rather it can use an external controller or flood + learn.\nSome networking vendors will only provide VXLAN tunnels if you have an external SDN-style controller, like Big Switch Networks, Dell and Cumulus. Generally this is not a problem when you have a single tenant infrastructure, you could use NSX-MH, BSN or an array of other controllers to provide intelligence about MAC locality and physical/host based VTEP endpoints.\nThis is not the case in a shared multi-tenant network because different vSphere environments means multiple integration points for MAC awareness and tunnel endpoints for any SDN controller. This feature was not provided by any networking vendor at the time in a commercially and operationally viable form.\nSo we had found another requirement, we couldn\u0026rsquo;t use a centralised controller at least none in their current forms but still needed P2MP.\nCumulus was ruled out at this stage due to a VXLAN tunnel down behaviour on loss of a single ToR switch when using MLAG. This was apparently to stop traffic blackholing, being linux based, it is tricky I\u0026rsquo;m told to view status of individual links within a bond reliably.\nDell was also ruled out as while the DNOS (Force 10) switches at the time had a feature vxlan they didn\u0026rsquo;t allow for tunnels to be created via CLI, only controller based i.e. NSX - however, we have been told by our rep that this is no longer the case in DNOS 9.11 and arbitrary tunnels are now supported.\nSo that really only left Cisco and Arista - at the time Cisco only supported VXLAN on the 7k and 9k series switches, which didn\u0026rsquo;t lend themselves to Spine and Leaf (now of course they have the Nexus 5600) and the cost was prohibitive as well as some multicast routing performance challenges ruled out Cisco.\nThus, we arrived at Arista who allow for all of the above (they support CLI based flood + learn for MAC addresses and BUM traffic suppression) and have a good external controller story should we choose to move that direction in future - I\u0026rsquo;ve also been informed by our SE they now support L2 and L3 eVPN as a control plane for VXLAN.\nThe switches chosen were 48x 10GbE, 6x 40GbE for the leaf nodes and 32x 40GbE for the spine - I will get into link scaling in another article as stated above.\nProviding an L3 core We had our chosen overlay tech and vendor, what about the L3 core?\nTypically in a spine and leaf you run a dynamic routing protocol like OSPF or BGP to distribute routes for all node interfaces to each other (VTEPs, loopbacks and P2P links for the spine/leaf fabric).\nIn this case, it was designed such that there was an AS per rack as well as a spine AS that all rack ASes peered with. This was chosen over a single AS for all leafs and spine as you can have instances in which traffic is dropped when a particular combination of links have an outage due to the default behaviour of BGP to prevent routing loops.\nThis can be overcome with allowas-in but it is more standard and safer to simply use a different ASN for each rack.\nLike most things this is best described with a diagram or two, below you can see two ASNs, one for all leafs and one for the spine - the combination of link outages below would result in the traffic being unroutable due to BGP\u0026rsquo;s built-in loop prevention methods:\n \nHowever, if we operate the network with an ASN per rack and an ASN for the spine we can see that the traffic can still be routed as there is no problem with the advertisement containing the same ASN as the one it is being advertised to:\n \niBGP was used to distribute the loopback and P2P interfaces to the other node at ToR as well provide redundancy should a leaf lose both uplinks to the spine and eBGP was used for the spine to distribute the routes learned from rack ASes to all other peered rack ASes - This provided VTEP visibility for all racks to each other as well as multiple routes to each destination which were then used for load distribution via ECMP.\nThe VTEP awareness across racks allowed for the creation of VLAN to VNI mappings that could traverse the spine.\nIt\u0026rsquo;s a given that to improve link utilisation you want a decent hashing algorithm for distribution of traffic, ECMP on Trident2 chipset based switches is by default 5-tuple (src + dest IP, protocol, src + dest port) - you will however need to enable explicitly multi-path BGP with:\nmaximum-paths [paths] ecmp [max ecmp paths per route to store in table]  Routing So now we have an L3 core, we have L2 adjacency across racks - what about routing?\nThere is an interesting constraint with the Trident2 chipset - you can\u0026rsquo;t route between VLANs that exist on a VNI segment because it would require recirculation back into the chipset after decapsulation (how Arista achieves this with the T2) or a separate chipset specifically to route between VNI segments (Cisco Nexus).\nThis was actually quite easy to solve - VLANs are stretched up to a pair of routers that come off the edge-leaf and provide all inter-VLAN routing and N/S traffic. Almost all of our customer traffic is E/W within the same VLAN and the traffic that was inter-VLAN is typically between DMZ/LAN and done on-host by a virtual firewall - anything else would traverse the links to the edge-leaf rack.\n \nIf a customer wished to use NSX however then routing could be done on the DLR within the hosts and save on traffic hairpinning as well as provide the value-added services from NSX.\nThis can also be achieved through the use of anycast gateway with VRFs on Arista switching where routing decisions are made at a ToR level, keeping the traffic within the rack so inter-VLAN routing does not have to traverse the spine or go to a centralised routing point as above. This has some obvious benefits, there are operational overheads involved here as well and at the time was not available from our chosen vendor that met all other requirements so we settled for the centralised routing option.\nThere is an excellent article on routing between VXLAN segments with MLAG and anycast gateway by Arista\u0026rsquo;s technical team here. I will include one diagram from the article however:\n \nThis shows the SVIs at the top of rack with the same IP, providing local routing decisions (as well as remote routing, done on the source ToR switch then sent over VXLAN) and vVTEPs for ARP suppression as well as broadcasts in large topologies. The article above is incredible and I highly recommend you read it if you want a good, in depth look at the exact packet flow in an environment like this.\nWrapping Up So, after all that - you can see there is a lot to learn when it comes to DC networking, especially ones at scale with L3 involved, but that is not to say they are hard to maintain or operate.\nKeep an eye out for articles in the near future on the maths behind why the particular switches were chosen and eventually ESXi networking config for VSAN over the encapsulated physical network.\nBig thanks to Novosco (now Telefonica Tech UK) for allowing me to publish this article in as much detail as I have and for giving me the opportunity to architect such a solution, I couldn\u0026rsquo;t have done it without the help and input of the rest of the Hosted Platforms team as well as the broader Novosco team!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/designing-modern-private-cloud-network/","summary":"Over the last 12 months my posting has been dialled back, this isn\u0026rsquo;t for lack of wanting or ideas, mainly a lack of time and mental bandwidth. Reason being, I have been designing and implementing a new cloud platform (namely \u0026ldquo;STC\u0026rdquo;) for my employer, Novosco - as with any new service or product this requires an element of discretion - but now is the time to let slip some of the detail on what makes the service tick!","title":"Designing a modern multi-tenant DC network"},{"content":"I\u0026rsquo;ve been putting off doing VCAP level exams for a long time, probably longer than I should have in hind-sight. But a month ago I took my brave pills and booked what would be my first VCAP level exam: VCIX6-NV. So the date was set and I have been studying in pretty much all the free time I have over the last month - repeating HOLs over and over, standing up, breaking, fixing my home lab\u0026rsquo;s NSX environment, setting all kinds of stuff with API instead of the UI to try and get a grasp of everything this exam is supposed to encompass.\nI\u0026rsquo;ll start with studying, follow the blueprint - it is absolutely essential and will prepare you for (almost) everything this exam throws at you, follow one of the blueprint guides, I used Martijn Smit\u0026rsquo;s excellent one - be aware it was written in 2014 and is not fully up to date with VCIX6-NV, but it very close - I used this guide step by step and went and implemented everything that was described in my lab.\nThis leads me on to step two - if you don\u0026rsquo;t have a home lab or a dedicated environment for testing in, I believe it will be very hard to pass this exam, even rent one from baremetal cloud I linked to before. It also helps to have a use case: mine is the services for my apartment and parent\u0026rsquo;s home runs inside this lab which gave me the perfect use case for NSX, multi-tenancy and some live workloads to experiment with, a snippet of my DLRs, Edges and Logical Switches can be seen below.\n \nIt helps that above, each of the ESGs and DLRs has a different config, some run OSPF, some static, some BGP between each other, the Kharms-DLR for example has some bridging interfaces there to transmit client data onto a shared subnet with servers (the kit is actually hosted in that premises).\n \nIf you don\u0026rsquo;t have use cases, make some up, build a few workload you sort-of care about so you are motivated to fix rather than just blow away and start again, it will also help you experience edge cases (I had a few load-balancer WTF moments the night before the exam!).\nI\u0026rsquo;m assuming you have a VCP6-NV and followed some online courses like Jason Nash\u0026rsquo;s PluralSight course for that - but this exam being 100% live lab based, the best experience you can get is to actually use the product.\nThat nicely leads me on to my third piece of advise for studying, do the HOLs lots.\nOnes I\u0026rsquo;d particularly recommend:\n HOL-1703-SDC-1 - VMware NSX: Introduction and Feature Tour HOL-1703-USE-2 - VMware NSX: Distributed Firewall with Micro-Segmentation HOL-1703-USE-3 - VMware NSX: Operations and Visibility  and if they\u0026rsquo;re still available:\n HOL-SDC-1603 VMware NSX Introduction HOL-SDC-1625 VMware NSX Advanced  I covered the above labs between 5-10 times each. They are invaluable and are very close to the exam experience of which you can get a look at here.\nMoving on to taking the exam itself, if you want more info on the environment, take a look at the blogs by Joshua Andrews and Dave Davis - take note in particular the keys that are disabled and that you have no right click so don\u0026rsquo;t click on a VM console session :)\nThe exam time is 190 minutes, which sounds like a lot - it\u0026rsquo;s not. This exam is grim and a god damn time vortex, I got hung up on Q2 after the browser cache didn\u0026rsquo;t clear and ended up rebooting an NSX manager to try and alleviate the problem - which worked, but it was time wasted. I also encountered a problem where two questions seemed to contradict each other, but it was me being panicked, I didn\u0026rsquo;t see it - don\u0026rsquo;t get lost in the beginning, note down questions you aren\u0026rsquo;t 100% confident with and come back to them.\nSet yourself a pace per question, like you would with any exam, 190 minutes and 23 questions = 8.2 minutes per question. I did find myself at the end with 30 minutes left and 8 questions to go, rushing through trying to make up for lost time and didn\u0026rsquo;t end up answering everything, but that appears to be the grim truth of VCAP level exams - I later found out on the vExpert Slack team this is the rule rather than the exception.\nBut the stress, leaving out questions at the end because of lack of time and overall dread felt during the exam resulted in this:\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  Well... that was a car crash. Need to think about this one. #VCAP\n\u0026mdash; Myles Gray (@mylesagray) September 21, 2016 However, less than an hour later and a very hasty + angry drive home, I found this in my inbox\u0026hellip;\nI have absolutely no idea how, but i’ve now got my @vmwarensx VCIX6-NV… #vExpert #VCAP pic.twitter.com/U75UQUxocS\n\u0026mdash; Myles Gray (@mylesagray) September 21, 2016 That I did not expect, I almost didn\u0026rsquo;t want to open the attachment for fear of it driving home the truth that I had failed, however, my pessimism appeared to be redundant and I can now proudly call myself a VCIX! :)\nIf you want a few more resources on exam experiences, Anthony Spiteri and Ross Wynne have both written about the VCIX-NV in a similar manner.\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/personal/vcix6-nv-exam-experience/","summary":"I\u0026rsquo;ve been putting off doing VCAP level exams for a long time, probably longer than I should have in hind-sight. But a month ago I took my brave pills and booked what would be my first VCAP level exam: VCIX6-NV. So the date was set and I have been studying in pretty much all the free time I have over the last month - repeating HOLs over and over, standing up, breaking, fixing my home lab\u0026rsquo;s NSX environment, setting all kinds of stuff with API instead of the UI to try and get a grasp of everything this exam is supposed to encompass.","title":"My VCIX6-NV exam experience"},{"content":"I have been meaning to write this for a very long time, finally inspired by seeing Russell Pope\u0026rsquo;s absolutely insane lab in the vExpert Slack and Mark Brookfield\u0026rsquo;s homelab post it started when my lab was a single Dell R710 with 96GB RAM and 2x X5670 procs. The home lab has stopped being a lab and become a datacenter in that time and it\u0026rsquo;s about time I put it down on paper.\nSo, like most people, I collect hardware and gubbins over time - about 2/3 years in now and I have what has been described as better than most people\u0026rsquo;s production infrastructures. It may looks like hardware lust, but it is (mostly) requirement driven. I want a lab in which I can accurately simulate an environment like I would have in my day-to-day work (a MSP, Novosco) so, dedicated management cluster, compute cluster, hardware to support a multi-tenant environment, enough resource to run all our various automation and services pieces.\nIn essence, this thing is big.\nCurrent Lab So I guess we\u0026rsquo;ll start with a LucidChart topograph of the whole deal:\n \nAs you can see from the above, yes, my management cluster is bigger than my compute cluster, but i\u0026rsquo;m emulating an MSP here, I don\u0026rsquo;t need a ton of compute workloads to replicate the tool chain.\nThere is a cacophony of software running in here; vSphere, vCloud Director, Zerto, VMware VIO, vROPS, Runecast, Veeam, PernixData FVP (R.I.P.), NSX and soon to be VSAN. All layed out with a true multi-tenant service model (even the house it\u0026rsquo;s hosted in accesses the VMs over an IPSec tunnel to an NSX edge as a tenant would).\nWith the topo fresh in your mind, here is the actual physical loadout of the boxes and the rest of the hardware:\n3x Dell R710:\n96 / 72 / 72GB RAM 2x X5670 / 2x X5570 / 2x X5570 4x Internal 250GB SATA drives RAID 10 1x 250GB Samsung 850 EVO in each (PernixData FVP FTW!) Quad Gig NICs iDRAC 6 Ent H700 RAID Card 2x Intel X520-DA1 2x Dell R610:\n48GB RAM 2x E5630 4x Internal 150GB 10K SAS RAID 1 Quad Gig NICs iDRAC 6 Ent PERC 6i RAID 2x Intel X520-DA1 Synology DS2015xs\n2x Intel 240GB 520 Series (RAID1 SSD R/W Cache) 6x HGST Ultrastar 7K4000 2x 1GbE 2x 10GbE ReadyNAS Ultra 6\n6x HGST Ultrastar 7K6000 2x 1GbE  2x Fortigate 100D firewalls in A/P HA Cisco 2811 Router for PPPoE termination to allow for the HA clustered firewalls 2x HP ProCurve 2824 switches (complete balls) Cisco SG300-10 (splits the interfaces between HA cluster members) Eaton 5PX 2200 UPS (with not enough runtime - watch this space)  The Money Shot\n \nAs you saw above, i\u0026rsquo;m running some archaeology grade HP Procurves as my ToR switching - they\u0026rsquo;re bog standard, noisy, old, L2 switches and need to die. :)\nAnd how does all this look in vCenter?\n \nThe sad part being, most of it belongs in the management cluster:\n \nI\u0026rsquo;m sure I\u0026rsquo;ll write another article/multiple on the set up, what way things are configured from an interop point of view and how it is run operationally - but this is about the hardware. That said, I should note that I do run the lab with DPM enabled so on the off chance it falls below N+1 it powers off the unnecessary hosts, which is helpful given the current usage at 240v for half the kit looks like this:\n \nThe Future So what does the future hold for this home DC?\nWell, no thanks to Erik Bussink\u0026rsquo;s latest blog post it refreshed my hunger for 10GbE switches in the lab, I had previously been eyeing up some Cisco 5548P, Mellanox SN series and even older Arista and Force10 switches - But the Nexus 3K Erik found seemed perfect.\nSo I picked up a Nexus 3K 3064PQ from a very helpful US Cisco reseller along with 2x 400W PSUs, some cables and N3K-LAN1k9 Layer 3 Enterprise networking services licenses along with a massive haul of Intel X520-DA1s I found a killer deal on to fully build out 10GbE in prep for VSAN and any other SDS goodness.\nOn the topic of futures, this thing chucks out a lot of heat, sound and every other sensory irritant known to man. So obviously, it is currently hosted in what was originally a room for a filing cabinet and some circuit breakers in the house with almost no ventilation or sound deadening.\nIt\u0026rsquo;ll be moving into a dedicated room in a detached garage with air conditioning and given all my bitching about power, a slight upgrade to the UPS - plus some 4-core fiber cross connects to the house.\nAfter that, who knows (I have some pie in the sky ideas), but hopefully whatever it is, it helps me learn and doesn\u0026rsquo;t just benefit the power company (NIE, hook me up with 3-phase, kthxbai).\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/my-home-datacenter/","summary":"I have been meaning to write this for a very long time, finally inspired by seeing Russell Pope\u0026rsquo;s absolutely insane lab in the vExpert Slack and Mark Brookfield\u0026rsquo;s homelab post it started when my lab was a single Dell R710 with 96GB RAM and 2x X5670 procs. The home lab has stopped being a lab and become a datacenter in that time and it\u0026rsquo;s about time I put it down on paper.","title":"My home datacenter."},{"content":"I protect any account I have with two factor auth, at least the ones that support it (this site for example has 2FA for admin logon), it\u0026rsquo;s not that inconvenient (especially not with Authy/Duo) and greatly increases security of your critical accounts.\nLet\u0026rsquo;s start with the endgame:\n \nHowever, I haven\u0026rsquo;t protected my publicly accessible firewall with 2FA - mainly because there is no real built in method for using industry standard apps with it. (Who wants a hardware token or a paid for token nowadays? no thanks).\nI have been using Duo recently for a lot of my 2FA accounts, mainly because I really like their \u0026ldquo;push\u0026rdquo; 2FA service, no need to type in any timed code, just tap approve on your phone/watch/whatever. They have an insane number of application integrations possible natively. However, there are a lot of services that don\u0026rsquo;t offer native integration, Fortigate as a case-in-point are a vendor that only allow their own tokens to be used - however you can have your VPN and firewall admin users auth against LDAP/RADIUS.\nHelpfully, Duo have an auth proxy that will sit between the firewall and our actual auth source, check the credential against the primary auth source, then send a push to your mobile device before sending the auth approved message back to the firewall - essentially giving you two factor for any device that can use LDAP/RADIUS as a backend auth mechanism, like below:\n \nThe beautiful part is it is completely application agnostic, the only requirement from the app is the ability to query a RADIUS or LDAP server.\nYou\u0026rsquo;ll need to sign up and add your mobile verification method. We\u0026rsquo;ll start by creating an application, navigate to the Protect an Application page, the number of apps is pretty overwhelming, but we are looking for RADIUS and then hit Protect this Application:\n \nGive it a meaningful name as multiple can be used across multiple sites - I\u0026rsquo;ve named mine MGIO-Lab-RADIUS-Proxy I find it helps to prepend a site name or domain to the start to make it more obvious in future. I also like to change the username normalisation to Simple as it will accept any of the given formats, which is fine by me.\n \nTake note of the three credentials at the top; Integration Key, Secret Key and API Hostname.\nNext we need to download the proxy, I typically install one on DC1 and another on DC2 with their primary auth methods pointed at themselves, with the other as a backup. This protects against app failure, VM failure and host failure (DRS anti-affinity rule).\nAs for any 2FA system, have backup keys as well as an unused admin user with a very long and complex password.\nI\u0026rsquo;m using AD, so my auth proxy is going to live on Windows for handiness, you can of course run them on linux of you wish as well - either way you can get them here.\nInstall on your chosen machine (very Next -\u0026gt; Next -\u0026gt; Finish type deal) and now for the actual setup. Navigate to and open this file with wordpad as administrator (notepad messes with spacing and encoding):\nC:\\Program Files (x86)\\Duo Security Authentication Proxy\\conf\\authproxy.cfg I\u0026rsquo;ve created a new domain user as a Duo service account called _svc.duo and also have encrypted the plaintext password with the Authy password encryptor located here (you will need to generate a new hash for each proxy as they are machine specific):\nC:\\Program Files (x86)\\Duo Security Authentication Proxy\\bin\\authproxy_passwd.exe We also need to adjust the config from service_account_password to service_account_password_protected to let Duo know it\u0026rsquo;s encrypted, my config looks like this with all the info plugged in:\n[ad_client] host=dc1.lab.mylesgray.io host_2=dc2.lab.mylesgray.io  service_account_username=_svc.duo  service_account_password_protected=\u0026lt;encrypted string\u0026gt;  search_dn=dc=lab,dc=mylesgray,dc=io security_group_dn=CN=Firewall_Admins,OU=Security Groups,OU=Groups,OU=Lab,DC=lab,DC=mylesgray,DC=io Note from the above, host_2 is my second DC in case the first isn\u0026rsquo;t available - as stated before the same config will exist on the second proxy, just with host and host_2 swapped. security_group_dn is the security group I want to filter users on to allow users admin access to the Fortigate. Save the file, you will be prompted if you want to remove formatting (this is fine) go ahead and save.\nNow we need to set up the RADIUS proxy so we can actually query it from the Fortigate, we need to add another section to the authproxy.cfg file and fill in the details from the console we recorded earlier:\n[radius_server_auto] client=ad_client ikey=\u0026lt;your identity key here\u0026gt;  skey=\u0026lt;your secret key here\u0026gt; api_host=\u0026lt;your API hostname here\u0026gt; radius_ip_1=\u0026lt;your firewall IP\u0026gt; radius_secret_1=\u0026lt;add a password for RADIUS client auth here\u0026gt; failmode=secure The failmode=secure in the above section can be added if you\u0026rsquo;d like to make Duo reject all logins if backend auth fails - if you have an out of band admin account this should be an okay option to use. The field radius_secret_1 is just a password to allow the device radius_1 to query the new RADIUS proxy, just make sure you match this to the firewall config later on.\nNow we are ready to start the Duo service:\nnet start DuoAuthProxy If for whatever reason it fails to startup, go diving for logs in Event Viewer they are usually helpful and Google-able. Now your proxy is listening so it\u0026rsquo;s time to configure the Fortigate. I\u0026rsquo;m using FortiOS 5.4.1 in my lab so your UI will likely look a little different, but it can be found in the User \u0026amp; Device section - we are going to configure a RADIUS Server with the below settings (note the active/backup radius servers):\n \nI have created a group in AD Firewall_Admins as above to allow users access based on group membership - it\u0026rsquo;s a pain adding and removing users manually from firewalls so for me centralised RBAC = win.\nWe will now create a user group on the Fortigate and associate it with the Duo RADIUS proxy - Navigate to User \u0026amp; Device -\u0026gt; User Groups -\u0026gt; Create New - Name the group, Type should be Firewall and we will add a remote group - your RADIUS Proxy should show in the list under Remote Server and no group is needed as we have already filtered within the proxy - so Any is fine here.\n \nLet\u0026rsquo;s add the Firewall_Admins group to the Fortigate administrator users, this is found in Global (if using VDOMs) -\u0026gt; System -\u0026gt; Administrators -\u0026gt; Create New, give it a name and change the Type to Match all users in a remote server group (or choose Wildcard on FortiOS 5.2). Choose the Firewall_Admins group we created earlier - set the Administrator Profile to super_admin.\n \nThat\u0026rsquo;s should be it, given all has gone well - logout of the firewall and log back in with one of the users in the Firewall_Admins group in AD - the login screen will wait for you to confirm on your phone then continue once you have pressed accept.\nIt\u0026rsquo;s a good idea to extend the login timeout on the fortigates to give you time to get your phone/process the logon, SSH into the firewalls and put this in to the console:\n#config global //if you\u0026#39;re using VDOMs #config system global #set remoteauthtimeout 60 #end #end //if you\u0026#39;re using VDOMs This Foritgate article helped out a lot in the end when I found myself spinning my wheels over providing admin auth to a group rather than individual users: http://kb.fortinet.com/kb/documentLink.do?externalID=FD36127\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/setting-duo-2fa-fortigate-admin-authentication/","summary":"I protect any account I have with two factor auth, at least the ones that support it (this site for example has 2FA for admin logon), it\u0026rsquo;s not that inconvenient (especially not with Authy/Duo) and greatly increases security of your critical accounts.\nLet\u0026rsquo;s start with the endgame:\n \nHowever, I haven\u0026rsquo;t protected my publicly accessible firewall with 2FA - mainly because there is no real built in method for using industry standard apps with it.","title":"Setting up Duo 2FA for Fortigate admin authentication"},{"content":"I swapped out my single Fortigate 100D at home a while back for a cluster of two in active/passive, as part of this migration, that I have written about before I needed to terminate any DHCP or PPPoE interfaces on a different piece of kit than the clustered firewalls.\nI have had this in the lab for a while on a Cisco 2811 router set up pretty much exactly like I had in the previous article.\nHowever, it came to my attention that OpenReach support RFC4638 (Mini Jumbo Frames) on their WAN, so I felt compelled to remove a few lines of config from my router to clean it up and gain whatever marginal benefit an extra 8 bytes of frame size will get me.\nThe current config looked like this (the parts that matter anyway):\ninterface FastEthernet0/0 description FG_side ip address my.public.ip.address 255.255.255.248 duplex auto speed 100 ! interface FastEthernet0/1 description WAN_side no ip address duplex auto speed auto pppoe enable group global pppoe-client dial-pool-number 1 ! interface Dialer1 ip unnumbered FastEthernet0/0 ip mtu 1492 encapsulation ppp ip tcp adjust-mss 1452 dialer pool 1 dialer idle-timeout 0 dialer-group 1 ppp authentication chap pap callin ppp chap hostname USERNAME HERE ppp chap password 7 PASSWORD ppp pap sent-username USERNAMEHERE password 7 PASSWORD no cdp enable ! The RFC allows for you to send a standard 1500 byte ethernet frame over the WAN - so we need to increase the MTU on the WAN side interface and tell ppp to negotiate a MRU size of 1500 as it is larger than the 1492 standard:\ninterface fa 0/1 mtu 1508 pppoe-client ppp-max-payload 1500 And we can also now remove ip tcp adjust-mss and ip mtu from the dialler as no frames will need their size change when going over wan:\ninterface Dial 1 no ip mtu 1492 no ip tcp adjust-mss 1452 You can see from the ping below running during my change that we are now able to ping google.com at a 1472 (accoung for 28 byte overhead) MTU.\n \nProps to this thread, without it I wouldn\u0026rsquo;t have known OpenReach implemented this feature.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/enabling-mini-jumbo-frames-rfc4638-bt-infinity/","summary":"I swapped out my single Fortigate 100D at home a while back for a cluster of two in active/passive, as part of this migration, that I have written about before I needed to terminate any DHCP or PPPoE interfaces on a different piece of kit than the clustered firewalls.\nI have had this in the lab for a while on a Cisco 2811 router set up pretty much exactly like I had in the previous article.","title":"Enabling Mini Jumbo Frames (RFC4638) on OpenReach FTTC"},{"content":"Preamble This article was written a few years back, but never published - it was some work I was doing in my lab to try and get to grips around the work involved in creating a SAN with synchronous replication built in from scratch.\nIt in no way should be used for production, but rather as a learning exercise - as previously stated the instructions are a few years old and version specific, so openSUSE may well now support some of the modules I had to compile and create repos for manually, also DRBD9 has been released and should obviously be used in place of DRBD8 as I have below.\nThe purpose of posting this information is just as a knowledge dump and some configs may come in handy to others out there. I learned a lot about the open source community during this project, how helpful, but also at times how toxic the politics can be. I could have written about those, as all the information is out in the open, but have chosen not to write about the experiences therein and rather, let the incredible work these people are doing speak for themselves.\nThe section about Corosync/Pacemaker is missing from the below, I will create some VMs with the config below and try to finish off that section in the near future - but know that these HA daemons were used to orchestrate quorum and failure domains in the event of bad things happening (automatically take down iSCSI targets etc).\n Intro / Specification I will leave the hardware spec and definition for another article, this one is just about getting the software sorted out.\nI had the need to create 2x SANs that had to have the following features:\n synchronous replication asynchronous replication (offsite-replication to another paired array - possibly) iSCSI support RAID10 - Large array (36TB per SAN) 10GbE 10-20k IOPS per host  Research With this in mind I had a few \u0026ldquo;nice\u0026rdquo; features I wanted the SANs to support myself, through software, namely:\n SPC-3/4 XCOPY, Persistent Reservations commands (SCSI Locking, Cluster Aware for Primary/Primary cluster) VAAI support SSD cache in front of HDDs (LSI cards with CacheCade)  A word on the above:\n VAAI is nothing more than standard (t10) SCSI commands implemented into VMWare\u0026rsquo;s ESX iSCSI initiator, there is nothing VMWare or VMFS specific about these commands so any hypervisor could add support for VAAI compliant storage by adding this functionality to their iSCSI initiator. The amazing thing about this change however is that data processing is now offloaded to the SAN\u0026rsquo;s hardware. Meaning your ESX instance now no longer has to process the data - this is particularly handy for cloning, replication, templating - instead of a VM clone taking hours it can take minutes. The exact commands are:    Atomic Test \u0026amp; Set (ATS), which is used during creation and locking of files on the VMFS volume (SCSI COMPARE AND WRITE) Clone Blocks/Full Copy/XCOPY, which is used to copy or migrate data within the same physical array (SCSI EXTENDED COPY) Zero Blocks/Write Same, which is used to zero-out disk regions (SCSI WRITE SAME) Block Delete in ESXi 5.x and later hosts, which allows for space to be reclaimed using the SCSI UNMAP feature. For more information on Block Delete (SCSI UNMAP)    Operating Systems are easy to choose between - especially for clustering, you either use RHEL or its derivatives (Fedora/CentOS) or SLES and thus conversely - openSUSE. Why not use Ubuntu? I hear you ask, Ubuntu is not what I call \u0026ldquo;Enterprise OS\u0026rdquo; material - clustering has been broken from 10.10 right through to the current release 13.04 - too focused on Desktop UX and not enough on core functionality it would appear.  Replication: DRBD is going to be the replication framework of choice - this is because it offers great support, is proven to be stable in production environments and as of DRBD9 will support scale-out clustering and multi-primary). I chose this over GlusterFS et al. because of stability problems using iSCSI on GlusterFS with VMWare - this has apparently been fixed in v3.3/3.4 but I have not tested and rather not be the one to find out.\niSCSI: I wanted an iSCSI framework that would support VAAI and SCP-3/4 commands - there is only one at the moment that does this and it is (controversially) Linux\u0026rsquo;s kernel build in SCSI framework - LIO - after fighting off SCST for the retired IET module.\nCluster Management: Heartbeat is dead, so the natural stack of choice for cluster management is Pacemaker/Corosync - all of DRBD\u0026rsquo;s guides are written for this and is basically a standard.\nSoftware So a break-down of the software to be used then:\n openSUSE12.3 (upgraded to linux-3.12 kernel) Lio-target w/ targetcli (native linux kernel SCSI module) DRBD 8.4.3 (DRBD9 as a rolling upgrade when released) Pacemaker/Corosync  First we install our base openSUSE 12.3 install - as default this comes with the linux-3.7.10 kernel to use the VAAI features of LIO Target we need to have the linux-3.12 kernel installed, so we need to pull this from the openSUSE kernel HEAD repository, get sudo then enter the following:\nzypper ar http://download.opensuse.org/repositories/Kernel:/HEAD/standard/ Kernel-Head zypper refresh #Yes you want to always trust this repo when adding zypper in --from Kernel-Head kernel-desktop #Yeah, openSUSE uses the desktop kernel reboot Upon reboot your output should read similar to this:\n# uname -r 3.14.0-rc3-4.g1d0217b-desktop Let\u0026rsquo;s install DRBD, openSUSE\u0026rsquo;s drbd trails behind what is currently in the linux kernel somewhat (v8.4.3) - the userland as of openSUSE 12.3 is v8.3.11 so I created a package to upgrade the userland to v8.4.3:\nzypper ar http://download.opensuse.org/repositories/home:MylesGray/openSUSE_12.3/home:MylesGray.repo zypper refresh #Yes - trust source zypper in --from home_MylesGray drbd That\u0026rsquo;s nicely installed DRBD for you avoiding all those exceedingly annoying userland and kernel recompiling problems you\u0026rsquo;d otherwise have :)\nNext up, install targetcli (again another package not in the openSUSE repo - i\u0026rsquo;ve added it to my build.opensuse.org repo):\nzypper ar http://download.opensuse.org/repositories/home:/MylesGray:/targetcli/openSUSE_12.3/home:MylesGray:targetcli.repo zypper refresh #Yes - trust source Next we have to remove the OS versions of these libs - the lio-utils one seems broken as standard, as such we need to run:\nzypper in --from home_MylesGray targetcli #select option 1 if prompted - Solution 1: deinstallation of patterns-openSUSE-minimal_base-conflicts So that\u0026rsquo;s targetcli and DRBD installed, lets configure drbd:\nnano /etc/drbd.conf Paste in the following:\nglobal { usage-count no; } common { protocol C; net { cram-hmac-alg sha1; shared-secret \u0026#34;abc123456789\u0026#34;; } syncer { rate 750M; } } resource data0 { device /dev/drbd0; disk /dev/sda5; meta-disk internal; on atlas { address 10.0.5.2:7789; } on zeus { address 10.0.5.3:7789; } } Start up DRBD:\nservice drbd start Bring resources up and make one node primary:\ndrbdadm primary --force all drbdadm -- --overwrite-data-of-peer primary all drbdadm up all drbd-overview Let\u0026rsquo;s create our lio-target config:\ntargetcli /\u0026gt;/backstores/iblock create data0 /dev/drbd0 /\u0026gt;/iscsi create /\u0026gt;/iscsi/iqn..../tpg1/luns create /backstores/iblock/data0 /\u0026gt;/iscsi/iqn..../tpg1/portals create 10.0.5.2 /\u0026gt;saveconfig /\u0026gt;exit We should now be able to access our target from our ESXi hosts.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/replicating-san-opensuse-vaai/","summary":"Preamble This article was written a few years back, but never published - it was some work I was doing in my lab to try and get to grips around the work involved in creating a SAN with synchronous replication built in from scratch.\nIt in no way should be used for production, but rather as a learning exercise - as previously stated the instructions are a few years old and version specific, so openSUSE may well now support some of the modules I had to compile and create repos for manually, also DRBD9 has been released and should obviously be used in place of DRBD8 as I have below.","title":"Replicating SAN on openSUSE with VAAI"},{"content":"Following on from my previous post on configuring custom ESXi images for PXE deployment, it piqued my interest again in Auto Deploy, now that I have a lab large enough (enough physical failure domains) to justify auto-deploy I figured i\u0026rsquo;d give it another go. I have chosen to implement stateless caching as it will allow the hosts to boot from the last used ESXi image they had if the PxE/AutoDeploy server goes down - then when it comes back up will pull the new version, this accounts for a total infrastructure outage and still allows the hosts to be bootable.\nSo to start off with, i\u0026rsquo;m assuming you\u0026rsquo;re using the vCenter Server Appliance and not a Windows based VC and you\u0026rsquo;re on vCenter 6.0.\nLet\u0026rsquo;s go and start the Auto Deploy service on the vCenter Web UI, you\u0026rsquo;re going to need to log in with a user with @vsphere.local/SSO permissions and navigate to Administration -\u0026gt; System Configuration -\u0026gt; Services -\u0026gt; Auto Deploy and click the Actions dropdown and Edit Startup Type and change to Automatic:\n \nNow back into the Action menu and click Start. Now that the Auto Deploy service is started and set to start on every boot, we\u0026rsquo;re ready to configure the service itself, to view the current config we need to move to Home -\u0026gt; Hosts and Clusters click your vCenter and click Manage -\u0026gt; Settings -\u0026gt; Auto Deploy and it should look similar to below:\n \nClick the link to Download TFTP Boot File Zip and extract - copy these files to the root of your PxE server tftpboot folder with FileZilla/your SFTP client of choice.\nNow we need to configure our DHCP server to hand out options codes to tell clients where the TFTP server is and what the boot file is called:\n 66 - next-server - IP address of the PxE server that you have previously spun up and copied the TFTP Boot File Zip contents to. 67 - filename - In above picture BIOS DHCP File Name  I have covered setting up DHCP options previously on a Fortigate and there are plenty of guides out there for doing this on Linux/Windows so trust in your Google-fu. I\u0026rsquo;m just going to show you what my finished DHCP config looks like on a Fortigate (note next-server and filename):\nconfig system dhcp server edit 2 set dns-service default set ntp-service default set default-gateway 10.0.3.1 set netmask 255.255.255.0 set interface \u0026#34;MGMT\u0026#34; config ip-range edit 1 set start-ip 10.0.3.2 set end-ip 10.0.3.100 next end set timezone-option default set next-server 10.0.3.189 set filename \u0026#34;undionly.kpxe.vmw-hardwired\u0026#34; next end Now we should be in a position to boot the hosts and have them pick up the iPxE boot environment that we pushed to it earlier, however, at this stage it shouldn\u0026rsquo;t run ESXi as we haven\u0026rsquo;t created any Auto Deploy Rules or created an active Auto Deploy Rule Set.\nFor purposes of demonstration I\u0026rsquo;ve spun up some VMs in my lab with no OS to PXE boot - when you power on the hosts at this stage, you should see the below screen, if you don\u0026rsquo;t you likely have a DHCP option problem or permissions problem on your tftpboot folder and it can\u0026rsquo;t be read by world.\n \nSo once you\u0026rsquo;re seeing the above we are good to build up our Auto Deploy rule set - you\u0026rsquo;ll need PowerCLI installed as there is no native UI for building Auto Deploy Rules (yet\u0026hellip;).\nOpen up PowerCLI, connect to the vCenter server that has the Auto Deploy service running and we will import an offline ESXi bundle to deploy our selected version of ESXi - if you want to create a customised image profile with particular VIBs pre-installed, check my article on that here.\nConnect-VIServer vc01.lab.mylesgray.io Add-ESXSoftwareDepot E:\\DL\\update-from-esxi6.0-6.0_update02.zip Now we can get the Name field of the image profiles included\nGet-ESXImageProfile | fl For this demo i\u0026rsquo;m going to use the latest image profile that includes VMware Tools ESXi-6.0.0-20160302001-standard - let\u0026rsquo;s create our first Auto Deploy Rule (you can create other more specific ones based on the patterns here if you like and add them to the rule set):\nNew-DeployRule -Name \u0026#34;InitialBootRule\u0026#34; -Item \u0026#34;ESXi-6.0.0-20160302001-standard\u0026#34; -AllHosts This will kick off an upload of the image profile to the vCenter Server for provisioning to the hosts:\n \nSo all this has done is created the rule, it\u0026rsquo;s not in the active rule set yet, so won\u0026rsquo;t apply to any booting hosts, we need to add the rule to part of the active rule set for it to apply to hosts:\nAdd-DeployRule -DeployRule \u0026#34;InitialBootRule\u0026#34; And we can run Get-DeployRuleSet to ensure the rules are part of the active set, if successful we should se it listed as so:\nPowerCLI C:\\Program Files (x86)\\VMware\\Infrastructure\\vSphere PowerCLI\u0026gt; Get-DeployRuleSet Name : InitialBootRule PatternList : ItemList : {ESXi-6.0.0-20160301001s-standard} Now as the host reboots we can see it boot the hypervisor from AutoDeploy:\n \nSo the host now boots into ESXi and joins vCenter, but is completely unconfigured and not very useful, the whole purpose of automating something like this is to for example, auto scale and IaaS cluster - especially one where the public can spin up VMs on demand.\nWith that in mind, let\u0026rsquo;s build a host profile to get some standardised config on the go - I\u0026rsquo;ve set up the first host manually with some generic stuff (NTP, Power Profile, Keyboard type, etc) and have extracted the host profile (deselecting anything irrelevant) then, attached the Host Profile to the cluster Auto Deploy will be moving the hosts into - In my case, I created a cluster TestClusterPleaseIgnore.\n \nThere is however one thing we need to change - Remember we said at the start we wanted the host to cache the image it pulls from Auto Deploy to disk in case of a PxE outage? Well, we do that in the host profile - the exact setting is in Advanced Configuration Settings -\u0026gt; System Image Cache Configuration -\u0026gt; Enable stateless caching on the host:\n \nThe other settings (overwrite VMFS, ignore SSD and the first disk) are up to you - however, just know the way I illustrated specifies the first disk with ESXi installed, followed by a local disk as the priority for storing the cached image.\nGiven we have got a cluster to adopt the hosts into and a host profile to provision and make the hosts useful (somewhat, this rabbit hole goes deep so spend time getting your host profile right) - we will update our Auto Deploy Rule to make it add all hosts into TestClusterPleaseIgnore and thus, automatically apply the Host Profile and make it production ready.\nLet\u0026rsquo;s remove the rule we created earlier from the active rule set (If you want to delete the rule altogether append with -Delete):\nRemove-DeployRule InitialBootRule And create a new rule with multiple arguments in the -Item field to represent Image Profile and Cluster:\nNew-DeployRule -Name \u0026#34;ProductionRule\u0026#34; -Item \u0026#34;ESXi-6.0.0-20160302001-standard\u0026#34;,TestClusterPleaseIgnore -AllHosts This rule will boot all hosts to the Image Profile we selected before, then, add them to the cluster TestClusterPleaseIgnore which will in turn attach the host profile to the host on bootup.\nWe now need to add the rule to our active rule set to deploy it:\nAdd-DeployRule ProductionRule Get-DeployRuleSet And that\u0026rsquo;s it, reboot the host and it should boot into ESXi, apply customisations and join the cluster.\n \nIn the words of Tag Team, \u0026ldquo;Whoomp, There it is\u0026rdquo;.\n \nIf you have any suggestions for further customisations or nice scenarios you have used Auto Deploy in, I\u0026rsquo;d love to hear about them in the comments!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/automation/configuring-auto-deploy-stateless-caching-vsphere-6-0/","summary":"Following on from my previous post on configuring custom ESXi images for PXE deployment, it piqued my interest again in Auto Deploy, now that I have a lab large enough (enough physical failure domains) to justify auto-deploy I figured i\u0026rsquo;d give it another go. I have chosen to implement stateless caching as it will allow the hosts to boot from the last used ESXi image they had if the PxE/AutoDeploy server goes down - then when it comes back up will pull the new version, this accounts for a total infrastructure outage and still allows the hosts to be bootable.","title":"Configuring Auto Deploy Stateless Caching in vSphere 6.0"},{"content":"Introduction I have recently been working on a larger scale platform for my employer, it requires quick deployments of environments on VSAN with some standardised VIBs added in, initially we were doing this with a standard ESXi ISO install through iDRAC and then installing vCenter, vSphere Update Manager and pushing the VIBs to the hosts via that.\nThis is clearly a sub-optimal process and given our dedicated lab environment, we wanted to be able to spin up/down environments a bit more quickly - so we looked to optimising the install process and making production ready as the first step (as most people know, VSAN has some stringent HCL requirements when it comes to drivers and firmware).\nPXE boot has always been traditional for larger scale deployments of kit and VMware very helpfully offer an installer customisation tool called ImageBuilder, which is a PowerCLI module made to allow you to build customised images with VIBs/drivers and extensions slip-streamed into the install like you would do for large scale Windows deployments.\nThere are a few concepts in ImageBuilder,:\nVIBs - which are driver/extensions for ESXi like you deploy with VUM/esxcli ImageProfiles - which are a collection of VIBs and components that make up an image Depots - A collection of VIBs and ImageProfiles\n \nSo to get into it, you need PowerCLI installed (latest at time of writing is 6.3 Release 1) and an offline ESXi depot - you can get this from the ESXi download page:\n \nI usually create a directory (C:\\Depot) to house all the various components used in the image building process with the following folder structure:\n \nSo, put the offline depot you downloaded into the Input folder and drivers or VIBs to slipstream into the VIBs folder.\nThe next step has two ways, the easy way and the hard way - I initially did it the hard way before I learned of the other so let\u0026rsquo;s start with that:\nThe hard way (CLI) Open up PowerCLI as Administrator and change your execution policy:\nSet-ExecutionPolicy Unrestricted Next we are going to load up our depot into ImageBuilder:\nPowerCLI C:\\Depot\u0026gt; Add-EsxSoftwareDepot -DepotUrl C:\\Depot\\Input\\ESXi600-201601001.zip Depot Url --------- zip:C:\\Depot\\Input\\ESXi600-201601001.zip?index.xml PowerCLI C:\\Depot\u0026gt; We can run the below to view what packages are part of the depot and then pull back the existing image profiles:\nGet-EsxSoftwarePackage Get-EsxImageProfile Name Vendor Last Modified Acceptance Level ---- ------ ------------- ---------------- ESXi-6.0.0-20160104001-stan... VMware, Inc. 28/12/2015 2... PartnerSupported ESXi-6.0.0-20160104001-no-t... VMware, Inc. 28/12/2015 2... PartnerSupported ESXi-6.0.0-20160101001s-sta... VMware, Inc. 28/12/2015 2... PartnerSupported ESXi-6.0.0-20160101001s-no-... VMware, Inc. 28/12/2015 2... PartnerSupported If we run Get-EsxImageProfile | fl we can see the full readout of the Image Profiles:\nName : ESXi-6.0.0-20160104001-standard Vendor : VMware, Inc. Author : Description : For more information, see http://kb.vmware.com/kb/2135120. CreationTime : 28/12/2015 20:28:21 ModifiedTime : 28/12/2015 20:28:21 ReadOnly : False VibList : {ima-qla4xxx 2.02.18-1vmw.600.0.0.2494585, sata-sata-sil 2.3-4vmw.600.0.0.2494585, lpfc 10.2.309.8-2vmw.600.0.0.2494585, lsi-mr3 6.605.08.00-7vmw.600.1.17.3029758...} AcceptanceLevel : PartnerSupported Guid : 8989d78eada111e594f10200ff6bd19a Rules : StatelessReady : True For reference, there are 4 profiles in this depot the difference between two is fairly obvious - VMware tools in one, not in the other - however the difference between the ESXi-6.0.0-20160104001 and ESXi-6.0.0-20160104001s designations is not so obvious, s as it turns out is a security patch release only you can check patch releases vs builds here.\nTo view all packages in a particular image profile run:\n(Get-EsxImageProfile -Name \u0026#34;Image Name Here\u0026#34;).VibList So let\u0026rsquo;s clone a profile to build out our customised image profile - I want the latest release standard build (with tools) so we\u0026rsquo;re going to use ESXi-6.0.0-20160104001-standard:\nNew-EsxImageProfile -CloneProfile ESXi-6.0.0-20160104001-standard -Name \u0026#34;ESXi-6.0.0-U1b-3380124-STC-Dell-Customised\u0026#34; -Vendor Your_Vendor_Name And if we run Get-EsxImageProfile again we will see our new profile:\nName Vendor Last Modified Acceptance Level ---- ------ ------------- ---------------- ESXi-6.0.0-20160101001s-sta... VMware, Inc. 28/12/2015 2... PartnerSupported ESXi-6.0.0-U1b-3380124-STC-... Novosco 28/12/2015 2... PartnerSupported ESXi-6.0.0-20160104001-no-t... VMware, Inc. 28/12/2015 2... PartnerSupported ESXi-6.0.0-20160104001-stan... VMware, Inc. 28/12/2015 2... PartnerSupported ESXi-6.0.0-20160101001s-no-... VMware, Inc. 28/12/2015 2... PartnerSupported Now let\u0026rsquo;s import each of the offline VIB packages into the depot (I find the best pace to get the up to date Dell VIBs is here):\nAdd-EsxSoftwareDepot -DepotUrl C:\\Depot\\VIBs\\VMW-ESX-6.0.0-lsi_mr3-6.903.85.00_MR-offline_bundle-3818071.zip Add-EsxSoftwareDepot -DepotUrl C:\\Depot\\VIBs\\OM-SrvAdmin-Dell-Web-8.3.0-1908.VIB-ESX60i_A00.zip Add-EsxSoftwareDepot -DepotUrl C:\\Depot\\VIBs\\ISM-Dell-Web-2.3.0-223.VIB-ESX60i_A00.zip Now check the VIBs were added to the depot (scroll to the bottom for our newly added packages):\nGet-EsxSoftwarePackage | Sort-Object CreationDate | ft . . . iSM 2.3.0.ESXi600-0000 Dell 14/02/2016 18... OpenManage 8.3.0.ESXi600-0000 Dell 15/02/2016 06... lsi-mr3 6.903.85.00-1OEM.600.0.0.27... Avago 25/04/2016 16... And add the VIBs to the image profile:\nAdd-EsxSoftwarePackage -ImageProfile ESXi-6.0.0-U1b-3380124-STC-Dell-Customised -SoftwarePackage iSM Add-EsxSoftwarePackage -ImageProfile ESXi-6.0.0-U1b-3380124-STC-Dell-Customised -SoftwarePackage OpenManage Add-EsxSoftwarePackage -ImageProfile ESXi-6.0.0-U1b-3380124-STC-Dell-Customised -SoftwarePackage lsi-mr3 We obviously have duplicates of the lsi-mr3 package as it comes with the offline bundle, but it would appear when we add as above it will add the latest version in the depot (ours). Let\u0026rsquo;s verify the packages were added to our profile (review the bottom of the list - should match the above packages):\n(Get-EsxImageProfile -Name \u0026#34;ESXi-6.0.0-U1b-3380124-STC-Dell-Customised\u0026#34;).VibList | Sort-Object CreationDate Now we can export the image profile to an offline installer (for AutoDeploy/PXE) or an ISO for standard installation with the -ExportToISO trigger - I\u0026rsquo;m using this for PXE so offline bundle it is:\nExport-EsxImageProfile -ImageProfile ESXi-6.0.0-U1b-3380124-STC-Dell-Customised -ExportToBundle -FilePath C:\\Depot\\Output\\ESXi-6.0.0-U1b-3380124-STC-Dell-Customised.zip And we\u0026rsquo;re done - it can now be extracted and used to PXE boot the hosts. But of course, there is the easy way\u0026hellip;\nThe easy way (Scripting) As always, someone\u0026rsquo;s made it easier - go and download the ESXi-Customiser-PS script from here: http://www.v-front.de/p/esxi-customizer-ps.html#download\nLeave the folder structure as above and cd C:\\Depot (assuming you placed the script here), i\u0026rsquo;m also asuming you have an offline bundle downloaded to the Input directory and all your VIBs are downloaded and in the VIBs directory - now run:\n.\\ESXi-Customizer-PS-v2.4.ps1 -izip C:\\Depot\\Input\\ESXi600-201601001.zip -pkgDir C:\\Depot\\VIBs\\ -ozip C:\\Depot\\Output\\ This takes our input offline bundle, adds all VIBs in a directory to it and outputs to the Output directory as per output below:\nScript to build a customized ESXi installation ISO or Offline bundle using the VMware PowerCLI ImageBuilder snapin (Call with -help for instructions) Logging to C:\\Users\\mgray\\AppData\\Local\\Temp\\ESXi-Customizer-PS.log ... Running with PowerShell version 5.1 and VMware vSphere PowerCLI 6.3 Release 1 build 3737840 Adding base Offline bundle .\\Input\\ESXi600-201601001.zip ... [OK] Getting Imageprofiles, please wait ... [OK] Using Imageprofile ESXi-6.0.0-20160104001-standard ... (dated 12/28/2015 20:28:21, AcceptanceLevel: PartnerSupported, For more information, see http://kb.vmware.com/kb/2135120.) Loading Offline bundles and VIB files from .\\VIBs\\ ... Loading C:\\Depot\\VIBs\\ISM-Dell-Web-2.3.0-223.VIB-ESX60i_A00.zip ... [OK] Add VIB iSM 2.3.0.ESXi600-0000 [OK, added] Loading C:\\Depot\\VIBs\\OM-SrvAdmin-Dell-Web-8.3.0-1908.VIB-ESX60i_A00.zip ... [OK] Add VIB OpenManage 8.3.0.ESXi600-0000 [OK, added] Loading C:\\Depot\\VIBs\\VMW-ESX-6.0.0-lsi_mr3-6.903.85.00_MR-offline_bundle-3818071.zip ... [OK] Add VIB lsi-mr3 6.903.85.00-1OEM.600.0.0.2768847 [OK, replaced 6.605.08.00-7vmw.600.1.17.3029758] Exporting the Imageprofile to \u0026#39;C:\\Depot\\Output\\\\ESXi-6.0.0-20160104001-standard-customized.zip\u0026#39;. Please be patient ... All done. And that\u0026rsquo;s it for the easy way, fully patched offline bundle ready for deploy - I know what i\u0026rsquo;m doing in future! :)\nI have an article on enabling the PXE boot options on Fortigate that is largely uniform with other platforms too.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/building-customised-esxi-image-pxe-installation/","summary":"Introduction I have recently been working on a larger scale platform for my employer, it requires quick deployments of environments on VSAN with some standardised VIBs added in, initially we were doing this with a standard ESXi ISO install through iDRAC and then installing vCenter, vSphere Update Manager and pushing the VIBs to the hosts via that.\nThis is clearly a sub-optimal process and given our dedicated lab environment, we wanted to be able to spin up/down environments a bit more quickly - so we looked to optimising the install process and making production ready as the first step (as most people know, VSAN has some stringent HCL requirements when it comes to drivers and firmware).","title":"Building a customised ESXi image for PXE installation"},{"content":"I have been testing out Runecast Analyzer in my lab recently - it\u0026rsquo;s pretty badass, you can set it up to scan your virtual infrastructure at a vCenter level and will scan your vC, VMs and hosts looking for KBs that may apply, security compliance and best practises.\n \nAs you can see my lab isn\u0026rsquo;t exactly a model config when it comes to any of these things:\n \nIt\u0026rsquo;s really very cool, syslogging is also built in, if you add it as a syslog target to your hosts (RCA can do this automatically too) it will monitor the syslogs incoming and search the KB database for any matching problems - I actually found that some of my iSCSI paths weren\u0026rsquo;t coming up after failover due to this!\nSo, this is all well and good, but why am I talking about Runecast? It is the thing that prompted my to look at the vSphere 6.0 U2 bug that relates to VMXNET3 adapters in this KB - I had vSphere Update Manager installed so decided to update as it is trivial.\nMade sure VUM was using the latest patches with a \u0026ldquo;Download Now\u0026rdquo; and hit the vCenter root object, navigated to Manage -\u0026gt; Update Manager and scanned all objects against the attached baselines, all seemed to be going well then it bombed out at the end with Could not scan host and a little more digging (scanned an individual host) yielded Error code: 99.\nSo diving through the VUM logs on the Windows guest the agent was installed on at:\nC:\\Users\\All Users\\VMware\\VMware Update Manager\\Logs The log file we are concerned with is the latest available that matches the filename vmware-vum-server-log4cpp.log roughly, open it up in notepad++ or another text editor and run another scan in vCenter. We should be able to see a line similar to the one here:\n[2016-05-15 00:47:01:772 \u0026#39;SingleHostScanTask.SingleHostScanTask{14}\u0026#39; 4292 ERROR] [singleHostScanTask, 399] SingleHostScan caught exception: 99 with code: 129 A few lines later we can see this:\n[2016-05-15 00:47:02:035 \u0026#39;HostUpdateDepotManager\u0026#39; 4016 ERROR] [hostErrorHandler, 73] esxupdate error, version: 1.50, operation: Scan, host: mgmt01.lab.mylesgray.io, entityName: host-661 error code: 99, desc: Cannot merge VIBs Dell_bootbank_OpenManage_8.3.0.ESXi600-0000, Dell_bootbank_OpenManage_8.3.0.ESXi600-0000 with unequal payloads attributes: ([OpenManage: 7807.439 KB], [OpenManage: 7809.081 KB]) This is telling us exactly the reason why the scan cannot complete:\nCannot merge VIBs Dell_bootbank_OpenManage_8.3.0.ESXi600-0000, Dell_bootbank_OpenManage_8.3.0.ESXi600-0000 with unequal payloads attributes There is a VMware KB for this behaviour here, it is also referenced on Dell\u0026rsquo;s forums with no resolution.\nSo, to quickly fix the problem I reinitialised the VUM database by shutting down the VUM service on the Windows box, opening an elevated command prompt, navigating to the VUM installation folder and running the following command, per this KB:\nvciInstallUtils.exe -O dbcreate -C . -L . I\u0026rsquo;m sure some of you are wondering, why not just remove the VUM Baseline I created for the Dell iSM and OMSA VIBs and re-scan?\nI had of course tried this, but the patches still exist in the VUM repo, I had not found any concrete method for removing a patch from the VUM repo DB, so a nuke of the DB it was.\nAfter that operation completed, I associated critical and non-critical patch baselines to the vCenter root object and re-scanned and success!\nHowever, this did solve the initial goal (update esx-base on all hosts to account for the VMXNET3 adapter bug), but now we have a problem in that, I have the Dell OMSA 8.3.0 VIB installed on all hosts already and would like to continue distributing this with VUM.\nIt would appear from the before threads I found that the VIB installed on the hosts and the VIB with the same patch ID pulled from the Dell VUM depot (http://vmwaredepot.dell.com/index.xml) were different as shown in the VUM logs on the agent Windows VM:\nunequal payloads attributes: ([OpenManage: 7807.439 KB], [OpenManage: 7809.081 KB]) The easiest solution I could think of to make the VIB compliant with the Dell VUM Depot was to just remove the VIB from each host manually with esxcli:\n#find out what the VIB name is [root@esxi01:~] esxcli software vib list | grep Dell OpenManage 8.3.0.ESXi600-0000 Dell PartnerSupported 2016-04-10 Now that we have the VIB name (OpenManage) we can remove it from the host:\n#enter host into maint mode and allow DRS to vMotion VMs [root@esxi01:~] esxcli system maintenanceMode set --enable true #remove Dell OMSA 8.3.0 VIB [root@esxi01:~] esxcli software vib remove --vibname=OpenManage Removal Result Message: The update completed successfully, but the system needs to be rebooted for the changes to be effective. Reboot Required: true VIBs Installed: VIBs Removed: Dell_bootbank_OpenManage_8.3.0.ESXi600-0000 VIBs Skipped: #reboot the host [root@esxi01:~]reboot When the host comes back up exit maint mode:\n[root@esxi01:~] esxcli system maintenanceMode set --enable false Add the Dell VUM Depot back into the VUM config, run \u0026ldquo;Download Now\u0026rdquo; to grab the patches:\n \nAdd to baseline:\n \nAttach to the host we just removed the VIB from to test and run a rescan on it:\n \nNow that VUM is successfully rescanning the host we can again stage and remediate the host(s):\n \nHost comes back up and ran another re-scan there we have it:\n \nHopefully this will help some poor souls out there who wasted time on this too!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/vsphere-update-manager-cannot-scan-host/","summary":"I have been testing out Runecast Analyzer in my lab recently - it\u0026rsquo;s pretty badass, you can set it up to scan your virtual infrastructure at a vCenter level and will scan your vC, VMs and hosts looking for KBs that may apply, security compliance and best practises.\n \nAs you can see my lab isn\u0026rsquo;t exactly a model config when it comes to any of these things:","title":"vSphere Update Manager – Cannot Scan Host"},{"content":"After a long an arduous certification and regression testing process following many problems with LSI 3108 based controllers that I have been using for VSAN they are finally VSAN 6.2 certified.\nHaving seen and opened multiple tickets about strange controller behaviors (hot add controller do VMware have released a FW/HW and Software combo that, according to a highly regarded VMware internal storage resource:\n Its certainly the most tested combination of a firmware/driver/controller ever at this point [\u0026hellip;] My understanding is the reason this took so long is they didn’t just fix the big issue, but also minor ones too, and any minor regressions\n I have been following a few VMware KBs with a keen eye in particular, it\u0026rsquo;s worth giving these a read over so you are aware of all the intricacies involved:\nCertification of Dell PERC H730 and FD332-PERC Controllers with VSAN 6.x (2144614) https://kb.vmware.com/selfservice/microsites/search.do?language=en_US\u0026amp;cmd=displayKC\u0026amp;externalId=2144614\nRequired VSAN and ESXi configuration for controllers based on the LSI 3108 chipset (2144936) https://kb.vmware.com/selfservice/search.do?cmd=displayKC\u0026amp;docType=kc\u0026amp;docTypeID=DT_KB_1_1\u0026amp;externalId=2144936\nAnd the HCL for the particular controller I am using (the Dell H730 mini): http://www.vmware.com/resources/compatibility/detail.php?deviceCategory=vsanio\u0026amp;productid=34859\n \nIt should be noted as well as upgrading the firmware and driver on the controller and VSAN hosts, the diskIoTimeout and diskIoRetryFactor advanced parameters should also still be implemented when rolling out with this controller from this KB.\nSo, go forth and install, reap the benefits of VSAN 6.2 of which there are many!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/lsi3108-based-controllers-now-vsan-6-2-certified/","summary":"After a long an arduous certification and regression testing process following many problems with LSI 3108 based controllers that I have been using for VSAN they are finally VSAN 6.2 certified.\nHaving seen and opened multiple tickets about strange controller behaviors (hot add controller do VMware have released a FW/HW and Software combo that, according to a highly regarded VMware internal storage resource:\n Its certainly the most tested combination of a firmware/driver/controller ever at this point [\u0026hellip;] My understanding is the reason this took so long is they didn’t just fix the big issue, but also minor ones too, and any minor regressions","title":"LSI3108 based controllers now VSAN 6.2 Certified"},{"content":"I\u0026rsquo;ve been playing around with VMware Integrated Openstack recently and wanted to see what the upgrade experience for bugfixes and point releases is like, happy to say - it\u0026rsquo;s quite easy.\nFirstly, download the .deb package from my.vmware.com and upload it to the VIO management appliance - I used FileZilla for this, the username is viouser and password is what you set during OVF deploy.\nI just uploaded mine to the viouser home folder /home/viouser/\n \nNext, SSH into the VIO management appliance and import the patch:\nviopatch add -l vio-patch-203_2.0.3.3720171_all.deb Then to show the patch is listed:\nviouser@vio1:~$ viopatch list Name Version Type Installed ------------- ------------- ------ ----------- vio-patch-203 2.0.3.3720171 infra No Now, we\u0026rsquo;re going to install the patch:\nsudo viopatch install --patch vio-patch-203 --version 2.0.3.3720171 This process took around 15 minutes in my case, the API endpoint will be down for the duration so any replies will be with Error 503.\nI opened another SSH session during the install and ran top to monitor progress, you will see the CPU utilisation cycle through Java and Ansible as it deploys to the cluster itself.\n \nAnd that\u0026rsquo;s it, if you see the following you\u0026rsquo;re good to go:\nviouser@vio1:~$ sudo viopatch install --patch vio-patch-203 --version 2.0.3.3720171 [sudo] password for viouser: Installing patch vio-patch-203 version 2.0.3.3720171 done Installation complete for patch vio-patch-203 version 2.0.3.3720171 Log out of the Web Client and back in and verify that you\u0026rsquo;re now operating at 2.0.3:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/cloud/upgrading-vmware-integrated-openstack-v2-0-1-v2-0-3/","summary":"I\u0026rsquo;ve been playing around with VMware Integrated Openstack recently and wanted to see what the upgrade experience for bugfixes and point releases is like, happy to say - it\u0026rsquo;s quite easy.\nFirstly, download the .deb package from my.vmware.com and upload it to the VIO management appliance - I used FileZilla for this, the username is viouser and password is what you set during OVF deploy.\nI just uploaded mine to the viouser home folder /home/viouser/","title":"Upgrading VMware Integrated Openstack from v2.0.1 to v2.0.3"},{"content":"My lab is not what you\u0026rsquo;d call typical in any way, a kit list will i\u0026rsquo;m sure come up in a future post, but I have what is analogous to a \u0026ldquo;primary\u0026rdquo; DC and a \u0026ldquo;backup\u0026rdquo; DC with regard to physical premises. The problem is, I live in the secondary with other human beings, meaning power draw and noise are to be kept to a minimum.\nI also don\u0026rsquo;t have the luxury of having a /29 of public addresses at the second site, or even a static address at all.\nHowever, I still want to be able to VPN/SSH in while i\u0026rsquo;m not there, so I needed something low-power, cheap, quiet, but quick enough to do a few things:\n Run OpenVPN Run some kind of DynamicDNS solution Be on all the time with minimal power draw Not replace my standard Virgin Media modem/router combo  A few things went through my head and it dawned on my I had bought a few Raspberry Pi 3\u0026rsquo;s for use in various projects - This was definitely a \u0026ldquo;goer\u0026rdquo;.\nSo to get started my requirements list is actually quite minimal;\n Raspberry Pi 3 (2 will likely be fast enough also) Ethernet cable/Wifi Power SD Card (64GB) KVM of some kind  Let\u0026rsquo;s get cracking then, this article will focus on the dynamic DNS implementation, plenty of tutorials out there for OpenVPN.\nThe first step is to download NOOBS (I use lite-for network install) and burn it to your Pi\u0026rsquo;s SD card, I use an application for OSX called ApplePi-Baker, it makes the process of formatting and making bootable very simple. Plug in your SD card to your computer, select from the list and click Prep for NOOBS and click OK because we\u0026rsquo;re a bunch of pros\u0026hellip;\n \nExtract the NOOBS zip file and copy/paste all contents into the root of the SD card.\n \nThen eject the disk, plug it into your Pi (you always safe-eject right?).\n \nHook up whatever you are using for KVM and connectivity and get NOOBS to install Raspbian for you - if you need a guide, here.\n \nNow that Raspbian is installed, we are going to SSH into the Pi so we can work on it remotely: ssh pi@your.ip.address.here and the password is raspberry. Now we can get down to business.\nFirst up I wanted to get the Cloudflare portion sorted - if you haven\u0026rsquo;t got Cloudflare as your DNS provider, i\u0026rsquo;d need to ask why then tell you to sign up. They offer a slew of services from CDN, Anti-DDoS, Always-On for free and offer an API as standard to add/remove/update your DNS rules (see where i\u0026rsquo;m going with this?).\nSign in to your Cloudflare account and go to my account, scroll down to the API key section and record your Global API Key we will need this soon.\nGo back to your zone and add an A-record for your current public IP (or any IP, it\u0026rsquo;s going to be programatically set anyway), for mine I have just used belfast.\n \nNext up, on the Pi sudo bash into root and as it goes, someone has already done it (and most likely better) so, I forked it, fixed a small bug and set the TTL to 2 minutes. You can just wget the file into a shell script:\nwget https://gist.githubusercontent.com/MylesGray/b6b3b9b6b373de6a90e1f2132cccfade/raw/abda700b0dd5a4eb68c64727b1c2a98da284891b/cf-ddns.sh /usr/local/bin/cf-ddns.sh Make it executable:\nchmod +x /usr/local/bin/cf-ddns.sh Next we are going to set up the params inside the file:\nnano /usr/local/bin/cf-ddns.sh And fill in the following params and save the file:\n# API key, see https://www.cloudflare.com/a/account/my-account, # incorrect api-key results in E_UNAUTH error CFKEY= # Zone name, will list all possible if missing, eg: example.com CFZONE= # Username, eg: user@example.com CFUSER= # Hostname to update, eg: homeserver.example.com CFHOST= Now we can run it and check that it works (if not, fix what it complains about or go up and re-check your steps):\n/usr/local/bin/cf-ddns.sh Hopefully you see something like this:\nroot@raspberrypi:/home/pi# /usr/local/bin/cf-ddns.sh Missing DNS record ID fetching from Cloudflare... =\u0026gt; Found CFID=********* , advising to save this to /usr/local/bin/cf-ddns.sh or set it using the -i flag Updating DNS to your.public.ip.address Updated succesfuly! You can verify this in the Cloudflare portal of course. Now let\u0026rsquo;s make it automatic edit the crontab with your editor of choice:\ncrontab -e I wanted mine to run every 2 minutes:\n*/2 * * * * /usr/local/bin/cf-ddns.sh \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 Anything running into OpenVPN setup and router forwarding is too situationally specific so i\u0026rsquo;m going to leave it here for now, hope this helps with whatever your use case may be!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/raspberry-pi-dynamic-dns-using-cloudflare/","summary":"My lab is not what you\u0026rsquo;d call typical in any way, a kit list will i\u0026rsquo;m sure come up in a future post, but I have what is analogous to a \u0026ldquo;primary\u0026rdquo; DC and a \u0026ldquo;backup\u0026rdquo; DC with regard to physical premises. The problem is, I live in the secondary with other human beings, meaning power draw and noise are to be kept to a minimum.\nI also don\u0026rsquo;t have the luxury of having a /29 of public addresses at the second site, or even a static address at all.","title":"Raspberry Pi with Dynamic-DNS using Cloudflare"},{"content":"I found myself in the position recently whereby I had two hosts I bought off eBay (as one does for labs), they arrived, I had great plans\u0026hellip; But no iDRAC Enterprise :(\nWhile the iDRAC Ent cards were on their way to me I couldn\u0026rsquo;t help but want to install ESXi on these things so they were ready to go (old Dell R610s are seriously good value now). One slight problem. No iDRAC Ent means no virtual console, or virtual media. I don\u0026rsquo;t have any USB drives because I use cloud storage for that kind of thing and they had CD drives - what is this, the dark ages, does my mac look like it has room for a CD burner?\nSo in my impatience I wanted a solution and this is what I came up with; I\u0026rsquo;m bad for keeping old tech around incase they one day may come in handy again - and my old Samsung Galaxy Nexus fit the bill perfectly - so after an hour on the charger and years of updates being installed it was ready to rock.\nIn case you haven\u0026rsquo;t gathered by now the plan is to use the Android phone as a USB storage device to boot the servers off and install my ISO(s).\nThere are a few pre-requisites:\n Android Phone USB Data cable (yeah, got bitten by the \u0026ldquo;power only\u0026rdquo; USB cables) DriveDroid Windows install with Rufus on it  I\u0026rsquo;m not going to nerd out too much, but Rufus is absolutely flawless, I have never used a program that makes bootable USBs so easily, without all that Floppy disk ROM faff.\nSo, start your Android phone, install the DriveDroid app, click the + button and hit Create blank image... this will essentially create a blanked out space on the internal storage of the phone to which you can write an ISO image.\n \nNext we will give it a name and a size - this is just for your own reference, as you can see mine is called ESXI6.0U2.iso and i\u0026rsquo;ve given it a size of 768MB which I know is larger than the ISO that will be extracted to it.\n \nYou can view image creation progress in the notification center.\n \nNext, we are going to click on the image we just created and choose Writable USB as the type, this will then mount the device, as a writable USB to your Mac/PC/VM.\n \nIn my case, I run Windows as a VM, so I attached the USB device to the VM and it shows up as such. Just hit Cancel here as Rufus will do this for us.\n \nNow we can run Rufus and it should detect the USB disk, ensure you pick the correct one then set up as below (be sure the Create a bootable disk option is using ISO Image), select the ISO for ESXi then hit Start.\n \nYes, we want to wipe the device and the progress should begin.\n \nOnce that is done we can close Rufus, and should see our ISO installer presented as a USB to the host operating system again - now we\u0026rsquo;re ready to roll.\n \nBoot the server/desktop into BIOS, ensure that USB emulation mode is Hard Drive, reboot into BIOS Boot Manager and choose the USB device as the boot drive - It should boot right into ESXi\u0026rsquo;s installer.\nGiven how easy it was to create images and how easy it is to switch between them with DriveDroid i\u0026rsquo;m going to put a new more standard ISOs on there, Windows 10, Ubuntu and the like.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/need-multi-os-bootable-usb-use-android-phone/","summary":"I found myself in the position recently whereby I had two hosts I bought off eBay (as one does for labs), they arrived, I had great plans\u0026hellip; But no iDRAC Enterprise :(\nWhile the iDRAC Ent cards were on their way to me I couldn\u0026rsquo;t help but want to install ESXi on these things so they were ready to go (old Dell R610s are seriously good value now). One slight problem.","title":"In need of a multi-OS, bootable USB? Use an Android phone."},{"content":"It\u0026rsquo;s sometimes necessary to clone VMs when you don\u0026rsquo;t have a vCenter, either because you plain don\u0026rsquo;t have one in a small customer environment or you are doing a deploy and don\u0026rsquo;t have vCenter deployed yet - you\u0026rsquo;ve created a template VM for Windows or such and want to roll out some DCs and management VMs before your vCenter deploy such that you have DNS etc.\nLuckily there is a way to do this through the ESXi host directly, the method I use that I find effective is:\nCopy the .vmx file over and rename it, also rename all entries inside it from the previous VM to the name of the new VM. Copy the vmdk over with vmkfstools as such:\nvmkfstools -i /vmfs/volumes/dc1-r2-mgmt1-das/Windows2012R2-Template/Windows2012R2-Template.vmdk /vmfs/volumes/dc1-r2-mgmt1-das/dc1-mgmt-mgmt01/dc1-mgmt-mgmt01.vmdk -d zeroedthick This will copy over the .vmdk, both the flat file and the metadata file - as we have already changed all the references in our .vmx we can now add the VM to inventory through the datastore browser (right click on .vmzx -\u0026gt; Add to Inventory), power on the VM - to see this prompt:\n \nWe, of course, copied the VM, so click OK - this will adjust some settings in the vmx such that there are no duplicate properties such as MAC address across VMs.\nThe VM will now power on as a clone of the previous.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/clone-vmdk-without-vcenter-esxi-freestandalone-esxi/","summary":"It\u0026rsquo;s sometimes necessary to clone VMs when you don\u0026rsquo;t have a vCenter, either because you plain don\u0026rsquo;t have one in a small customer environment or you are doing a deploy and don\u0026rsquo;t have vCenter deployed yet - you\u0026rsquo;ve created a template VM for Windows or such and want to roll out some DCs and management VMs before your vCenter deploy such that you have DNS etc.\nLuckily there is a way to do this through the ESXi host directly, the method I use that I find effective is:","title":"Clone VMDK without vCenter (ESXi Free/Standalone ESXi)"},{"content":"Spent longer than necessary messing with vRealize Orchestrator and trying to get it to display the plugin in vCenter server appliance 6.0 U1, you can review my trials and tribulations here:\nhttps://communities.vmware.com/thread/523397?src=vmw_so_vex_mgray_1080\n I have been trying to deploy vRealize Orchestrator 6.0.3 with my VCSA 6.0 U1 instance (supported according to compatibility matrix), the symptoms are almost exactly the same as this post:\nRe: Installing vRO v6.01 but not showing in web client\nCan run workflows, auth using the client, everything, just no plugin in web client.\ncom.vmware.vco isn\u0026rsquo;t showing at all in the MOB browser however.\nI have tried cat-ing the virgo.log file on the VCSA but nothing relating to vco-plugin comes up when I tell vro to register the extension with vcenter.\nAll that shows in the web client is the getting started page, nothing else - i have tried restarting the web client service and the appliance, also rebooting the vro appliance - nothing works.\n As you can see, even OOTB config is broken for this release.\nI stumbled across this article:\nhttp://orchestration.io/2015/09/28/deploying-vrealize-orchestrator-6-0-3/\nAnd, of course, I was stumbling at the simplest of hurdles, when registering the appliance extension with vCenter and executing the workflow you are prompted for \u0026ldquo;External address to advertise this Orchestrator\u0026rdquo; - I was just putting in my FQDN, apparently, this is not how we do.\nInstead of vro1.lab.mylesgray.io I needed to put in https://vro1.lab.mylesgray.io:8281.\nRe-registered and BAM, working right off the bat!\n \nThanks to Chris Greene (@orchestrationio) for documenting this better than VMware.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/ref-configure-vrealize-orchestrator-6-0-3-with-vcenter-6-0-u1/","summary":"Spent longer than necessary messing with vRealize Orchestrator and trying to get it to display the plugin in vCenter server appliance 6.0 U1, you can review my trials and tribulations here:\nhttps://communities.vmware.com/thread/523397?src=vmw_so_vex_mgray_1080\n I have been trying to deploy vRealize Orchestrator 6.0.3 with my VCSA 6.0 U1 instance (supported according to compatibility matrix), the symptoms are almost exactly the same as this post:\nRe: Installing vRO v6.01 but not showing in web client","title":"Configure vRealize Orchestrator 6.0.3 with vCenter 6.0 U1"},{"content":"I have been working with VSAN in the lab recently and had the need to get some deeper stats on the inner operations.\nI had upgraded the lab to ESXi 6.0 U1 and vCenter 6.0 U1 and for the life of me couldn\u0026rsquo;t get the RVC console in the VCSA to work per the VMware KB.\nIn particular it just wouldn\u0026rsquo;t log in with this line, even with the correct password:\nrvc username@localhost and this didn\u0026rsquo;t work either:\nrvc administrator@localhost Then I had a sort of epiphany, what if I append the SSO domain to the start and target it at the localhost?\nrvc administrator@vsphere.local@localhost Sure, it looks janky, but it worked!\n \nIt appears to need the SSO domain (whatever yours is - could obviously be different from the vsphere.local default) appended to the username then target the rvc at localhost.\nHope this helps, had me stumped for a bit for sure!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/vsan-observer-rvc-in-vcenter-appliance-6-0-u1/","summary":"I have been working with VSAN in the lab recently and had the need to get some deeper stats on the inner operations.\nI had upgraded the lab to ESXi 6.0 U1 and vCenter 6.0 U1 and for the life of me couldn\u0026rsquo;t get the RVC console in the VCSA to work per the VMware KB.\nIn particular it just wouldn\u0026rsquo;t log in with this line, even with the correct password:","title":"VSAN Observer RVC in vCenter Appliance 6.0 U1"},{"content":"I am very passionate about my photography, usually I\u0026rsquo;ll go on a few trips a year just for that and this was one of those instances. I\u0026rsquo;ve decided I might as well start posting them up here so I have a nice centralised location I can give to people that want to see them.\nWe visited quite a number of places, most prolific in my mind was DUGA-3 which is hands down the single largest free standing structure I\u0026rsquo;ve ever climbed at 160m, It\u0026rsquo;s very hard to get the scale of it in any of the pictures, but just know, the ladders were very rusty and large sections were missing as you climbed up, got to the top though, much to the dismay of our guide Igor, who, according to himself only ever went halfway up and that was more than enough!\nSoloEast did an amazing job and i\u0026rsquo;ll definitely be back!\nAnyway, without further-adoo, here was my two days inside the Chernobyl nuclear exclusion zone (in photos):\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/personal/photography-trip-to-chernobyl-ukraine/","summary":"I am very passionate about my photography, usually I\u0026rsquo;ll go on a few trips a year just for that and this was one of those instances. I\u0026rsquo;ve decided I might as well start posting them up here so I have a nice centralised location I can give to people that want to see them.\nWe visited quite a number of places, most prolific in my mind was DUGA-3 which is hands down the single largest free standing structure I\u0026rsquo;ve ever climbed at 160m, It\u0026rsquo;s very hard to get the scale of it in any of the pictures, but just know, the ladders were very rusty and large sections were missing as you climbed up, got to the top though, much to the dismay of our guide Igor, who, according to himself only ever went halfway up and that was more than enough!","title":"Photography Trip to Chernobyl, Ukraine"},{"content":"While doing some research for NSX setups I found the urge to delve deeper into the calculations of some of ESXi\u0026rsquo;s load-balancing and teaming types that are available, below I have outlined the scenarios, calculations (where appropriate) and recommendations when it comes to choosing a NIC load balancing and teaming type.\nVirtual Port ID Your VMs all have single vNICs, You have multiple physical switches, the pNICs from the servers are striped across them, the switches aren\u0026rsquo;t stacked/don\u0026rsquo;t have an awareness of each other/are from different vendors (point here, completely different, no collaboration between equipment - any brownfield environment).\nWhy? Simple, a VM, when it is spun up is assigned out a VPID each VM gets a different port, when the number of VMs \u0026gt; number of NICs, cycle back to the start again.\nIt doesn\u0026rsquo;t break and will work anywhere, no special switch config or awareness required network-side.\nExample Server has 4 physical NICs, we are spinning up 5 VMs:\nVM1 -\u0026gt; pNIC1 VM2 -\u0026gt; pNIC2 VM3 -\u0026gt; pNIC3 VM4 -\u0026gt; pNIC4 VM5 -\u0026gt; pNIC1 Cons VM pinning to VPID means that if a super busy VM is on the same NIC as another busy VM, that\u0026rsquo;s just bad luck - nothing you can do about it.\nSource MAC Hash Same as scenario 1, except we want to account for VMs with multiple vNICs.\nWhy? Also the same as scenario 1, with the exception that VMs have multiple vNICs\nExample A host has 4 physical pNICs, we are spinning up 3x VMs with 2x vNICs each. The VMKernel does a calculation based on the MAC of the source vNIC. For 4 pNICs it will use 4 as the modulus to which it will test the MACs against. (because MAC addresses are just hexadecimal numbers) - let\u0026rsquo;s say:\nVM1-vNIC1 = 00:50:56:00:00:00 VM1-vNIC2 = 00:50:56:00:00:01 VM2-vNIC1 = 00:50:56:00:00:0a VM2-vNIC2 = 00:50:56:00:00:0b VM3-vNIC1 = 00:50:56:00:00:1e VM3-vNIC2 = 00:50:56:00:00:1f We would run mod(4) against each MAC to get the remainder, the remainder will be the pNIC ID that vNIC is assigned to. Excellent article here.\nConvert the hex to Base10:\nVM1-vNIC1 = 00:50:56:00:00:00 -\u0026gt; 345040224256 VM1-vNIC2 = 00:50:56:00:00:01 -\u0026gt; 345040224257 VM2-vNIC1 = 00:50:56:00:00:0a -\u0026gt; 345040224266 VM2-vNIC2 = 00:50:56:00:00:0b -\u0026gt; 345040224267 VM3-vNIC1 = 00:50:56:00:00:1e -\u0026gt; 345040224286 VM3-vNIC2 = 00:50:56:00:00:1f -\u0026gt; 345040224287 Run a modulus of number of NICs against it:\nVM1-vNIC1 -\u0026gt; 345040224256 mod 4 = 0 VM1-vNIC2 -\u0026gt; 345040224257 mod 4 = 1 VM2-vNIC1 -\u0026gt; 345040224266 mod 4 = 2 VM2-vNIC2 -\u0026gt; 345040224267 mod 4 = 3 VM3-vNIC1 -\u0026gt; 345040224286 mod 4 = 2 VM3-vNIC2 -\u0026gt; 345040224287 mod 4 = 3 The idea is we will end up with something like this (perfect scenario):\nVM1-vNIC1 -\u0026gt; 345040224256 mod 4 = 0 -\u0026gt; pNIC1 (vmnic0) VM1-vNIC2 -\u0026gt; 345040224257 mod 4 = 1 -\u0026gt; pNIC2 (vmnic1) VM2-vNIC1 -\u0026gt; 345040224266 mod 4 = 2 -\u0026gt; pNIC3 (vmnic2) VM2-vNIC2 -\u0026gt; 345040224267 mod 4 = 3 -\u0026gt; pNIC4 (vmnic3) VM3-vNIC1 -\u0026gt; 345040224286 mod 4 = 2 -\u0026gt; pNIC3 (vmnic2) VM3-vNIC2 -\u0026gt; 345040224287 mod 4 = 3 -\u0026gt; pNIC4 (vmnic3) Cons So the workloads are pretty-evenly balanced, but again we are at the mercy of vNIC placement not actual load on the pNIC.\nIP Hash Your physical switches that the hosts uplink to are stacked, or have stacking-like technologies (like Cisco vPC), if you have a single switch this will also work, or if you just have a pair of Dell 8024F/Cisco 3750-X that are stacked and create a LAG/Port Channel, and replicate the config on your vDS, that will also work.\nWhy? This method will balance connections based on source and destination IP addresses across pNICs so single guests communicating with clients on different IP addresses will be distributed across pNICs.\nExample It will make a hash of source and destination IP addresses, then run an bitwise xor and modulus on those based on the number of pNICs in the server, so if it\u0026rsquo;s 4 like the above example, it will run (hex1 xor hex2) mod (4). This ensures (roughly) that each connection between a single source and different destinations are distributed across the pNICs.\nObviously, the guest and client IP remain the same throughout that particular communication, so that connection will stay pinned to its calculated pNIC, if a pNIC goes down, re-calc is run across the remaining live pNICs, pretty neat.\nLet\u0026rsquo;s look at a practical example (Again, assuming host with 4 pNICs):\nClient1 -\u0026gt; VM1 (10.0.1.1 -\u0026gt; 10.0.1.200) Client1 -\u0026gt; VM2 (10.0.1.1 -\u0026gt; 10.0.1.201) Client2 -\u0026gt; VM1 (10.0.1.2 -\u0026gt; 10.0.1.200) Client3 -\u0026gt; VM1 (10.0.1.3 -\u0026gt; 10.0.1.200) Let\u0026rsquo;s convert the IP addresses to hex:\nClient1 = 10.0.1.1 -\u0026gt; 0x0A000101 Client2 = 10.0.1.2 -\u0026gt; 0x0A000102 Client3 = 10.0.1.3 -\u0026gt; 0x0A000103 VM1 = 10.0.1.200 -\u0026gt; 0x0A0001C8 VM2 = 10.0.1.201 -\u0026gt; 0x0A0001C9 Alright, let\u0026rsquo;s xor those values:\nClient1 -\u0026gt; VM1 (0A000101 xor 0A0001C8) = C9 = 201 Client1 -\u0026gt; VM2 (0A000101 xor 0A0001C9) = C8 = 200 Client2 -\u0026gt; VM1 (0A000102 xor 0A0001C8) = CA = 202 Client3 -\u0026gt; VM1 (0A000103 xor 0A0001C8) = CB = 203 And now run a modulus on the resulting base10 numbers:\nClient1 -\u0026gt; VM1 = (201 mod 4) = 1 = vmnic1 Client1 -\u0026gt; VM2 = (200 mod 4) = 0 = vmnic0 Client2 -\u0026gt; VM1 = (202 mod 4) = 2 = vmnic2 Client3 -\u0026gt; VM1 = (203 mod 4) = 3 = vmnic3 So, as you can see, even connections to the same VM, but from different clients will get distributed across pNICs. Therefore theoretically more than single pNIC throughput to one guest from multiple clients if connections are distributed across pNICs.\nCons Again, at the mercy of a very busy client + server connection loading up one pNIC, harder to configure, requires specific physical switch and vDS config, doesn\u0026rsquo;t \u0026ldquo;just work\u0026rdquo;.\nLBT/Physical NIC Load This is the only option that is utilisation aware, it also requires no special switch configuration (same as Virtual Port ID/MAC Hash).\nInitial placement of VMs uses the exact same calculation as Virtual Port ID.\nOnce a pNIC becomes 75% utilised for 30s then there will be a calculation run, and in a sort-of \u0026ldquo;network-DRS\u0026rdquo; kind of way, the connections will be shuffled around to try and create a more balanced pNIC load.\nLBT investigates RX and TX individually. So, if RX is at 99% and TX is at 1%, average being 50%, RX is above the 75% threshold, therefore, the pNIC is marked as saturated.\nWhy? It\u0026rsquo;s the only method that\u0026rsquo;s utilisation aware and actually balances load across pNICs.\nExample Take a server with 4 pNICs again, with the following pNIC utilisation levels:\nvmnic0 -\u0026gt; 70% utilised vmnic1 -\u0026gt; 80% utilised vmnic2 -\u0026gt; 50% utilised vmnic3 -\u0026gt; 65% utilised When the calculation runs, vmnic0, vmnic2, vmnic3 will be seen as candidates for rebalancing, LBT will rebalance as it sees fit, let\u0026rsquo;s say one particular VM is using 15% of the bandwidth on vmnic1, a rebalance would look like so:\nvmnic0 -\u0026gt; 70% utilised vmnic1 -\u0026gt; 65% utilised vmnic2 -\u0026gt; 65% utilised vmnic3 -\u0026gt; 65% utilised Pretty simple, however note, if you look at esxtop and find that you have a lot of traffic going out one vmnic and not others, this is because LBT only kicks in when a pNIC becomes saturated.\nThus you may end up with 3 pNICs with 0% utilisation and 1 pNIC with 72% utilisation, it just hasn\u0026rsquo;t cross the rebalancing threshold yet. But if it\u0026rsquo;s not causing contention, who cares?\nCons Requires Ent+ licensing because it requires a vDS to use this mode.\nLACP LACP mode allows you to use dynamic link aggregation groups from your physical networking infrastructure to your ESXi hosts.\nLAG balancing is yet another set of distribution methods, not load balancing methods, this is a common misconception.\nA list of all LAG distribution methods in ESXi (as of v5.5) can be found here.\nAn important thing to note about LACP/LAGs on vDSs:\n The LAG load balancing policies always override any individual Distributed Port group if it uses the LAG with exception of LBT and netIOC as they will override LACP policy, if configured.\n Basically, if you have Network IO Control enabled or LBT on a port group these will take precedence over LAG balancing policies, for obvious reasons, to quote VMware:\n These two configurations are going to load balance based on the traffic load which is better than LACP level load balancing.\n Why? You want to use dynamic LAGs from your physical network to your ESXi boxes, it will also allow VMs, (depending on the distribution type specified) and the workload running on the VM, to use more than 1 pNIC worth of bandwidth, whereas, if you were to use other methods (except IP-Hash which also has this trait) each VM will only be able to use 1 pNIC worth of bandwidth.\nExample As per our other examples, 1 server with 4 pNICs, we are using the Source and destination IP address and TCP/UDP port load balancing type. We will use a very \u0026ldquo;perfect\u0026rdquo; scenario, assuming that the calculation run will allow this method to work as optimally as possible.\nClient1:1000 -\u0026gt; VM1:2000 Client1:1001 -\u0026gt; VM1:2001 Client1:1002 -\u0026gt; VM1:2002 Client2:1000 -\u0026gt; VM1:2000 Because LACP-hashing calculations are usually firmware specific, and quite often a \u0026ldquo;secret-sauce\u0026rdquo; kind of thing we can\u0026rsquo;t do a calculation that will hold true across manufacturers, chipsets, even releases of the same software. So we will assume that it will work as optimally as possible.\nWhat we will see in our 4 pNIC server case is:\nClient1:1000 -\u0026gt; VM1:2000 = vmnic0 Client1:1001 -\u0026gt; VM1:2001 = vmnic1 Client1:1002 -\u0026gt; VM1:2002 = vmnic2 Client2:1000 -\u0026gt; VM1:2000 = vmnic3 Note: this is a very perfect scenario, in reality, it will likely be nothing close to this, however the law of averages will say this can of course occur in some environments.\nCons Some extra complexity at the physical network layer, and messing around with active/passive LACP sides, and Ent+ licensing is required as this is a vDS feature.\nHonestly, if you were licensed for vDS and didn\u0026rsquo;t require VMs to have the possibility of having over 1 pNIC worth of bandwidth, then you would just use LBT mode.\nConclusion If you\u0026rsquo;re licensed for vDS\n Use LBT, unless you have workloads that require more than 1 pNIC of bandwidth, then use LACP.  If you don\u0026rsquo;t have vDS licensing\n If your network uses teaming/stacked switches, use IP-Hash (if you don\u0026rsquo;t mind the extra complexity). If your VMs have multiple vNICs and you want to distribute them across pNICs use MAC Hash (on non-stacked switches). If you just have single vNICs and non-stacked switches, Virtual Port ID it is.  I hope this helped, any questions, drop me a line below!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/vmware-nic-load-balancing-and-teaming-the-math/","summary":"While doing some research for NSX setups I found the urge to delve deeper into the calculations of some of ESXi\u0026rsquo;s load-balancing and teaming types that are available, below I have outlined the scenarios, calculations (where appropriate) and recommendations when it comes to choosing a NIC load balancing and teaming type.\nVirtual Port ID Your VMs all have single vNICs, You have multiple physical switches, the pNICs from the servers are striped across them, the switches aren\u0026rsquo;t stacked/don\u0026rsquo;t have an awareness of each other/are from different vendors (point here, completely different, no collaboration between equipment - any brownfield environment).","title":"VMware NIC Load Balancing and Teaming, the Math"},{"content":"If you\u0026rsquo;ve been reading my other posts of late, you will have gathered I\u0026rsquo;ve been building a new lab. I say \u0026ldquo;new\u0026rdquo;, the last one was a single R710 with a ReadyNas Ultra 6 attached. So essentially, this is my first REAL lab.\nIt\u0026rsquo;s mostly based on Dell hardware; it\u0026rsquo;s cheap on eBay, I like their management tools and in the past i\u0026rsquo;ve only really had good experiences with them, granted it\u0026rsquo;s no Cisco UCS, HP Bladesystem or Dell M1000e - I think with the addition of OpenManage, and in particular OMIVV it makes it almost as manageable as those environments when you get the foundations laid down nice and solid.\nIt makes sense to try and integrate hardware infrastructure with the virtualisation infrastructure as much as possible, \u0026ldquo;single pane of glass\u0026rdquo; management is very much the thing at the moment, mainly because it makes life easier. I can see, in my normal operating environment, if there are hardware problems, have it trigger vMotion events, send up vCenter alarms, update firmware, all sorts of cool stuff - who doesn\u0026rsquo;t want this?\nLuckily for me (totally based purchasing decisions around this) Dell have an offering called OpenManage, it\u0026rsquo;s been in their line up for a very long time, but it\u0026rsquo;s gone and gotten all modern and has a vCenter plugin and ESXi VIB installers for info gathering and reporting to the plugin.\nOpenManage for vSphere is three discrete piece of software:\n A VIB to be deployed to each ESXi host (you have vUM installed, right?) An OpenManage Integration for VMware vCenter \u0026lsquo;.ova\u0026rsquo; (provides vCenter plugin) The OpenManage Web Server (provides a windows-based web GUI for ESXi VIB agents)  So, to get the ball rolling, let\u0026rsquo;s install the Windows component on a management machine that has access to the host management VMkernel ports, download the OM Managed Node installer from above and extract on your management box, navigate to extraction and run setup.exe, we want to see that the box we\u0026rsquo;re installing it on supports the Web Server role:\n \nInstallation is a very Next, Next, Finish type thing, just blast through it then try navigating to https://localhost:1311/:\n \nWe obviously can\u0026rsquo;t log in yet as we haven\u0026rsquo;t installed the VIBs on the ESXi hosts, so let\u0026rsquo;s get on that (if you don\u0026rsquo;t have vUM installed, either set it up, or just follow this VMware KB on how to manually install ESXi VIBs, download the OpenManage VIB from above and apply the same procedure).\nI\u0026rsquo;m going to assume you\u0026rsquo;ve already got your vCenter set up and plugged VMware Update Manager into it - so lets navigate to the C# client, select our cluster or hosts then go to:\nUpdate Manager tab -\u0026gt; Admin View -\u0026gt; Configuration tab -\u0026gt; Download Settings menu item.\nNow we should see the default VMware repositories in here, let\u0026rsquo;s click Add Download Source and input this URL:\nhttps://vmwaredepot.dell.com/index.xml Add a description of your choosing and click Validate URL you should see the below:\n \nClick Ok, then Apply and finally Download Now to kick off VIB catalogue download.\nIf you go to the Patch Repository tab in vUM and add 6.0 to the filter box you should now see a few packages loaded from the Dell VIB Depot:\n \nAlright cool, so that all looks good, now, as I said before, I run Dell R710s in my lab, which come with iDRAC6 boards, so I can\u0026rsquo;t use the fancy new Dell iSM to replicate log events into the OS or do automatic reboots etc, but the OpenManage 8.1.0 VIB will give me the functionality that I need regardless.\nSo let\u0026rsquo;s create a Dell Baseline, navigate to Baselines and Groups and click Create on Baseline, name it Dell OpenManage, choose Baseline Type as Host Extension, On the next screen you want to choose the Dell VIBs that apply to you, I only need OpenManage 8.1.0 for ESXi600 so I selected that and added to my Baseline, if you can run iSM then add that VIB in here too, finish off the creation of the Baseline then move back to Compliance View.\nClick Attach and tick the Dell OpenManage Extension Baseline we just created and click Scan, check Patches and Extensions then click Scan.\nYour hosts should now all show Non-Compliant in the Extensions field - this is fine, click Remediate choose the Extension Baselines option and check the Dell OpenManage option from before.\n \nChoose the hosts you want to deploy it on check the VIBs to deploy and run through the options around remediation, choose what is best for your environment, it\u0026rsquo;s always good to hit Generate Report to see any blockers before you run the remediation, go ahead and remediate. If you have DRS enabled you\u0026rsquo;re Recent Tasks should look similar to this:\n \nOnce they\u0026rsquo;re remediated all hosts should show compliant against the Dell OpenManage baseline. We will now be able to connect to the hosts through the OpenManage Web Server we set up on https://localhost:1311 before, just put in the host vmk management address, username and password:\n \nFrom here we can do things we can\u0026rsquo;t in iDRAC - Manage storage rebuilds/disk replacements, view hardware and firmware revisions and if you\u0026rsquo;ve done what I have in the past and forgotten to put a VLAN ID into the iDRAC you can recover from a complete iDRAC disconnection by changing the settings in here - think of it as an out of band for your out of band.\nOkay, so we\u0026rsquo;re almost there, we can see some benefits already, however the vCenter plugin is where this solution really shines, so download the .ova from above, run the Dell_OpenManage_Installation.exe (just a zip extraction) and deploy it on your vCenter, once deployed and powered on it will run an initial setup procedure itself, this can take some time so be patient.\n \nWhen it\u0026rsquo;s finally started up, you need to login as admin and will be asked for a password, then you\u0026rsquo;ll see the following screen:\n \nYou\u0026rsquo;ll need to set up an IP to log into the appliance\u0026rsquo;s web interface, from here we will also change change its' hostname and time config. Once you\u0026rsquo;ve done that, reboot the appliance.\nLog on to the appliance\u0026rsquo;s hostname/IP from your browser and we will set up vCenter Registration (this is the point at which the plugin will be installed), navigate to: vCenter Registration -\u0026gt; Register a New vCenter, fill in the details with those of your local vCenter and hit Register, if it\u0026rsquo;s all gone well you\u0026rsquo;ll see the below:\n \nIf you log in to the Web Client now, you\u0026rsquo;ll see A communication error has occurred in the Dell Host Infromation sections, this is because we haven\u0026rsquo;t configured auth for the vCenter plugin to the iDRACs.\nLet\u0026rsquo;s log into the vCenter Web Client and configure authentication for the host\u0026rsquo;s iDRACs in the vCenter plugin. Navigate to Home -\u0026gt; Administration -\u0026gt; OpenManage Integration:\n \nThen click on Start Initial Configuration Wizard, it\u0026rsquo;s fairly self explanatory, set up a Connection Profile for your hosts and test it against them (this needs to succeed before any useful info will be displayed), it will also ask you to create inventory and warranty scan schedules, I just use the defaults here.\nI have my OMIVV to post virtualisation-related critical and warning events into vCenter and have enabled Enable Alarms for Dell Hosts to trigger automatic DRS migrations of VMs on critical host events.\n \nOnce you hit Finish the wizard will run the warranty and inventory checks:\n \nYou will then see the inventory has run on the boxes you specified in the Job Queue section of OMIVV Home -\u0026gt; Administration -\u0026gt; OpenManage Integration -\u0026gt; Monitor -\u0026gt; Job Queue:\n \nNow if we navigate back to the Hosts and Clusters view and go to a host you should see something like the below:\n \nMy favourite utility here is the firmware updater option, from here you can view firmware and update it directly from vCenter - this is pretty cool, what I tend to do is Firmware Update have it stage all firmware patches to the host and have it automatically install them on next restart - this is a very cool feature. Of course, again, if you use DRS, just set it up to remediate immediately:\n \nThen review the recent tasks pane to view firmware updates:\n \nLuckily for you (not so for me), while writing this a DIMM died in one of my hosts, so we can see the vCenter alarms working as expected:\n \nAnd there we are, your vCenter is fully integrated with your physical host infrastructure and out-of-band management to give you full visibility.\nHope this helped, any questions, ask below, or indeed any suggestions too!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/deploying-dell-openmanage-on-esxi-and-vcenter-6/","summary":"If you\u0026rsquo;ve been reading my other posts of late, you will have gathered I\u0026rsquo;ve been building a new lab. I say \u0026ldquo;new\u0026rdquo;, the last one was a single R710 with a ReadyNas Ultra 6 attached. So essentially, this is my first REAL lab.\nIt\u0026rsquo;s mostly based on Dell hardware; it\u0026rsquo;s cheap on eBay, I like their management tools and in the past i\u0026rsquo;ve only really had good experiences with them, granted it\u0026rsquo;s no Cisco UCS, HP Bladesystem or Dell M1000e - I think with the addition of OpenManage, and in particular OMIVV it makes it almost as manageable as those environments when you get the foundations laid down nice and solid.","title":"Deploying Dell OpenManage on ESXi and vCenter 6"},{"content":"I recently rebuilt my lab and added 2x new ESXi hosts, I re-used my old single host in the process which I upgraded from ESXi 5.5 to 6.0 and patched to the same level as the new hosts.\nEverything was working as expected until it came for the time to enable HA.\nMy old host claimed the master roll and thus the other boxes had to connect to it as slaves, however, these failed with \u0026ldquo;HA Agent Unreachable\u0026rdquo; and \u0026ldquo;Operation Timed Out\u0026rdquo; errors.\nAfter some host reboots, ping, nslookup and other standard connectivity tests with still no progress I started blaming the ESXi 5.5 -\u0026gt; 6.0 upgrade this was, as it turns out, unfounded.\nLooking at the /var/log/fdm.log on the master host the following lines could be seen:\nSSL Async Handshake Timeout : Read timeout after approximately 25000ms. Closing stream \u0026lt;SSL(\u0026lt;io_obj p:0x1f33f794, h:31, \u0026lt;TCP \u0026#39;ip:8182\u0026#39;\u0026gt;, \u0026lt;TCP \u0026#39;ip:47416\u0026#39;\u0026gt;\u0026gt;)\u0026gt; Further along we could see that it knows the other hosts are alive:\n[ClusterDatastore::UpdateSlaveHeartbeats] (NFS) host-50 @ host-50 is ALIVE And further along again:\n[AcceptorImpl::FinishSSLAccept] Error N7Vmacore16TimeoutExceptionE(Operation timed out) creating ssl stream or doing handshake On the slave candidates this could be seen:\n[ClusterManagerImpl::AddBadIP] IP 1{master.ip.address.here} marked bad for reason Unreachable IP After yet more troubleshooting and messing about with SSL cert regeneration I stumbled upon this:\n This issue occurs when Jumbo Frames is enabled on the host Management Network (VMkernel port used for host management) and a network misconfiguration prevent hosts communicating using jumbo frames. It is supported to use jumbo frames on the Management Network as long as the MTU values and physical network are set correctly.\n Checked the vmk0 MTU on my master host - sure enough, I had configured this as 9000 back in the day and completely forgotten about it, bumped it back down to 1500, HA agents came up right away:\n \nHopefully this saves you some time and you don\u0026rsquo;t have to go through what I did trying to solve this.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/vsphere-ha-configuration-fails-operation-timed-out/","summary":"I recently rebuilt my lab and added 2x new ESXi hosts, I re-used my old single host in the process which I upgraded from ESXi 5.5 to 6.0 and patched to the same level as the new hosts.\nEverything was working as expected until it came for the time to enable HA.\nMy old host claimed the master roll and thus the other boxes had to connect to it as slaves, however, these failed with \u0026ldquo;HA Agent Unreachable\u0026rdquo; and \u0026ldquo;Operation Timed Out\u0026rdquo; errors.","title":"vSphere HA Configuration fails: Operation Timed Out"},{"content":"If you\u0026rsquo;ve just spun up a new vCenter 6.0 appliance, have joined it to the domain and added a new identity source but have found that your integrated windows auth (the handy checkbox you use for SSO) isn\u0026rsquo;t working with this error:\nA General System error occurred: Cannot get user info Then it\u0026rsquo;s because the nsswitch.conf file is missing the lsass parameter, to remedy this:\nSSH as root to your vCenter server appliance.\nEnable the local shell:\nshell.set --enabled True shell Open the nsswitch.conf file:\nvi /etc/nsswitch.conf Find the line that specifies:\npasswd: compat ato And append lsass so it looks like this:\npasswd: compat ato lsass Write \u0026amp; exit the file then restart the vpxa service.\n/etc/init.d/vmware-vpxd restart You will now be able able to log into vCenter using SSO in both the web client and legacy client:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/windows-integrated-auth-sso-fails-in-vcenter-6-0/","summary":"If you\u0026rsquo;ve just spun up a new vCenter 6.0 appliance, have joined it to the domain and added a new identity source but have found that your integrated windows auth (the handy checkbox you use for SSO) isn\u0026rsquo;t working with this error:\nA General System error occurred: Cannot get user info Then it\u0026rsquo;s because the nsswitch.conf file is missing the lsass parameter, to remedy this:\nSSH as root to your vCenter server appliance.","title":"Windows Integrated Auth (SSO) fails in vCenter 6.0"},{"content":"Creating signed certs for vCenter has never been easy, with the new release of 6.0 though this has changed somewhat, there is a built in certificate manager that allows you to import a CA (say Microsoft AD) cert and key to have VMCA sign it\u0026rsquo;s own certs with and make them trusted.\nFirst thing, we need to set up an AD cert template for vSphere 6.0, that\u0026rsquo;s in my article here.\nNext, log in to your vCenter Server Appliance as root and enter:\nshell.set --enabled True shell This will get us access to the VCSA underlying OS CLI\nCreate a directory to store our csr and key:\nmkdir /root/SSLCerts Next we will need to launch the certificate manager, execute:\n/usr/lib/vmware-vmca/bin/certificate-manager You will see a display like so:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ | | | *** Welcome to the vSphere 6.0 Certificate Manager *** | | | | -- Select Operation -- | | | | 1. Replace Machine SSL certificate with Custom Certificate | | | | 2. Replace VMCA Root certificate with Custom Signing | | Certificate and replace all Certificates | | | | 3. Replace Machine SSL certificate with VMCA Certificate | | | | 4. Regenerate a new VMCA Root Certificate and | | replace all certificates | | | | 5. Replace Solution user certificates with | | Custom Certificate | | | | 6. Replace Solution user certificates with VMCA certificates | | | | 7. Revert last performed operation by re-publishing old | | certificates | | | | 8. Reset all Certificates | |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _| We are going to use option 1 to replace the machine_ssl cert an AD signed one.\nYou will now be prompted for your SSO user password (usually administrator@vsphere.local unless you\u0026rsquo;ve changed it during setup like me), so enter it.\nNo you\u0026rsquo;re going to be asked:\n1. Generate Certificate Signing Request(s) and Key(s) for Machine SSL certificate 2. Import custom certificate(s) and key(s) to replace existing Machine SSL certificate Option [1 or 2]: 1\nWe want to choose option 1 to generate the csr for signing by AD.\nChoose an output directory (/root/SSLCerts created earlier).\nPlease provide a directory location to write the CSR(s) and PrivateKey(s) to: Output directory path: /root/SSLCerts 2015-07-19T18:48:25.878Z Running command: [\u0026#39;/usr/lib/vmware-vmca/bin/certool\u0026#39;, \u0026#39;--genkey\u0026#39;, \u0026#39;--privkey\u0026#39;, \u0026#39;/root/SSLCerts/machine_ssl.key\u0026#39;, \u0026#39;--pubkey\u0026#39;, \u0026#39;/tmp/pubkey.pub\u0026#39;] 2015-07-19T18:48:26.144Z Done running command 2015-07-19T18:48:26.145Z Running command: [\u0026#39;/usr/lib/vmware-vmca/bin/certool\u0026#39;, \u0026#39;--gencsrfromcert\u0026#39;, \u0026#39;--privkey\u0026#39;, \u0026#39;/root/SSLCerts/machine_ssl.key\u0026#39;, \u0026#39;--cert\u0026#39;, \u0026#39;/tmp/vecs_crt.crt\u0026#39;, \u0026#39;--csrfile\u0026#39;, \u0026#39;/root/SSLCerts/machine_ssl.csr\u0026#39;] 2015-07-19T18:48:26.245Z Done running command CSR generated at: /root/SSLCerts/machine_ssl.csr As you can see the .csr was generated at: /root/SSLCerts/machine_ssl.csr so we will cat the output file (open another ssh session to the vc) to get the csr:\ncd /root/SSLCerts/ cat machine_ssl.csr Output will be in standard csr format:\nvc1:~/SSLCerts # cat machine_ssl.csr  -----BEGIN CERTIFICATE REQUEST----- {CSR HERE} -----END CERTIFICATE REQUEST----- Load up AD CertSvc (usually at: https://{DCnameorIP}/CertSrv/en-US/) and follow this procedure:\n Request Certificate Advanced Certificate Request Certificate Template: vSphere 6.0 Paste the csr in and click submit.   \nNext, download the certificate as Base 64 encoded (not the chain!).\nOpen the cert with notepad/sublime text or such and paste the content into a new file on the vcsa:\nvi /root/SSLCerts/machine_ssl.cer Put vi into insert mode:\ni Paste in the contents of the cer file, then hit Esc, write and quit the file:\n:wq Download the CA root certificate in Base 64 also and add it to another file, as above, called ca.cer.\nYou should now have 4 files in /root/SSLCerts/:\n ca.cer machine_ssl.cer machine_ssl.csr machine_ssl.key  Back in the first ssh session where certificate manager is running enter option 1 and enter the requested signed cert file paths:\n1. Continue to importing Custom certificate(s) and key(s) for Machine SSL certificate 2. Exit certificate-manager Option [1 or 2]: 1 Please provide valid custom certificate for Machine SSL. File : /root/SSLCerts/machine_ssl.cer Please provide valid custom key for Machine SSL. File : /root/SSLCerts/machine_ssl.key Please provide the signing certificate of the Machine SSL certificate File : /root/SSLCerts/ca.cer You are going to replace Machine SSL cert using custom cert Continue operation : Option[Y/N] ? : y Status : 100% Completed [All tasks completed successfully] And we\u0026rsquo;re done!\n \nReferences:\n VMware KB 2111571 VMware blog on custom certs VMware KB 2097936  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/using-ad-signed-certificates-with-vcenter-server-appliance-6/","summary":"Creating signed certs for vCenter has never been easy, with the new release of 6.0 though this has changed somewhat, there is a built in certificate manager that allows you to import a CA (say Microsoft AD) cert and key to have VMCA sign it\u0026rsquo;s own certs with and make them trusted.\nFirst thing, we need to set up an AD cert template for vSphere 6.0, that\u0026rsquo;s in my article here.","title":"Using AD signed certificates with vCenter Server Appliance 6"},{"content":"Signing certs for VMware has always been a pain in the ass, it\u0026rsquo;s gotten a lot better in v6 but there are a few caveats, what we\u0026rsquo;re going to do here is set up a certificate template in Active Directory from which we will sign our vCenter certificates.\nLoad up your AD-CA box and run:\ncerttmpl.msc Next right click on Web Server and click Duplicate Template:\n \nIf you use an encryption level higher than sha1 choose Windows Server 2008 as the Certification Authority.\n \nClick the General tab and change the name to something significant to you (mine is vSphere 6.0).\n \nThen navigate to the Extensions tab and select Application Policies and click Edit, select Server Authentication and click Remove then Ok.\n \nSelect Key Usage and click Edit. Select Signature is proof of origin (nonrepudiation) option and click Ok.\n \nMove to the Subject Name tab. Make sure Supply in the request option is selected. Click Ok on both dialogues. It should now show up in your cert templates like so:\n \nLoad up mmc and add the Certificate Authority snap-in.\nNavigate to the Certificate Templates folder and right click choose New -\u0026gt; Certificate Template to Issue then select vSphere 6.0.\n \nWe are now ready to use the template for signing vCenter certs.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/creating-a-vsphere-6-certificate-template-in-active-directory/","summary":"Signing certs for VMware has always been a pain in the ass, it\u0026rsquo;s gotten a lot better in v6 but there are a few caveats, what we\u0026rsquo;re going to do here is set up a certificate template in Active Directory from which we will sign our vCenter certificates.\nLoad up your AD-CA box and run:\ncerttmpl.msc Next right click on Web Server and click Duplicate Template:\n \nIf you use an encryption level higher than sha1 choose Windows Server 2008 as the Certification Authority.","title":"Creating a vSphere 6 certificate template in Active Directory"},{"content":"Sometimes when third party plugins or solutions work with vCenter and ESXi (Like NSX) they will create a custom TCP/IP stack for them to use.\nIf for whatever reason (say, unclean uninstall) you need to remove the TCP/IP stack you can\u0026rsquo;t do it from the vCenter GUI, log into each host directly and execute:\nesxcli network ip netstack delete -N=\u0026#34;stack_name\u0026#34; E.g. if you are uninstalling NSX and get a stuck vxlan stack:\nesxcli network ip netstack remove -N=\u0026#34;vxlan\u0026#34; ","permalink":"https://blah.cloud/command-line-fu/manually-delete-custom-tcpip-stack-in-esxi/","summary":"Sometimes when third party plugins or solutions work with vCenter and ESXi (Like NSX) they will create a custom TCP/IP stack for them to use.\nIf for whatever reason (say, unclean uninstall) you need to remove the TCP/IP stack you can\u0026rsquo;t do it from the vCenter GUI, log into each host directly and execute:\nesxcli network ip netstack delete -N=\u0026#34;stack_name\u0026#34; E.g. if you are uninstalling NSX and get a stuck vxlan stack:","title":"Manually delete custom TCP/IP stack in ESXi"},{"content":"While working on my VMware NSX implementation I wanted to operate the solution in Multicast mode, to do so we need IGMP support and addresses on the switches.\n The Internet Group Management Protocol (IGMP) is a communications protocol used by hosts and adjacent routers on IPv4 networks to establish multicast group memberships.\n Enter the following in configure mode on the VLANs you want IGMP enabled on:\nvlan 8 ip address [enter.switch.ip.here] ip igmp high-priority-forward  Allow some time for queirier to converge, then to verify:\nsh ip igmp  Output:\nVLAN ID : 8 VLAN Name : NSX Querier Address : 10.0.8.2 Active Group Addresses Reports Queries Querier Access Port ---------------------- ------- ------- ------------------- 224.0.1.140 2 1 Trk4  And also:\nsh ip igmp [VLAN ID] config  Output:\nLab-2824-Top(config)# sh ip igmp 8 config\nIGMP Service VLAN ID : 8 VLAN NAME : NSX IGMP Enabled [No] : Yes Forward with High Priority [No] : Yes Querier Allowed [Yes] : Yes Port Type | IP Mcast ---- --------- + -------- 3 | Auto 4 | Auto 5 | Auto 6 | Auto 7 | Auto 8 | Auto 9 | Auto 10 | Auto 11 | Auto 12 | Auto 13 | Auto 14 | Auto 15 | Auto 16 | Auto 17 | Auto 18 | Auto 19 | Auto 20 | Auto 21 | Auto 22 | Auto 23 | Auto 24 | Auto Trk4 | Auto  Don\u0026rsquo;t forget to wr mem to save your changes!\nReference: http://ftp.hp.com/pub/networking/software/AdvTraff-Oct2005-59908853-Chap04-IGMP.pdf\n","permalink":"https://blah.cloud/command-line-fu/enable-igmp-snooping-on-hp-procurve-2800-series-switch/","summary":"While working on my VMware NSX implementation I wanted to operate the solution in Multicast mode, to do so we need IGMP support and addresses on the switches.\n The Internet Group Management Protocol (IGMP) is a communications protocol used by hosts and adjacent routers on IPv4 networks to establish multicast group memberships.\n Enter the following in configure mode on the VLANs you want IGMP enabled on:\nvlan 8 ip address [enter.","title":"Enable IGMP/IGMP Snooping on HP ProCurve 2800 series switch"},{"content":"Ran into a maximum VLAN problem (8 VLANs) on my lab HP ProCurve 2824 switches.\nThis command can be run to increase the max number of VLANs allowed on the switch (in config mode):\nmax-vlans 256 write memory reload ","permalink":"https://blah.cloud/command-line-fu/increase-maximum-number-of-vlans-on-hp-procurve-switch/","summary":"Ran into a maximum VLAN problem (8 VLANs) on my lab HP ProCurve 2824 switches.\nThis command can be run to increase the max number of VLANs allowed on the switch (in config mode):\nmax-vlans 256 write memory reload ","title":"Increase maximum number of VLANs on HP ProCurve switch"},{"content":"Particularly useful if you have used DNS for your NFS datastore mounts and have rebooted the host with the only DNS server on it:\nesxcfg-nas -r ","permalink":"https://blah.cloud/command-line-fu/re-mount-all-unmounted-or-lost-nfs-datastores/","summary":"Particularly useful if you have used DNS for your NFS datastore mounts and have rebooted the host with the only DNS server on it:\nesxcfg-nas -r ","title":"Re-mount all unmounted or \"lost\" NFS Datastores"},{"content":"I have recently been rebuilding my home lab from scratch (a series of posts on that coming soon), so naturally my first port of call for server hardware was eBay, what self-respecting techie would pay full price for anything\u0026hellip;\nI found an incredible deal on some used Dell R710 servers, so I bought two to bring my collection of these beasts up to 3 so I can run VSAN, NSX, vCloud Director and some other SDDC tastiness (VMware VIO anyone?).\nSo picked up this great deal and my servers arrived promptly, noticing they came in EMC boxes made me very intrigued, haven\u0026rsquo;t I seen boxes just like this one at work (we run a sizable Avamar grid), open the boxes, lo-and-behold i\u0026rsquo;m greeted with this familiar sticker:\n \nSo they were familiar!\nAnyway, no big deal, we all know EMC Gen3 Avamar nodes are just re-branded Dell R710s, after all just look at the BOM for one of my nodes' service tags:\nhttp://www.dell.com/support/home/uk/en/ukbsdt1/product-support/servicetag/38CHT4J/configuration\nPlenty of EMC only line items, still though, same motherboard, iDRAC, etc.\nSo, powering it up, clearly had not been updated in some time (BIOS version 6.0.8, iDRAC6 1.10, Lifecycle Controller 1.2), so I did what any good sysadmin would and download the Dell CentOS Firmware LiveDVD (detail), stuck it on a USB and proceeded to pimp it out with all the latest firmwares.\nUpdates stated they were successful, so I thought \u0026ldquo;yay!\u0026rdquo;, rebooted the host and hit F10 to log into Lifecycle Controller/Universal Server Configurator.\nServer hangs for 30 minutes\nClearly, that\u0026rsquo;s not gone well.\nThis is repeatable, also the BIOS on boot now just says:\nBIOS Version With no version number displayed as-would be normal. (Another hint something was amiss - zero Dell branding anywhere, even on iDRAC and UEFI - see below)\n \nAfter a spot of Google archaeology I found some threads indicating that this may be because when 3rd Party Integrators use Dell items they are offered OEMR versions of the firmwares (OEM-Ready) we can find those for the R710 here.\nHowever, they are lagging behind and also handicap the functionality and integration somewhat, in that, they don\u0026rsquo;t play nice with stock firmware images for other components (hence my LCS/USC weirdness).\nI don\u0026rsquo;t want to have to flash a special OEMR BIOS every time I do an upgrade, I want to use the standard Dell repos with my OMSA integration for vCenter and/or Dell Repository Manager.\nSo how can we force a \u0026ldquo;standard\u0026rdquo; Dell firmware on to the hardware (which is, of course, identical to its EMC/Google/whatever integrated counterpart)?\nThis is actually pretty easy, we need to create a DOS Boot USB using Rufus;\nSetting the file system to FAT32 and the bootable OS type to MS-DOS, then load our stock Dell Non-Packaged BIOS firmware .exe on to it.\nBoot into our newly made USB and run the update package with the /forcetype argument:\nR710-060400C.exe /forcetype  \nLet the upgrade complete, reboot and BAM, stock Dell goodness again.\nPressed F10 LSC/USC loads right up with all the usual Dell branding and we can update our firmwares from here on out with peace of mind, knowing that we don\u0026rsquo;t have to wait on special OEMR firmware updates.\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/flashing-over-oem-r-biosfirmware-on-dell-hardware/","summary":"I have recently been rebuilding my home lab from scratch (a series of posts on that coming soon), so naturally my first port of call for server hardware was eBay, what self-respecting techie would pay full price for anything\u0026hellip;\nI found an incredible deal on some used Dell R710 servers, so I bought two to bring my collection of these beasts up to 3 so I can run VSAN, NSX, vCloud Director and some other SDDC tastiness (VMware VIO anyone?","title":"Flashing over OEM-R BIOS/Firmware on Dell hardware"},{"content":"My old ReadyNAS was in need of an update and figured i\u0026rsquo;d look back into upgrading to OS 6.2.x again, this used to be quite an involved manual process requiring you to access the VGA header on the motherboard.\nAs it turns out Netgear have realised people would get round this anyway and have provided an (unsupported) upgrade path.\nThis will allow us to use a number of features not available on our current firmware (for me I have a ReadyNAS Ultra 6):\n AD Authentication NFS v4 Native link bonding (without 3rd party plugin) SSH access (without 3rd party plugin) New plugin catalogue A shiny new GUI :)  N.B: This operation will factory reset your NAS including all shares, take a backup first!\nSo, first things first, download R4toR6_Prep_Addon.bin and R4toR6_6.9.5.bin from the here.\nLog into your ReadyNAS admin interface and navigate to Add-ons -\u0026gt; Add New, Select the R4toR6_Prep_Addon.bin extension we downloaded earlier and click Upload and verify image...:\n \nIf the installation prep file was successfully uploaded and verified you will see the below:\n \nClick Install to commit to the OS.\nNext up we need to upload the OS R4toR6_6.9.5.bin itself via System \u0026gt; Update \u0026gt; Local:\n \nAfter the firmware has been uploaded and verified click Perform System Update and reboot when prompted:\n \nNow we pray to the computing deities and hope that the completely unsupported software upgrade we did on our NAS has not fudged the entire box.\nAs the box gets reset to factory defaults it will now have a DHCP address - connect to this new address, login with admin and password and set it back up with bonding, AD auth, set up some shares and private Time Machine, etc:\n \nI installed Pydio on mine, it\u0026rsquo;s an awesome cloud file sync platform that you forward through your firewall (enable IPS on your firewall now if you have it!).\nSo there it is, nice and easy, updated to the latest RAIDiator.\nWorth holding your breath during the upgrade for? I think so.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/upgrading-a-legacy-readynas-from-raidiator-4-2-x-to-6-2-x/","summary":"My old ReadyNAS was in need of an update and figured i\u0026rsquo;d look back into upgrading to OS 6.2.x again, this used to be quite an involved manual process requiring you to access the VGA header on the motherboard.\nAs it turns out Netgear have realised people would get round this anyway and have provided an (unsupported) upgrade path.\nThis will allow us to use a number of features not available on our current firmware (for me I have a ReadyNAS Ultra 6):","title":"Upgrading a legacy ReadyNAS from RAIDiator 4.2.x to 6.x"},{"content":"Very handy little snippet I discovered today, mostly here for my own reference in future.\nIt\u0026rsquo;s handy to be able to re-play/re-submit commands that you\u0026rsquo;ve typed into the CLI before on your Linux box, to do this you can use the history command.\nLet\u0026rsquo;s take a look at my webserver hosting the site, just as an example:\nroot@web:~# history 781 nano /etc/cron.hourly/.placeholder sess_ 782 crontab 783 crontab -e 784 nano /etc/cron.d/php5 785 sudo bash 786 exit 787 sudo bash 788 service php5-fpm restart 789 service nginx restart 790 service varnish restart If I want to look for particular entries I can just grep the output:\nroot@web:~# history | grep \u0026#34;cat\u0026#34; 1005 cat /etc/nginx/sites-enabled/default 1006 cat /etc/nginx/sites-enabled/www.mylesgray.com 1027 cat mini/README.txt 1137 cat var/report/1084963200249 Then if you pay attention to the left hand column, there is a history number, to re-enter a command we simple put a bang (!) in front of the number in the CLI:\nroot@web:~# !1006 cat /etc/nginx/sites-enabled/www.mylesgray.com ## https://blah.cloud -\u0026gt; https://blah.cloud server { . . . etc If you want to execute the very last command you typed:\nroot@web:~# !! If you want to execute a command issued n commands previous:\nroot@web:~# !-n If you want to execute the last command starting with word:\nroot@web:~# !word If you want to execute the last command containing word:\nroot@web:~# !?word If you want to view the parameters passed to the last command:\nroot@web:~# !* If you want to view the parameters passed to command n commands previous:\nroot@web:~# !-n* As you can see, plenty of options, these are by no means exhausted, you can combine them to create any kind of filter in-between.\nBonus extra tip - if you forgot to add sudo to a command that requires it (because we all do) this will repeat the last command, with sudo prefixed to it:\nroot@web:~# sudo !! Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/linux/replaying-linux-cli-commands-with-history/","summary":"Very handy little snippet I discovered today, mostly here for my own reference in future.\nIt\u0026rsquo;s handy to be able to re-play/re-submit commands that you\u0026rsquo;ve typed into the CLI before on your Linux box, to do this you can use the history command.\nLet\u0026rsquo;s take a look at my webserver hosting the site, just as an example:\nroot@web:~# history 781 nano /etc/cron.hourly/.placeholder sess_ 782 crontab 783 crontab -e 784 nano /etc/cron.","title":"Replaying Linux CLI commands with history"},{"content":"Sometimes you need your devices (say an SMTP server) to have a specific outbound public IP for things like reverse-DNS look-ups to ensure mail delivery and reputation, or maybe you want traffic from particular devices or policies to go out an IP for means of tracking.\nIt is not immediately obvious on Fortigates how to do this, typically, when you create a policy and NAT traffic out through it, the Fortigate will use its' own public IP assigned by the ISP to originate the traffic from, if you have got a static IP and use an unnumbered address from your ISP then you might be lucky and your R-DNS might match this, however, in most cases you will have a separate Virtual IP for your SMTP server that is different to this and thus you need the R-DNS lookup to match that of the A-Record.\nSo the problem becomes:\n How do I get traffic from a specific policy to originate from a static public IP of my choosing?\n Fortigates have a concept called IP Pools.\n IP Pools are a mechanism that allow sessions leaving the FortiGate Firewall to use NAT. An IP pool defines a single IP address or a range of IP addresses to be used as the source address for the duration of the session. These assigned addresses will be used instead of the IP address assigned to that FortiGate interface.\n So we need to first create an IP Pool in Policy \u0026amp; Objects -\u0026gt; Objects -\u0026gt; IP Pools:\n Click Create New Set the Name Set the type to Overload (To allow multiple back-end devices to use this one public IP) Set the External IP Range to be a single address in the block assigned by your ISP Save   \nNext we need to go to Policies in the Policy \u0026amp; Objects -\u0026gt; Policy -\u0026gt; IPv4 section and select the policy from LAN -\u0026gt; WAN that contains our SMTP server and edit the Firewall/Network Options section:\n Set NAT to ON Choose Use Dynamic IP Pool Specify the pool name you created before Save   \nNow any traffic going to WAN through this policy will be NAT\u0026rsquo;d through the IP Pool address(es) you specified, thus, the outbound traffic from your SMTP server will originate from the same address as the R-DNS lookup for you domain\u0026rsquo;s A-Record and result in successful mail delivery.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/specifying-outbound-nat-address-for-policy-on-a-fortigate/","summary":"Sometimes you need your devices (say an SMTP server) to have a specific outbound public IP for things like reverse-DNS look-ups to ensure mail delivery and reputation, or maybe you want traffic from particular devices or policies to go out an IP for means of tracking.\nIt is not immediately obvious on Fortigates how to do this, typically, when you create a policy and NAT traffic out through it, the Fortigate will use its' own public IP assigned by the ISP to originate the traffic from, if you have got a static IP and use an unnumbered address from your ISP then you might be lucky and your R-DNS might match this, however, in most cases you will have a separate Virtual IP for your SMTP server that is different to this and thus you need the R-DNS lookup to match that of the A-Record.","title":"Specifying outbound NAT address for policy on a Fortigate"},{"content":"This article is a bit of a divergence for me, I recently had the need to scan an entire network for a particularly nasty Microsoft security vulnerability MS15-034.\nThere are a few ways to check for this, the first is obvious, check what servers have IIS installed. However, this bug isn\u0026rsquo;t limited to IIS, rather anything using HTTP.sys and, of course, a HTTP server can be spun up on any port you want so we need to check for servers that have HTTP exposed on any port from 1-65535.\nNobody wants to manually log on to every server and check if the specific KB patch is installed though, that takes a lot of effort and time.\nSo is there a way we can scan for vulnerabilities in a \u0026ldquo;start and forget\u0026rdquo; sort of way?\nSure, we can use Zenmap - Zenmap is a GUI built on top of nmap, a network scanner that can gather info on open ports, OS detection, etc. It has tons of really cool features, but one thing it allows for that is of particular benefit is scripting of particular scan parameters, this makes it ideal for vulnerability scanning.\nThe reason I use Zenmap is that it provides a nice summarised output of nmap commands and supports all of the features nmap does. If we open up Zenmap and run the below against our subnet (obviously replace this with your subnet and mask, or indeed, single host) in question:\nnmap -v3 10.0.0.0/23 This will give you an output of all active hosts on the network (the -v3 trigger simply increases output verbosity during the scan, I like this to see where we are at in the scan progress-wise), nice and easy:\n \nnmap\u0026rsquo;s default \u0026ldquo;host is active\u0026rdquo; detection behaviour (on IPv4) is; send an ICMP echo request, a TCP SYN packet to port 443, a TCP ACK packet to port 80, and an ICMP timestamp request.\nSometimes, however, hosts don\u0026rsquo;t respond to these requests/packets; If you think there may be hosts on your subnet that act in this manner, we can get around it by disabling host detections by passing the trigger -Pn.\n Disabling host discovery with -Pn causes Nmap to attempt the requested scanning functions against every target IP address specified\n So for the below it will fully scan all top 1000 ports (default for nmap) on every IP in the 10.0.0.0/23 subnet. N.B. This takes a LONG time:\nnmap -v3 -Pn 10.0.0.0/23 Let\u0026rsquo;s make our scan a little more useful and output to a nicely formatted XML document, create a folder in C:\\ called temp then with the -oX [filename] trigger edit the command:\nnmap -v3 -oX \u0026#34;C:\\\\temp\\\\scan.xml\u0026#34; 10.0.0.0/23 This will give you a nice XML report (saved in the C:\\temp\\ directory) you can open with your browser and get a report like so:\n \nSo we understand how to look for open ports (on 1000 top used TCP ports - default) and generate a nice XML report.\nLet\u0026rsquo;s see if we can figure out what a couple of those hosts are then.\nnmap has a built in trigger for OS: -A and OS version detection: -sV that will use a number of pointers and try and guess what the OS is based on info available to it.\nLet\u0026rsquo;s run it and see what we can get (I ran it on a single host because it takes a LONG time to run these scans on a /23 subnet):\nnmap -A -sV -v3 -oX \u0026#34;C:\\\\temp\\\\scan.xml\u0026#34; 10.0.1.253 Output looks similar to the below:\nStarting Nmap 6.47 ( http://nmap.org ) at 2015-05-25 16:47 GMT Daylight Time NSE: Loaded 118 scripts for scanning. NSE: Script Pre-scanning. NSE: Starting runlevel 1 (of 2) scan. NSE: Starting runlevel 2 (of 2) scan. Initiating ARP Ping Scan at 16:47 Scanning 10.0.1.253 [1 port] Completed ARP Ping Scan at 16:47, 0.03s elapsed (1 total hosts) Initiating Parallel DNS resolution of 1 host. at 16:47 Completed Parallel DNS resolution of 1 host. at 16:47, 0.00s elapsed DNS resolution of 1 IPs took 0.09s. Mode: Async [#: 3, OK: 1, NX: 0, DR: 0, SF: 0, TR: 1, CN: 0] Initiating SYN Stealth Scan at 16:47 Scanning dc02.home.kharms.co.uk (10.0.1.253) [1000 ports] Discovered open port 135/tcp on 10.0.1.253 Discovered open port 3389/tcp on 10.0.1.253 Discovered open port 53/tcp on 10.0.1.253 Discovered open port 139/tcp on 10.0.1.253 Discovered open port 445/tcp on 10.0.1.253 Discovered open port 111/tcp on 10.0.1.253 Discovered open port 593/tcp on 10.0.1.253 Discovered open port 88/tcp on 10.0.1.253 Discovered open port 3269/tcp on 10.0.1.253 Discovered open port 49154/tcp on 10.0.1.253 Discovered open port 49153/tcp on 10.0.1.253 Discovered open port 464/tcp on 10.0.1.253 Discovered open port 49156/tcp on 10.0.1.253 Discovered open port 636/tcp on 10.0.1.253 Discovered open port 3268/tcp on 10.0.1.253 Discovered open port 389/tcp on 10.0.1.253 Discovered open port 49158/tcp on 10.0.1.253 Discovered open port 49157/tcp on 10.0.1.253 Completed SYN Stealth Scan at 16:47, 4.70s elapsed (1000 total ports) Initiating Service scan at 16:47 Scanning 18 services on dc02.home.kharms.co.uk (10.0.1.253) Completed Service scan at 16:49, 116.16s elapsed (18 services on 1 host) Initiating OS detection (try #1) against dc02.home.kharms.co.uk (10.0.1.253) NSE: Script scanning 10.0.1.253. NSE: Starting runlevel 1 (of 2) scan. Initiating NSE at 16:49 NSE Timing: About 80.77% done; ETC: 16:49 (0:00:07 remaining) Completed NSE at 16:49, 41.75s elapsed NSE: Starting runlevel 2 (of 2) scan. Nmap scan report for dc02.home.kharms.co.uk (10.0.1.253) Host is up (0.00s latency). Scanned at 2015-05-25 16:47:08 GMT Daylight Time for 164s Not shown: 982 filtered ports PORT STATE SERVICE VERSION 53/tcp open domain Microsoft DNS 88/tcp open kerberos-sec Windows 2003 Kerberos (server time: 2015-05-25 15:47:18Z) 111/tcp open rpcbind? | rpcinfo: | program version port/proto service | 100000 2,3,4 111/tcp rpcbind | 100000 2,3,4 111/udp rpcbind | 100004 2 787/udp ypserv | 100004 2 789/tcp ypserv | 100009 1 788/udp yppasswdd |_ 1073741824 1 790/udp fmproduct 135/tcp open msrpc? 139/tcp open netbios-ssn 389/tcp open ldap 445/tcp open netbios-ssn 464/tcp open kpasswd5? 593/tcp open ncacn_http Microsoft Windows RPC over HTTP 1.0 636/tcp open ssl/ldap | ssl-cert: Subject: commonName=dc02.home.kharms.co.uk | Issuer: commonName=Kharms CA/domainComponent=home | Public Key type: rsa | Public Key bits: 2048 | Not valid before: 2015-01-25T15:35:12+00:00 | Not valid after: 2016-01-25T15:35:12+00:00 | -----BEGIN CERTIFICATE----- | [REDACTED] |_-----END CERTIFICATE----- |_ssl-date: 2015-05-25T15:49:11+00:00; 0s from local time. 3268/tcp open ldap 3269/tcp open ssl/ldap | ssl-cert: Subject: commonName=dc02.home.kharms.co.uk | Issuer: commonName=Kharms CA/domainComponent=home | Public Key type: rsa | Public Key bits: 2048 | Not valid before: 2015-01-25T15:35:12+00:00 | Not valid after: 2016-01-25T15:35:12+00:00 | -----BEGIN CERTIFICATE----- | [REDACTED] |_-----END CERTIFICATE----- |_ssl-date: 2015-05-25T15:49:11+00:00; 0s from local time. 3389/tcp open ms-wbt-server Microsoft Terminal Service 49153/tcp open msrpc Microsoft Windows RPC 49154/tcp open msrpc Microsoft Windows RPC 49156/tcp open msrpc Microsoft Windows RPC 49157/tcp open ncacn_http Microsoft Windows RPC over HTTP 1.0 49158/tcp open msrpc Microsoft Windows RPC MAC Address: 00:50:56:A4:E1:FF (VMware) Warning: OSScan results may be unreliable because we could not find at least 1 open and 1 closed port Device type: general purpose Running: Microsoft Windows 2012 OS CPE: cpe:/o:microsoft:windows_server_2012 OS details: Microsoft Windows Server 2012 TCP/IP fingerprint: OS:SCAN(V=6.47%E=4%D=5/25%OT=53%CT=%CU=%PV=Y%DS=1%DC=D%G=N%M=005056%TM=5563 OS:44A0%P=i686-pc-windows-windows)SEQ(SP=100%GCD=1%ISR=108%TI=I%II=I%SS=S%T OS:S=7)OPS(O1=M5B4NW8ST11%O2=M5B4NW8ST11%O3=M5B4NW8NNT11%O4=M5B4NW8ST11%O5= OS:M5B4NW8ST11%O6=M5B4ST11)WIN(W1=2000%W2=2000%W3=2000%W4=2000%W5=2000%W6=2 OS:000)ECN(R=Y%DF=Y%TG=80%W=2000%O=M5B4NW8NNS%CC=Y%Q=)T1(R=Y%DF=Y%TG=80%S=O OS:%A=S+%F=AS%RD=0%Q=)T2(R=N)T3(R=N)T4(R=N)U1(R=N)IE(R=Y%DFI=N%TG=80%CD=Z) Uptime guess: 27.639 days (since Tue Apr 28 01:29:16 2015) Network Distance: 1 hop TCP Sequence Prediction: Difficulty=256 (Good luck!) IP ID Sequence Generation: Incremental Service Info: OS: Windows; CPE: cpe:/o:microsoft:windows Host script results: | nbstat: NetBIOS name: DC02, NetBIOS user: \u0026lt;unknown\u0026gt;, NetBIOS MAC: 00:50:56:a4:e1:ff (VMware) | Names: | HOME\u0026lt;00\u0026gt; Flags: \u0026lt;group\u0026gt;\u0026lt;active\u0026gt; | DC02\u0026lt;00\u0026gt; Flags: \u0026lt;unique\u0026gt;\u0026lt;active\u0026gt; | HOME\u0026lt;1c\u0026gt; Flags: \u0026lt;group\u0026gt;\u0026lt;active\u0026gt; | DC02\u0026lt;20\u0026gt; Flags: \u0026lt;unique\u0026gt;\u0026lt;active\u0026gt; | Statistics: | 00 50 56 a4 e1 ff 00 00 00 00 00 00 00 00 00 00 00 | 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |_ 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | p2p-conficker: | Checking for Conficker.C or higher... | Check 1 (port 6408/tcp): CLEAN (Timeout) | Check 2 (port 33074/tcp): CLEAN (Timeout) | | Check 3 (port 27466/udp): CLEAN (Timeout) | | Check 4 (port 40700/udp): CLEAN (Timeout) |_ 0/4 checks are positive: Host is CLEAN or ports are blocked | smb-os-discovery: | OS: Windows Server 2012 R2 Datacenter 9600 (Windows Server 2012 R2 Datacenter 6.3) | OS CPE: cpe:/o:microsoft:windows_server_2012::- | Computer name: dc02 | NetBIOS computer name: DC02 | Domain name: home.kharms.co.uk | Forest name: home.kharms.co.uk | FQDN: dc02.home.kharms.co.uk |_ System time: 2015-05-25T16:49:11+01:00 | smb-security-mode: | Account that was used for smb scripts: guest | User-level authentication | SMB Security: Challenge/response passwords supported |_ Message signing required |_smbv2-enabled: Server supports SMBv2 protocol TRACEROUTE HOP RTT ADDRESS 1 0.00 ms dc02.home.kharms.co.uk (10.0.1.253) NSE: Script Post-scanning. NSE: Starting runlevel 1 (of 2) scan. NSE: Starting runlevel 2 (of 2) scan. Read data files from: C:\\Program Files (x86)\\Nmap OS and Service detection performed. Please report any incorrect results at http://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 166.58 seconds Raw packets sent: 2020 (90.718KB) | Rcvd: 225 (92.285KB) I want to highlight a few lines in particular from the output:\nRunning: Microsoft Windows 2012 OS CPE: cpe:/o:microsoft:windows_server_2012 OS details: Microsoft Windows Server 2012 and in the smb-os-discovery section:\nOS: Windows Server 2012 R2 Datacenter 9600 (Windows Server 2012 R2 Datacenter 6.3) Also, confirmed in the pretty Zenmap GUI:\n \nSo it\u0026rsquo;s a Windows 2012 server, awesome, and we can see from the port scan it\u0026rsquo;s got DNS, IIS, LDAP and Kerberos - so, probably a Domain Controller.\nLet\u0026rsquo;s dig into this host a little more and run a scan on all ports by using -p 1-65535, also that last scan took a little longer than I liked so, lets specify -T4 to limit dynamic scan delay from exceeding 10 ms for TCP ports:\nnmap -p 1-65535 -T4 -A -sV -v3 -oX \u0026#34;C:\\\\temp\\\\scan.xml\u0026#34; 10.0.1.253 I\u0026rsquo;m not going to output the entire script, as it\u0026rsquo;s mostly the same, however here is the extra info pulled back from the full TCP range scan:\n744/tcp open ypserv 5985/tcp open http Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP) 6677/tcp closed unknown 9389/tcp open unknown 49155/tcp open msrpc Microsoft Windows RPC 49159/tcp open msrpc Microsoft Windows RPC 49164/tcp open msrpc Microsoft Windows RPC 49215/tcp open msrpc Microsoft Windows RPC 55382/tcp open msrpc Microsoft Windows RPC The Windows RPC ports aren\u0026rsquo;t new, they\u0026rsquo;ve just moved, RPC ports are dynamically allocated:\n allow for traffic between servers in the dynamic port range of 49152 through 65535\n So the new surfaces exposed are 744, 5985, 6677 and 9389.\nI see that Microsoft HTTPAPI httpd 2.0 is on port 5985, Windows vulnerability MS15-034 addresses a vulnerability in HTTP.sys, which this service uses.\nTo get into scanning ports for the MS15-034 vulnerability we will need to download a NSE script, this is a script that defines parameters to execute a POC attack to prove the exploit is viable against the defined host.\nI found one that sets the required range in the header to bytes=0-18446744073709551615 that will show whether the vulnerability is viable or not:\nhttps://github.com/cldrn/nmap/blob/master/scripts/http-vuln-cve2015-1635.nse\nThe construction of an NSE is too long for this post, I will cover that in another article, but in a nutshell this script will run against all resulting ports from the scan definition that match its parameters, in this example we can see this line in the NSE file:\nportrule = shortport.http This tells nmap to run this script against all ports that match the type of shortport.http in nmap\u0026rsquo;s pre-defined list. We can see from this thread that it will match against the below parameters:\nhttp = shortport.port_or_service({80, 443, 631, 3872, 8080}, {\u0026#34;http\u0026#34;, \u0026#34;https\u0026#34;, \u0026#34;ipp\u0026#34;, \u0026#34;http-alt\u0026#34;, \u0026#34;oem-agent\u0026#34;}) So we can download the script (if you copy and paste it into a new doc, make sure to save it as ANSI encoded) and move it to the scripts subdirectory of the nmap installation folder then run this to update the script.db file:\nnmap --script-updatedb So now we have our nse installed we can run it against our host:\nnmap -p 1-65535 -T4 -A -sV -v3 -d -oX \u0026#34;C:\\\\temp\\\\scan.xml\u0026#34; --script http-vuln-cve2015-1635.nse --script-args vulns.showall 10.0.0.1/23 Let me break-down these commands a little, we\u0026rsquo;ve seen all the preceeding ones before except for -d.\n -d: provides debugging output for scripts (so you can figure out why it isn\u0026rsquo;t working) --script: indicates the script to target in the scripts subdirectory --script-args vulns.showall: tells nmap to print NSE results for both vulnerable and non-vulnerable hosts  I also like to use a script that provides a summary of the results at the bottom if i\u0026rsquo;m doing a large subnet scan, (You can view Peter Kacherginsky\u0026rsquo;s article on NSE building here and follow the section on aggregating output, I highly recommend it), though this is not necessary, you can simply pass it as a second script by following the first with a comma as below:\nnmap -p 1-65535 -T4 -A -sV -v3 -d -oX \u0026#34;C:\\\\temp\\\\scan.xml\u0026#34; --script http-vuln-cve2015-1635.nse,post-process.nse --script-args vulns.showall 10.0.0.1/23 At the end of it we should see whether our targeted host is vulnerable:\n5985/tcp open http syn-ack Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP) | http-vuln-cve2015-1635: | NOT VULNERABLE: | Remote Code Execution in HTTP.sys (MS15-034) | State: NOT VULNERABLE | IDs: CVE:CVE-2015-1635 | References: | https://technet.microsoft.com/en-us/library/security/ms15-034.aspx |_ http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-1635 Any questions/problems please drop a comment below!\nReferences:\n https://thesprawl.org/research/writing-nse-scripts-for-vulnerability-scanning/ https://gist.github.com/bonsaiviking/10402038 http://nmap.org/book/man-host-discovery.html  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/scanning-for-network-vulnerabilities-using-nmap/","summary":"This article is a bit of a divergence for me, I recently had the need to scan an entire network for a particularly nasty Microsoft security vulnerability MS15-034.\nThere are a few ways to check for this, the first is obvious, check what servers have IIS installed. However, this bug isn\u0026rsquo;t limited to IIS, rather anything using HTTP.sys and, of course, a HTTP server can be spun up on any port you want so we need to check for servers that have HTTP exposed on any port from 1-65535.","title":"Scanning for network vulnerabilities using nmap"},{"content":"I ran into some very strange behaviour on a BT Business Fiber connection with PPPoE and static IPs assigned by the ISP on a Fortigate firewall.\nA site-to-site IPSec VPN was required, however the tunnel kept terminating as BT assign a dynamic address with the PPPoE connection, then the static IPs are typically ingested through the use of Virtual-IPs on the fortigate unit, however IPSec requires the use of the router WAN address and it needs to be static.\nSetting the unnumbered IP on the Fortigate to one of the assigned static IP addresses from the ISP should have presented the firewall on this address to the outside world, but not so.\nI stumbled upon a CLI parameter that was used to remedy non-standard PPPoE implementations in Japan on an article linked below and gave it a go:\nset pppoe-unnumbered-negotiate disable This will reset the WAN connection when saved, however in place of the dynamically assigned IP you should now be able to access the firewall remotely with the ISP static IP you just assigned.\nReferences:\n http://qiita.com/Glassphere/items/7f737153f8f291e089ca  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/fortigate-unnumbered-ip-against-pppoe-interface/","summary":"I ran into some very strange behaviour on a BT Business Fiber connection with PPPoE and static IPs assigned by the ISP on a Fortigate firewall.\nA site-to-site IPSec VPN was required, however the tunnel kept terminating as BT assign a dynamic address with the PPPoE connection, then the static IPs are typically ingested through the use of Virtual-IPs on the fortigate unit, however IPSec requires the use of the router WAN address and it needs to be static.","title":"Fortigate Unnumbered IP against PPPoE Interface"},{"content":"Just a quick note today, more of a reference than anything else.\nI had the requirement recently to convert a load of VMs that had thin VMDKs to thick provisioned, however the client was not licensed for live Storage vMotion.\nIn an effort to minimise downtime I decided the best thing to do was use the \u0026ldquo;Inflate\u0026rdquo; option in the datastore for that VMDK - this requires the VM to be powered off.\n \nHowever, Inflate - at least when i\u0026rsquo;ve tested it is very slow in comparison to Storage vMotion, to keep downtime to a minimum (some inflations were in the order of 200GB+) I wanted to minimise the data that the Inflate process had to fill out on the end of the drive.\nThe solution is to use sdelete in OS to fill the target disks with data in order to force the VMDK to full size.\nHowever, there is an interesting caveat:\nsdelete.exe -z Zeros free space in OS, does not affect thin VMDK size when when drive is filled due to thin disk compression/dedupe algorithms.\nsdelete.exe -c Fills with random bits, expands disk to full size.\nA little nugget there, the purpose of running sdelete is to fill all the space on the drive, however, when using non-random or zeroed bits, vmware\u0026rsquo;s thin disk technology dedupes the zeroed writes resulting in the wrong outcome (a disk that is NOT full size). Using the sdelete.exe -c trigger fills the disk with random bits and thus forces the VMDK to its full size.\nThe result? Inflate ran across a 5GB increase in 30 seconds rather than 7 minutes.\nAn extension of this is, if you want to do the above but don\u0026rsquo;t want to fill the whole drive (say a SQL server log drive) you can use a dd port for Windows, this emulates Linux\u0026rsquo;s /dev/random and will let you specify bytesize and count, letting you set the size of random data to write to the drive.\nThe below will write a 3GB file filled with random bits to the D:\\ drive then delete the file created:\ndd.exe if=/dev/random of=D:\\file.img bs=1M count=3000 --progress \u0026amp; del D:\\file.img Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/converting-vmware-thin-disks-to-thick-using-inflate/","summary":"Just a quick note today, more of a reference than anything else.\nI had the requirement recently to convert a load of VMs that had thin VMDKs to thick provisioned, however the client was not licensed for live Storage vMotion.\nIn an effort to minimise downtime I decided the best thing to do was use the \u0026ldquo;Inflate\u0026rdquo; option in the datastore for that VMDK - this requires the VM to be powered off.","title":"Converting VMware thin disks to thick using Inflate"},{"content":"I have come across a number of environments where mystery \u0026ldquo;snapshot\u0026rdquo; files exist - they are not seen in snapshot manager, running a consolidation them doesn\u0026rsquo;t help, creating a snapshot (with memory, or guest OS quiescing) then running \u0026ldquo;Delete All\u0026rdquo; doesn\u0026rsquo;t resolve it, but some applications still think a snapshot is there.\nTo take care of these is quite a manual process after you have followed all the VMware KB advice:\n VMware KB 2017072 VMware KB 1023657 VMware KB 1002310  So we\u0026rsquo;ve done all the above, don\u0026rsquo;t fancy doing a V2V to sort this as it shouldn\u0026rsquo;t really be a problem in the first place.\nFirst step is to find all snapshots and delta disks on the datastores:\n# find /vmfs/volumes/ -name *-delta*;find /vmfs/volumes/ -name *-0000* /vmfs/volumes/[id]/[VM]/VM-000002-delta.vmdk /vmfs/volumes/[id]/[VM]/VM-000002.vmdk /vmfs/volumes/[id]/[VM]/VM_1-000002-ctk.vmdk /vmfs/volumes/[id]/[VM]/VM_1-000002-delta.vmdk /vmfs/volumes/[id]/[VM]/VM_1-000002.vmdk As you can see above there are 5 snapshot/tracking/vmdk files that are orphaned and we need to investigate.\nThe first step is to snapshot the VM above and then run delete all to see if VMware can clear them all down - re-run the check above, if they still exist it is quite possible they are orphaned.\nTo investigate further we can find out what vmdks are mounted by the vmx for that particular VM:\n# cat /vmfs/volumes/[id]/[VM]/VM.vmx | grep vmdk scsi0:0.fileName = \u0026#34;VM.vmdk\u0026#34; scsi0:1.fileName = \u0026#34;VM_1.vmdk\u0026#34; So this gives us all the vmdks mounted by the VM - we can then cat these files to check what underlying files on the datastore they reference (I have done one of the two disks as an example):\n# cat VM_1.vmdk # Disk DescriptorFile version=3 encoding=\u0026#34;UTF-8\u0026#34; CID=IDHERE parentCID=ffffffff isNativeSnapshot=\u0026#34;no\u0026#34; createType=\u0026#34;vmfs\u0026#34; # Extent description RW 220200960 VMFS \u0026#34;VM_1-flat.vmdk\u0026#34; # Change Tracking File changeTrackPath=\u0026#34;VM_1-ctk.vmdk\u0026#34; We are interested in the two sections from above \u0026ldquo;Extent description\u0026rdquo; and \u0026ldquo;Change Tracking File\u0026rdquo;, from the above we can see the reference VMDKs files are:\nVM_1-flat.vmdk VM_1-ctk.vmdk In the interests of completeness a cat of the other VMDK (VM.vmdk) showed the following were referenced:\nVM-flat.vmdk VM-ctk.vmdk Check if the vmdk files are locked by any hosts, -delta, -ctk and -flat files should be locked when in active I/O use, descriptor files (just the .vmdk \u0026ldquo;meta\u0026rdquo; files) are not so you need to check all the files individually:\n# vmkfstools -D VM-000002-delta.vmdk Lock [type 10c00001 offset 39821312 v 23225, hb offset 3702784 gen 7489, mode 0, owner 00000000-00000000-0000-000000000000 mtime 2048078 num 0 gblnum 0 gblgen 0 gblbrk 0] Addr \u0026lt;4, 66, 20\u0026gt;, gen 27, links 1, type reg, flags 0, uid 0, gid 0, mode 600 len 606, nb 0 tbz 0, cow 0, newSinceEpoch 0, zla 4305, bs 65536 If it was locked by an ESXi host the MAC of the host would be shown in the owner readout above - all zeros indicates no R/W lock. From the VMware docs:\n If the command vmkfstools -D VM-000002-delta.vmdk does not return a valid MAC address in the top field (returns all zeros ). Review the field below it, the RO Owner line below it to see which MAC address owns the read only/multi writer lock on the file.\nIn some cases it is possible that it is a Service Console-based lock, an NFS lock or a lock generated by another system or product that can use or read VMFS file systems. The file is locked by a VMkernel child or cartel world and the offending host running the process/world must be rebooted to clear it.\nOnce you have identified the host or backup tool (machine that owns the MAC) locking the file, power it off or stop the responsible service, then restart the management agents on the host running the virtual machine to release the lock.\n So no references to our 5 mystery files - check the last time they were used by running:\n# ls -ltr /vmfs/volumes/[id]/[VM]/ | grep vmdk -rw------- 1 root root 16863232 Nov 13 15:01 VM-000002-delta.vmdk -rw------- 1 root root 344 Nov 13 15:01 VM-000002.vmdk -rw------- 1 root root 6554112 Nov 13 15:01 VM_1-000002-ctk.vmdk -rw------- 1 root root 16986112 Nov 13 15:01 VM_1-000002-delta.vmdk -rw------- 1 root root 419 Nov 13 15:01 VM_1-000002.vmdk -rw------- 1 root root 2621952 Feb 5 22:01 VM-ctk.vmdk -rw------- 1 root root 612 Feb 5 22:01 VM_1.vmdk -rw------- 1 root root 606 Feb 5 22:01 VM.vmdk -rw------- 1 root root 6881792 Feb 5 22:01 VM_1-ctk.vmdk -rw------- 1 root root 42949672960 Feb 6 15:20 VM-flat.vmdk -rw------- 1 root root 112742891520 Feb 6 15:20 VM_1-flat.vmdk As we can see above our orphaned files were last accessed almost 3 months previous.\nThen make sure they are not locked by a process, touch them and see that the timestamp updates:\n# touch /vmfs/volumes/[id]/[VM]/*-00000* | ls -ltr | grep vmdk -rw------- 1 root root 612 Feb 5 22:01 VM_1.vmdk -rw------- 1 root root 606 Feb 5 22:01 VM.vmdk -rw------- 1 root root 6881792 Feb 5 22:01 VM_1-ctk.vmdk -rw------- 1 root root 2621952 Feb 5 22:01 VM-ctk.vmdk -rw------- 1 root root 42949672960 Feb 6 15:29 VM-flat.vmdk -rw------- 1 root root 419 Feb 6 15:29 VM_1-000002.vmdk -rw------- 1 root root 16986112 Feb 6 15:29 VM_1-000002-delta.vmdk -rw------- 1 root root 6554112 Feb 6 15:29 VM_1-000002-ctk.vmdk -rw------- 1 root root 112742891520 Feb 6 15:29 VM_1-flat.vmdk -rw------- 1 root root 344 Feb 6 15:29 VM-000002.vmdk -rw------- 1 root root 16863232 Feb 6 15:29 VM-000002-delta.vmdk Being able to touch the file, run vmkfstools -D finding no locks, find no references in vmdk descriptor files generally means it isn\u0026rsquo;t in active use and is safe to move/remove, create a new create a new directory and move the suspect files to it and check for problems with the VM:\n# mkdir oldfiles # mv *-00000* oldfiles/. If all looks well and you are happy the VM is operating normally delete the directory:\n# rm -r oldfiles/ References:\n VMware KB 10051 VMware blog on vmkfstools  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/safely-checkremove-orphaned-vmdk-files-from-esxi/","summary":"I have come across a number of environments where mystery \u0026ldquo;snapshot\u0026rdquo; files exist - they are not seen in snapshot manager, running a consolidation them doesn\u0026rsquo;t help, creating a snapshot (with memory, or guest OS quiescing) then running \u0026ldquo;Delete All\u0026rdquo; doesn\u0026rsquo;t resolve it, but some applications still think a snapshot is there.\nTo take care of these is quite a manual process after you have followed all the VMware KB advice:","title":"Safely check/remove orphaned VMDK files from ESXi"},{"content":"I\u0026rsquo;ve been playing with cloud platforms quite a lot recently, and in particular Juju\u0026rsquo;s way of operations caught my particular attention.\n \nIt has a very impressive feature set and makes deploying and linking \u0026ldquo;canned\u0026rdquo; apps very simple, whether you are using public, private or hybrid cloud instances.\nI wanted to set Juju up with minimal fuss to give it a quick spin, obviously deploying OpenStack etc is a little more involved for a simple POC than I would have liked and using AWS/Azure/HP Cloud/MAAS was just way overkill.\nLuckily, there is a very nice dev environment manager for OSX and Windows by the name of Vagrant, it can run on VirtualBox (the \u0026ldquo;normal\u0026rdquo; installation method) or VMware Workstation/Fusion if you pay a $79 license, as it\u0026rsquo;s a POC i\u0026rsquo;m cool with using VirtualBox.\nVagrant lets you spin up *nix \u0026ldquo;boxes\u0026rdquo; with services etc preconfigured with simple commands like:\nvagrant up hashicorp/precise32 The above will spin you up a Ubuntu 12.04 LTS \u0026ldquo;Precise\u0026rdquo; x86 instance, pretty cool.\nSo, to get the ball rolling, for this deployment we have 2x pieces of software to install:\n Vagrant VirtualBox  Run through the installer for each on your respective OS (very straight forward so I won\u0026rsquo;t document).\nI like to create a new directory for Vagrant under my Documents folder:\ncd Documents/ mkdir Vagrant cd Vagrant/ To gain access to the machines created by Juju later (in a separate subnet accessible by the Juju VM) we should install sshuttle which is a VPN over SSH program, i\u0026rsquo;m on OSX so I use the package manager brew.sh to install it:\nbrew install sshuttle On Windows you need to install the node.js binary for Windows then run:\nnpm install sshuttle Ubuntu has a pre-built dev/test environment for Juju as a cloud image:\nvagrant box add JujuBox http://cloud-images.ubuntu.com/vagrant/trusty/trusty-server-cloudimg-amd64-juju-vagrant-disk1.box This will download and install an Ubuntu cloud image as a vagrant instance with juju pre-installed. Now we need to init this instance:\nvagrant init JujuBox vagrant up  \nOnce it is spun up you can access the Juju GUI via: http://127.0.0.1:6080/, deploy charms etc - Just to test I deployed the \u0026ldquo;WordPress\u0026rdquo; charm:\n \nThe box created will use an address in the 10.0.3.0/24 range as this is the range LXC uses to assign DHCP addresses. So I will use sshuttle to create a VPN over SSH to this network (password for machine is vagrant):\nsshuttle -r vagrant@localhost:2222 10.0.3.0/24 Now I can browse to my newly created WordPress instance through its ip specified by Juju:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/deploying-installing-first-juju-charm-vagrant/","summary":"I\u0026rsquo;ve been playing with cloud platforms quite a lot recently, and in particular Juju\u0026rsquo;s way of operations caught my particular attention.\n \nIt has a very impressive feature set and makes deploying and linking \u0026ldquo;canned\u0026rdquo; apps very simple, whether you are using public, private or hybrid cloud instances.\nI wanted to set Juju up with minimal fuss to give it a quick spin, obviously deploying OpenStack etc is a little more involved for a simple POC than I would have liked and using AWS/Azure/HP Cloud/MAAS was just way overkill.","title":"Deploying and Installing your first Juju Charm on Vagrant"},{"content":"It has, over the years always been quite a quandary to get SSO auth working from *nix -\u0026gt; MS AD without a huge amount of fiddling and tinkering, but there is a new auth framework in town by the name of realmd. While tinkering with The Foreman recently it had dawned on me it would be cool to have it set up such that, after the VM had been automatically provisioned it would allow me to SSH into it using my AD credentials.\nThis has the double benefit of providing SSO for users through SASL/GSSAPI and auto registering the linux box in Windows DNS if that is what you use as your DNS server backend.\nObviously before you can script something like this with Puppet/Foreman it is a good idea to do a test install on a blank Ubuntu 14.04.1 box so you know what exactly needs configured, so I spun up a VM using my newly created PXE boot environment to start playing around with.\nrealmd encompasses a number of existing technologies into a rather easy to install and configure package to get SSO/LDAP integration to work, primarily it uses a package developed by RedHat called SSSD that takes care of LDAP and Kerberos communications for you.\nRedHat docs on SSSD/Kerberos/LDAP setup, pros/cons (Section 6.3).\n \nThe reason I chose this implementation is clearly outlined in the RedHat doc above:\n  Kerberos SSO capable Supports SASL/GSSAPI binds for LDAP queries (optional) Enforces encrypted authentication only Client side caching of user information Off-line caching of previously authenticated user credentials Reduces number of client queries to server Graceful ID collision management   realmd is really a wrapper for SSSD and to quote the site:\n realmd configures sssd or winbind to do the actual network authentication and user account lookups.\n To the configuration then, first we have to install realmd and sssd:\nsudo aptitude install realmd sssd samba-common samba-common-bin samba-libs sssd-tools krb5-user adcli packagekit -y Enter your full domain name in all caps when prompted for Default Kerberos version 5 realm, e.g. EXAMPLE.DOMAIN.COM\nGain a kerberos ticket from AD:\nkinit -V myles.gray Add the short and long domain names to the /etc/hosts file (order is important) and save:\n#edit the localhost entry to include the box\u0026#39;s short and long names like below 127.0.0.1 test1.domain.example.com test1 localhost N.B. If you don\u0026rsquo;t do the above you will see an error in the following output similar to the below:\nDNS update failed: NT_STATUS_INVALID_PARAMETER Using short domain name -- {your domain name here} Joined \u0026#39;TEST1\u0026#39; to dns domain \u0026#39;domain.example.com\u0026#39; No DNS domain configured for test1. Unable to perform DNS Update. If you do come across this problem leave the domain and then edit the /etc/hosts file. You can leave the domain with the following command:\nrealm --verbose leave -U myles.gray domain.example.com Now we can run our realm join command to join us to AD:\nrealm --verbose join -U myles.gray domain.example.com You will be prompted for your admin user\u0026rsquo;s password, enter this and you should receive an output like below:\nroot@test1:~# realm --verbose join -U myles.gray domain.example.com * Resolving: _ldap._tcp.domain.example.com * Performing LDAP DSE lookup on: 10.0.1.123 * Performing LDAP DSE lookup on: 10.0.1.124 * Successfully discovered: domain.example.com Password for myles.gray: * Unconditionally checking packages * Resolving required packages * Installing necessary packages: sssd-tools, libpam-sss, libnss-sss, sssd, samba-common-bin * LANG=C LOGNAME=root /usr/bin/net -s /var/cache/realmd/realmd-smb-conf.X2OPQX -U myles.gray ads join domain.example.com Enter myles.gray\u0026#39;s password: Using short domain name -- DOMAIN Joined \u0026#39;TEST1\u0026#39; to dns domain \u0026#39;domain.example.com\u0026#39; * LANG=C LOGNAME=root /usr/bin/net -s /var/cache/realmd/realmd-smb-conf.X2OPQX -U myles.gray ads keytab create Enter myles.gray\u0026#39;s password: * /usr/sbin/update-rc.d sssd enable update-rc.d: /etc/init.d/sssd: file does not exist * /usr/sbin/service sssd restart stop: Unknown instance: sssd start/running, process 9085 * Successfully enrolled machine in realm We need to also comment out this line in our /etc/sssd/sssd.conf file because of a segfault bug known to RH:\n#use_fully_qualified_names = True Restart sssd service:\nservice sssd restart Now if we run a realm list we should see some info about our newly joined domain:\nroot@test1:~# realm list domain.example.com type: kerberos realm-name: domain.example.com domain-name: domain.example.com configured: kerberos-member server-software: active-directory client-software: sssd required-package: sssd-tools required-package: sssd required-package: libnss-sss required-package: libpam-sss required-package: adcli required-package: samba-common-bin login-formats: %U login-policy: allow-realm-logins Check the group membership of our AD user and that the AD integration is working correctly:\nroot@test1:~# id myles.gray uid=952601104(myles.gray) gid=952600513(domain users) groups=952600513(domain users),952601139(virtualisation admins),952600519(enterprise admins),952601127(inet_filter_none),952603106(foreman_admins),952600512(domain admins),952600518(schema admins),952603117(linux_admins),952603116(linux_users),952601103(net-users),952601152(vpn users),952600572(denied rodc password replication group) Now choose the groups we want to allow login from by denying all (default is allow all) then allowing explicit AD groups (in my case, Linux_Users):\nrealm deny -R domain.example.com -a realm permit -R domain.example.com -g Linux_Users Now we can add our Active Directory Domain Admins and Linux_Admins groups to the /etc/sudoers file to give root access for users in those security groups:\nvisudo Add the following lines (it is important to escape spaces in group names with a \\):\n%domain\\ admins ALL=(ALL:ALL) ALL %Linux_Admins ALL=(ALL:ALL) ALL One thing I like to do is have each user get their own automatically generated home directory in the format /home/domain.example.com/myles.gray, PAM can do this for us if we edit the /etc/pam.d/common-session file:\nnano /etc/pam.d/common-session Add this line at the end of the file:\nsession required pam_mkhomedir.so skel=/etc/skel/ umask=0022 User directories will be automatically created in the format /home/domain.example.com/myles.gray upon login.\nYou should now be able to SSH into the guest with your AD credentials and sudo bash if you are a member of Linux_Admins or Domain Admins AD groups:\nMyless-MacBook-Pro:~ myles.gray$ ssh myles.gray@10.0.2.18 myles.gray@10.0.2.18\u0026#39;s password: Creating directory \u0026#39;/home/home.kharms.co.uk/myles.gray\u0026#39;. Welcome to Ubuntu 14.04.1 LTS (GNU/Linux 3.13.0-40-generic x86_64) * Documentation: https://help.ubuntu.com/ The programs included with the Ubuntu system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Mon Dec 8 00:31:25 2014 from 10.0.3.2 myles.gray@test1:~$ Run a pwd to make sure our home directory was created and we were placed there:\nmyles.gray@test1:~$ pwd /home/home.kharms.co.uk/myles.gray Check out if we can sudo bash as a member of one of the two AD groups we configured as sudoers:\nmyles.gray@test1:~$ sudo bash [sudo] password for myles.gray: root@test1:~# You now have full AD auth for users and groups in your linux environment. I will likely revisit this or make another post about SSO/password-less ssh login using Kerberos in the near future. For the moment, good luck!\nSources:\n http://stephenfritz.blogspot.it/2014/04/linux-microsoft-active-directory_28.html http://funwithlinux.net/2014/04/join-ubuntu-14-04-to-active-directory-domain-using-realmd/ http://serverfault.com/questions/436037/sudoers-file-allow-sudo-on-specific-file-for-active-directory-group http://derflounder.wordpress.com/2012/12/14/adding-ad-domain-groups-to-etcsudoers/ http://www.chriscowley.me.uk/blog/2014/06/17/new-linux-active-directory-integration/  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/utilising-kerberosad-auth-ubuntu-14-04-realmd/","summary":"It has, over the years always been quite a quandary to get SSO auth working from *nix -\u0026gt; MS AD without a huge amount of fiddling and tinkering, but there is a new auth framework in town by the name of realmd. While tinkering with The Foreman recently it had dawned on me it would be cool to have it set up such that, after the VM had been automatically provisioned it would allow me to SSH into it using my AD credentials.","title":"Utilising Kerberos/AD auth in Ubuntu 14.04 with realmd"},{"content":"I have been recently setting up The Foreman as a Puppet management front end to allow me to quickly provision Linux based VMs on my VMware cluster - more on that setup in another article.\nI had to create a PXE boot environment for The Foreman to fully automate the provisioning of the VMs, I run a Fortigate 100D in my lab from which DHCP is served, as you may or may not know, the PXE boot options are served from DHCP.\nFortigate use the next-server command to tell the client where to find the next bootstrap server, or, the server that hosts the TFTP instance.\nThere is a DHCP option in the IANA list we are particularly interested in is:\nTag Name Data Length Meaning Reference 67 Bootfile-Name N Boot File Name [RFC2132] We must set this option to tell the PXE client what filename it is looking for on the TFTP server.\nFortigate have a strange way of doing this particular config, at least in the latest version (5.2.2) which I am running.\nI like to configure from the CLI but couldn\u0026rsquo;t help but noticing in the GUI that there was a new section added to the DHCP config:\n \nIt seems to allow some commonly-set DHCP options to be selected and specified with ASCII rather than hex:\n \nAnyway, we can do all this through the CLI as well, firstly navigate to the DHCP server instance in question:\nshow system dhcp server 2 My output looks like this:\nconfig system dhcp server edit 2 set dns-service default set ntp-service default set default-gateway 10.0.0.1 set netmask 255.255.254.0 set interface \u0026#34;LAN\u0026#34; config ip-range edit 1 set start-ip 10.0.0.2 set end-ip 10.0.1.199 next end set timezone-option default next end To this we need to add the next-server and filename directives to set the DHCP options for TFTP server and boot file name.\nconfig system dhcp server edit 2 set next-server 10.0.2.15 set filename \u0026#34;pxelinux.0\u0026#34; next exit This should now point your DHCP client (Intel E1000 on ESXi) to the TFTP server 10.0.2.15 which is for this example my Foreman server and tell it to pull the pxelinux.0 file to begin the boot and install from network.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/enabling-pxe-boot-options-fortigate-dhcp/","summary":"I have been recently setting up The Foreman as a Puppet management front end to allow me to quickly provision Linux based VMs on my VMware cluster - more on that setup in another article.\nI had to create a PXE boot environment for The Foreman to fully automate the provisioning of the VMs, I run a Fortigate 100D in my lab from which DHCP is served, as you may or may not know, the PXE boot options are served from DHCP.","title":"Enabling PXE boot options on Fortigate DHCP"},{"content":"I recently tried to deploy Cisco VIRL on VMWare Workstation 10 - the install instructions are for v8 - there are a few differences I noted.\n It doesn\u0026rsquo;t account for the host-only network installed by default so increment all vmnets by 1   \n The labelling for VT-x/EPT has changed, it now lives under Settings -\u0026gt; Hardware -\u0026gt; Processors -\u0026gt; Virtualisation engine -\u0026gt; Preferred mode: You need to explicitly select Intel VT-x/EPT or AMD-V/RVI mode   \nAfter this entering the sudo kvm-ok command in the VIRL CLI still output KVM acceleration can NOT be used.\nI needed to edit the .vmx file directly and add/change these lines:\nmonitor.virtual_mmu = \u0026#34;hardware\u0026#34; monitor.virtual_exec = \u0026#34;hardware\u0026#34; vhv.enable = \u0026#34;TRUE\u0026#34; monitor_control.restrict_backdoor = \u0026#34;true\u0026#34; After that booting into VIRL and running sudo kvm-ok output KVM acceleration can be used.\nOnce this was overcome configuration went quite smoothly and was fairly simple to setup, be sure to follow the tutorials once you are ready to go.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/deploying-cisco-virl-vmware-workstation-caveats/","summary":"I recently tried to deploy Cisco VIRL on VMWare Workstation 10 - the install instructions are for v8 - there are a few differences I noted.\n It doesn\u0026rsquo;t account for the host-only network installed by default so increment all vmnets by 1   \n The labelling for VT-x/EPT has changed, it now lives under Settings -\u0026gt; Hardware -\u0026gt; Processors -\u0026gt; Virtualisation engine -\u0026gt; Preferred mode: You need to explicitly select Intel VT-x/EPT or AMD-V/RVI mode","title":"Deploying Cisco VIRL on VMware Workstation – Caveats"},{"content":"VMWare, as of writing, has a nasty bug that means your backups that run utilising CBT (hint: if you have basically any enterprise backup product worth its salt, it\u0026rsquo;s got CBT enabled) it loses track of the changed blocks when the VMDK reaches any Power 2 value of 128GB (128, 256, 512, 1024, etc.) which may make your backup unrecoverable.\nThe VMWare bug is in KB:\n kb.vmware.com/selfservice/microsites/search.do?language=en_US\u0026amp;cmd=displayKC\u0026amp;externalId=2090639\n The remedy for this is to disable and re-enable (reset) CBT on the affected machines, this can be done with the machine powered off or with it turned on by running PowerCLI commands and a snapshot, we will be doing the latter, no one likes downtime:\nDownload and install VMWare PowerCLI then run the following command:\nConnect-VIServer -Server {VC-Address} Enter Username and Password when prompted. Should display output like below:\nName Port User ---- ---- ---- vcsa.domain.com 443 username The following will run and collect the VMs matching the conditions VMDK\u0026gt;=128GB and CBT enabled into the array $vms:\n[System.Collections.ArrayList]$vms = Get-VM| ?{$_.ExtensionData.Config.Hardware.Device.CapacityInKB -ge 128000000} | ?{$_.ExtensionData.Config.ChangeTrackingEnabled -eq $true} To view the list of VMs run the following:\necho $vms You should get a nice list of VMs that match the conditions and likely need CBT reset:\nName PowerState Num CPUs MemoryGB ---- ---------- -------- -------- Machine1.domain... PoweredOn 4 8.000 Machine2.domain... PoweredOn 4 8.000 Machine3.domain... PoweredOn 2 6.000 To reset CBT on these machines while they are live you need to create a VM spec that disables CBT and apply it to the affected machines:\n$spec = New-Object VMware.Vim.VirtualMachineConfigSpec; $spec.ChangeTrackingEnabled = $false; To disable CBT on all VMs affected we then have to apply the $spec to each VM in the $vms array:\nforeach($vm in $vms){$vm.ExtensionData.ReconfigVM($spec);$snap=$vm | New-Snapshot -Name \u0026#39;Disable CBT\u0026#39;;$snap | Remove-Snapshot -confirm:$false;} This will apply the $spec to each VM affected, take a snapshot then remove it to commit the CBT param to turn off.\n \nTo check if your command ran successfully run:\nget-vm | ?{$_.ExtensionData.Config.ChangeTrackingEnabled -eq $false} This outputs a list of VMs with CBT disabled - you should see your full list of VMs from above here. If you are using a backup product that forces CBT to on, like Veeam, then you can leave it here, Veeam will re-enable CBT and run a full backup next time (because we have lost our CBT history).\nHowever, if you run a product that doesn\u0026rsquo;t do this you will need to let your backup run once then run the following command to enable CBT in the spec again and apply to the VMs:\n[System.Collections.ArrayList]$vms = Get-VM| ?{$_.ExtensionData.Config.Hardware.Device.CapacityInKB -ge 128000000} | ?{$_.ExtensionData.Config.ChangeTrackingEnabled -eq $false} $spec = New-Object VMware.Vim.VirtualMachineConfigSpec; $spec.ChangeTrackingEnabled = $true; foreach($vm in $vms){$vm.ExtensionData.ReconfigVM($spec);$snap=$vm | New-Snapshot -Name \u0026#39;Disable CBT\u0026#39;;$snap | Remove-Snapshot -confirm:$false;} This is subtly different than the first set of commands; of note are:\n.ChangeTrackingEnabled -eq $false To only pull VMs with CBT disabled into the $vms array.\n$spec.ChangeTrackingEnabled = $true; To enable CBT on machines rather than disable.\nThis will resolve the problem until your machine crosses another Power 2 border of 128GB when this will need run again.\nThis bug is currently under research with VMWare and I am keeping an eye on the KB for updates on a hotfix available. Source for PowerShell code that has been adapted from: http://www.veeam.com/kb1940\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/fix-cbt-bug-vmware-products/","summary":"VMWare, as of writing, has a nasty bug that means your backups that run utilising CBT (hint: if you have basically any enterprise backup product worth its salt, it\u0026rsquo;s got CBT enabled) it loses track of the changed blocks when the VMDK reaches any Power 2 value of 128GB (128, 256, 512, 1024, etc.) which may make your backup unrecoverable.\nThe VMWare bug is in KB:\n kb.vmware.com/selfservice/microsites/search.do?language=en_US\u0026amp;cmd=displayKC\u0026amp;externalId=2090639\n The remedy for this is to disable and re-enable (reset) CBT on the affected machines, this can be done with the machine powered off or with it turned on by running PowerCLI commands and a snapshot, we will be doing the latter, no one likes downtime:","title":"Fix for CBT bug in VMWare Products"},{"content":"I had recently come across the need to deploy an OVA file remotely and didn\u0026rsquo;t want to have to upload the file over VPN to the destination vCenter, the solution is to install OVFTool on a server that has local access to the vCenter and deploy it using the following syntax:\novftool.exe --acceptAllEulas -ds=\u0026#34;[DATASTORE NAME HERE]\u0026#34; --net:\u0026#34;NAME OF OVA NETWORK\u0026#34;=\u0026#34;NAME OF PORT GROUP\u0026#34; --prop:[PROPNAME]=[Value] \\path\\to\\appliance.ova vi://vcsa.domain.com/DatacenterName/host/ClusterName The easiest way to get a list of objects you must reference for --net and --prop values is by running (in this example I am testing a vSphere Data Protection 5.8 0 .ova):\novftool.exe \\path\\to\\appliance.ova You will receive an output similar to the below:\nDownload Size: 4.58 GB Deployment Sizes: Flat disks: 100.00 GB Sparse disks: 8.98 GB Networks: Name: Isolated Network Description: The Isolated Network network Virtual Machines: Name: vSphereDataProtection-0.0TB Operating System: sles11_64guest Virtual Hardware: Families: vmx-07 Number of CPUs: 4 Cores per socket: 1 Memory: 4.00 GB Disks: Index: 0 Instance ID: 11 Capacity: 100.00 GB Disk Types: SCSI-lsilogic NICs: Adapter Type: VmxNet3 Connection: Isolated Network Properties: ClassId: vami Key: gateway InstanceId vSphere_Data_Protection_5.8 Category: Networking Properties Label: Default Gateway Type: string Description: The default gateway address for this VM. ClassId: vami Key: DNS InstanceId vSphere_Data_Protection_5.8 Category: Networking Properties Label: DNS Type: string Description: The domain name servers for this VM (comma ClassId: vami Key: ip0 InstanceId vSphere_Data_Protection_5.8 Category: Networking Properties Label: Network 1 IP Address Type: string Description: The IP address for this interface. ClassId: vami Key: netmask0 InstanceId vSphere_Data_Protection_5.8 Category: Networking Properties Label: Network 1 Netmask Type: string Description: The netmask or prefix for this interface. We are interested in a few key items from the above:\nNICs: Adapter Type: VmxNet3 **Connection: Isolated Network** Our --net command would look like this for the above trigger:\n--net:\u0026#34;Isolated Network\u0026#34;=\u0026#34;{Port Group}\u0026#34; Where {Port Group} is the name of your vSwitch Port Group you wish to assign the appliance to.\nFrom the Properties section in the output we can see there 4 --prop triggers we are interested in - our --prop triggers would be constructed of 3 variables from each of the Properties sections:\n ClassID Key InstanceID  each --prop trigger is constructed like so:\n--prop:{ClassID}.{Key}.{InstanceID}={Value} If we take Default Gateway as an example it would be constructed like so:\n--prop:vami.gateway.vSphere_Data_Protection_5.8=10.0.0.1 You will of course chain the --prop triggers one after another in the command line.\nGiven an example datacenter our fully constructed ovftool.exe deployment command would look like this:\novftool.exe --acceptAllEulas -ds=\u0026#34;datastore1\u0026#34; \\ --net:\u0026#34;Isolated Network\u0026#34;=\u0026#34;DMZ\u0026#34; \\ --prop:\u0026#34;vami.gateway.vSphere_Data_Protection_5.8\u0026#34;=\u0026#34;10.0.2.1\u0026#34; \\ --prop:\u0026#34;vami.DNS.vSphere_Data_Protection_5.8\u0026#34;=\u0026#34;10.0.1.254\u0026#34; \\ --prop:\u0026#34;vami.ip0.vSphere_Data_Protection_5.8\u0026#34;=\u0026#34;10.0.2.150\u0026#34; \\ --prop:\u0026#34;vami.netmask0.vSphere_Data_Protection_5.8\u0026#34;=\u0026#34;255.255.255.0\u0026#34; \\ \\\\nas\\data\\nfs\\VMWare\\vSphereDataProtection-5.8.ova \\ vi://vcsa.domain.com/datacentername/host/clustername Enter username and password (in URL safe mode - substitute special characters like / or ! for %2F or %21)\nDeploy will run and show progress in CLI and vCenter\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/deploying-ovaovf-remote-vcenter-using-ovftool/","summary":"I had recently come across the need to deploy an OVA file remotely and didn\u0026rsquo;t want to have to upload the file over VPN to the destination vCenter, the solution is to install OVFTool on a server that has local access to the vCenter and deploy it using the following syntax:\novftool.exe --acceptAllEulas -ds=\u0026#34;[DATASTORE NAME HERE]\u0026#34; --net:\u0026#34;NAME OF OVA NETWORK\u0026#34;=\u0026#34;NAME OF PORT GROUP\u0026#34; --prop:[PROPNAME]=[Value] \\path\\to\\appliance.ova vi://vcsa.domain.com/DatacenterName/host/ClusterName The easiest way to get a list of objects you must reference for --net and --prop values is by running (in this example I am testing a vSphere Data Protection 5.","title":"Deploying OVA/OVF to remote vCenter using OVFTool"},{"content":"One of the things that the Dell MD Storage Manager is a progress indicator for rebuild operations or any actions at all really, it\u0026rsquo;s fairly simple to do, but you have to use the command line tool SMcli.exe that comes with MD Storage Manager.\nFirst navigate to:\nC:\\Program Files (x86)\\Dell\\MD Storage Software\\MD Storage Manager\\client Then execute:\nSMcli.exe {your.san.ip.address} -p {password} -c \u0026#34;show virtualDisk [\\\u0026#34;name-of-vdisk\\\u0026#34;] actionProgress;\u0026#34; Obviously replace the curly braces with appropriate values - as well as the \u0026quot;name-of-vdisk\u0026quot; the square brackets are part of the syntax.\nYou should get an output similar to the below:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/check-action-progress-dell-md3000i-array/","summary":"One of the things that the Dell MD Storage Manager is a progress indicator for rebuild operations or any actions at all really, it\u0026rsquo;s fairly simple to do, but you have to use the command line tool SMcli.exe that comes with MD Storage Manager.\nFirst navigate to:\nC:\\Program Files (x86)\\Dell\\MD Storage Software\\MD Storage Manager\\client Then execute:\nSMcli.exe {your.san.ip.address} -p {password} -c \u0026#34;show virtualDisk [\\\u0026#34;name-of-vdisk\\\u0026#34;] actionProgress;\u0026#34; Obviously replace the curly braces with appropriate values - as well as the \u0026quot;name-of-vdisk\u0026quot; the square brackets are part of the syntax.","title":"Check action progress on Dell MD3000i array"},{"content":"Multi-NIC vMotion is a no-brainer configuration for performance:\n Faster maintenance mode operations Better DRS load balance operations Overall reduction in lead time of a manual vMotion process.  It was introduced in vSphere 5.0 and has improved in v5.5 - so let\u0026rsquo;s get into how to configure it (we\u0026rsquo;ll be using the vSphere Web Client because that\u0026rsquo;s what VMWare wants us to do nowadays\u0026hellip;).\n I don\u0026rsquo;t have an Enterprise Plus license so no Distributed Switches for me - however, if you do have Distributed Switching licenses you should be able to extrapolate from my Standard Switching how to config yours\n First, log in and navigate to your first host Manage -\u0026gt; Networking -\u0026gt; VMKernel Adapters (I already have an existing vMotion vmk adapter - we will reuse this to create our first vMotion NIC):\n \nCreate the new VMkernel Network Adapter:\n \nAdd your vMotion VLAN, label and check the vMotion box:\n \nEnter your IP settings and finish the operation.\nDon\u0026rsquo;t forget - if you are using jumbo frames to edit the VMkernel adapter just created and set the MTU to 9000.\n \nI like to also go back into the vSwitches section and rename the first vmk port group to vMotion-1 for posterity.\nYou can of course repeat this procedure across as many NICs as VMWare supports for your pNIC, with 1Gb and 10Gb you can utilise up to 16 and 4 NICs respectively.\nNote: if you use a 1Gb NIC in your vMotion config along with your 10Gb NICs you\u0026rsquo;ll be limited to vMotion properties of the 1Gb NIC - 4 concurrent vMotion operations. 10Gb NICs limit the number of concurrent vMotion transfers to 8. Adding more NICs does NOT allow more concurrent vMotions instead, it increases throughput so the vMotion operations are faster\nNext we need to set up the failover order for each of our VMkernel adapaters - each needs one active and one standby NIC:\n \nAs you can see currently our vMotion port groups are using both adapters each, we need to fix this:\n \nEdit the first vMotion adapter\u0026rsquo;s Teaming and failover section to \u0026ldquo;Override\u0026rdquo; and prioritise your NICs as you wish:\n \nAnd do the same for the second, but obviously, swapping the NICs order for active/standby:\n \nYour vMotion port groups should now point at alternating pNICs:\n \nYou\u0026rsquo;ve successfully configured Multi-NIC vMotion, pretty easy, just be careful of MTU for jumbo frames and your failover order is correct for each of the port groups on each host.\nThis guide couldn\u0026rsquo;t have been completed without the great articles by Frank and Duncan. I also recommend Duncan\u0026rsquo;s book on VMWare clusters for those just cutting their teeth on the topic.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/setting-multi-nic-vmotion-vsphere-5-5/","summary":"Multi-NIC vMotion is a no-brainer configuration for performance:\n Faster maintenance mode operations Better DRS load balance operations Overall reduction in lead time of a manual vMotion process.  It was introduced in vSphere 5.0 and has improved in v5.5 - so let\u0026rsquo;s get into how to configure it (we\u0026rsquo;ll be using the vSphere Web Client because that\u0026rsquo;s what VMWare wants us to do nowadays\u0026hellip;).\n I don\u0026rsquo;t have an Enterprise Plus license so no Distributed Switches for me - however, if you do have Distributed Switching licenses you should be able to extrapolate from my Standard Switching how to config yours","title":"Setting Up Multi-NIC vMotion in vSphere 5.5"},{"content":"It\u0026rsquo;s fairly straight forward to update your Horizon Workspace vApp to the latest (this is an out-of-hours update due to downtime):\n  Back up your vApp\n  Ensure all VAs have connectivity to vapp-updates.vmware.com on port 80\n  Log into your configurator-va CLI with the root password you set up initially\n  Run the following command to check for update:\n  /usr/local/horizon/lib/menu/updatemgr.hzn check It should come back after checking all other appliances in the vApp with something like this:\nvdi-configurator:~ # /usr/local/horizon/lib/menu/updatemgr.hzn check Checking for updates, this can take up to 5 minutes. .. checking connector-va 192.168.xxx.xxx checking data-va 192.168.xxx.xxx checking gateway-va 192.168.xxx.xxx checking service-va 192.168.xxx.xxx Current version: 1.8.1.1810 Update version available: none Individual VM versions: configurator-va: 1.8.1.1810 connector-va: 1.8.0.1800 (Needs update) data-va: 1.8.0.1800 (Needs update) gateway-va: 1.8.0.1800 (Needs update) service-va: 1.8.0.1800 (Needs update) Some VMs are out of date. Run update to bring them up to the current version. Run the following to update your VAs:\n/usr/local/horizon/lib/menu/updatemgr.hzn update It will run through and update all VAs:\nChecking for updates, this can take up to 5 minutes. .. checking connector-va 192.168.xxx.xxx checking data-va 192.168.xxx.xxx checking gateway-va 192.168.xxx.xxx checking service-va 192.168.xxx.xxx Updating out of date VMs to version: 1.8.1.1810 Running preupdate -c Running preupdate -c connector-va CONNECTOR vdi-connector.xxxxx.xx 192.168.xxx.xxx Update connector-va to 1.8.1.1810 Running postupdate -c connector-va CONNECTOR vdi-connector.xxxxx.xx 192.168.xxx.xxx postupdate.hzn rebuilding connector-va manifest file ssh -oBatchMode=yes -o StrictHostKeyChecking=no -i /home/configurator/.ssh/id_rsa -q configurator@192.168.xxx.xxx sudo /usr/local/horizon/scripts/updfix.hzn /home/configurator/manifest-installed.save /opt/vmware/var/lib/vami/update/data/info/manifest-installed.xml 1.8.1.1810 1752346 version=1.8.1.1810 fullversion=1.8.1.1810 Build 1752346 Running preupdate -c data-va DATA vdi-data.xxxxx.xx 192.168.xxx.xxx Update data-va to 1.8.1.1810 [continues until all VAs updated...] This takes some time, so just keep an eye on the ssh output and wait for this and you\u0026rsquo;ll be ready to go:\nRunning postupdate -c updateMobilemoduleIfEnabled Check your https://[configurator-va-address]/cfg/system to make sure all the software versions match the updated version you saw earlier in the CLI when you checked for updates.That\u0026rsquo;s all there is to it, the update does take some time but is a straightforward procedure as long as you check the pre-requisites thoroughly.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/updating-vmware-horizon-workspace-vapp/","summary":"It\u0026rsquo;s fairly straight forward to update your Horizon Workspace vApp to the latest (this is an out-of-hours update due to downtime):\n  Back up your vApp\n  Ensure all VAs have connectivity to vapp-updates.vmware.com on port 80\n  Log into your configurator-va CLI with the root password you set up initially\n  Run the following command to check for update:\n  /usr/local/horizon/lib/menu/updatemgr.hzn check It should come back after checking all other appliances in the vApp with something like this:","title":"Updating VMWare Horizon Workspace vApp"},{"content":"So after the last one met it\u0026rsquo;s fate fairly quickly due to a number of tuning problems I set about rebuilding the engine again, this is what happened:\n  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/another-racecar-engine-build/","summary":"So after the last one met it\u0026rsquo;s fate fairly quickly due to a number of tuning problems I set about rebuilding the engine again, this is what happened:\n  Why not follow @mylesagray on Twitter for more like this!","title":"Another racecar engine build…"},{"content":"Introduction I have been deploying a VDI solution recently based on the fantastic VMWare Horizon Suite, one of the important points of deploying the Horizon View component of this is making it highly available and accessible from the outside for on-the-road users.\nThe best way I have found to load-balance incoming connections (both internally and externally) is to set up a linux VM and run NginX, which is a reverse caching proxy - it allows us to terminate the SSL connections and load-balance across our backend View Security Servers in a DMZ.\nYou could buy a hardware or VM load balancer from F5, Citrix, Barracuda but that will run into the £1,000\u0026rsquo;s if not £10,000\u0026rsquo;s. For our case, using NginX is more than adequate - please note some people use HAProxy, I don\u0026rsquo;t recommend this as it does not have native SSL (so HTTPS) support until v1.5 which is yet to be released.\nWhy is this important? It means you can use one address e.g: view.company.com to act as a proxy for all the backend security and/or connection servers for your users, one address is simpler to use and remember, for you, it streamlines configuration.\nImplementation Architecture So to get down to it, here\u0026rsquo;s a rough topology of what your config would look like:\n \nUbuntu Server I assume you have your linux VM installed (say Ubuntu), static IP assigned and DNS setup point view.company.com to this address.\nFirstly we need to install NginX:\naptitude update \u0026amp;\u0026amp; aptitude install nginx SSL Certs Next as VMWare View\u0026rsquo;s servers require SSL we need to have an SSL cert signed by your CA for this VM for the address view.company.com:\nmkdir /ssl \u0026amp;\u0026amp; cd /ssl openssl genrsa -out view.company.com.key 2048 openssl req -new -key view.company.com.key -out view.company.com.csr Have your CA (whether AD internal or external CA) sign the cert, retrieve the request by doing this:\ncat /ssl/view.company.com.csr The output is your Certificate Signing Request.\nIf you are using an internal Microsoft CA you can have it signed by the web GUI:\n Go to: https://[your.internal.ca.address]/CertSrv/default.asp Click \u0026ldquo;Download a CA Certificate, Certificate Chain, or CRL\u0026rdquo; Click \u0026ldquo;Base64 encoded\u0026rdquo; Click \u0026ldquo;Download CA Certificate\u0026rdquo; Go back to: https://[your.internal.ca.address]/CertSrv/default.asp Click \u0026ldquo;Request a certificate\u0026rdquo; Click \u0026ldquo;advanced certificate request\u0026rdquo; Paste in request and change template to web server Click \u0026ldquo;Submit\u0026rdquo; Download certificate (Base64 encoded) not the chain  Open both files with a text editor like Sublime Text 3 and order them in a new file like so:\n-----BEGIN CERTIFICATE----- Server Certificate -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- CA Root Certificate -----END CERTIFICATE----- Save it as a new file view.company.com.crt and transfer it to the /ssl folder on your NginX server.\nNginX Config Edit the /etc/nginx/nginx.conf file and add the following to the http { section: remember to change the upstream addresses to match your View Security Servers addresses!\n# enable reverse proxy proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwared-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; client_header_buffer_size 64k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 16k; proxy_buffers 32 16k; proxy_busy_buffers_size 64k; upstream hrz-view-cluster { server hrz-view-sec01.company.com:443 fail_timeout=1s max_fails=1; server hrz-view-sec02.company.com:443 backup; } You can of course add more upstream servers by simply adding them to the upstream section - you will also notice we are running in active-backup, this is important to preserve sessions otherwise logins don\u0026rsquo;t work as the requests get split across the two servers.\nYou can use the ip_hash module to encourage session persistence and split the load evenly (more like proper active load balancing than the failover scenario above) - however this module has a few drawbacks listed in an article here:\n Collisions as it only uses the 3 first numbers of the IP for the hash. That means that all the ips of the same C-class network range will go to the same backend server.\nAll users behind a NAT will access to the same backend server.\nIf you add new backends, all the hashes will change and sessions will be lost.\n Please note: ip_hash does now support IPv6.\nupstream hrz-view-cluster { ip_hash; server hrz-view-sec01.company.com:443; server hrz-view-sec02.company.com:443; } The final thing we need to do is set up our NginX server block for the \u0026ldquo;site\u0026rdquo; by editing /etc/nginx/sites-enabled/default, empty its contents and add the following: (Change the view.company.com instances to your own address)\n#redirect all http to https server { listen 80 default; server_name view.company.com; rewrite ^ https://view.company.com permanent; } server { listen 443 ssl; server_name view.company.com; ssl on; ssl_certificate /ssl/view.company.com.crt; ssl_certificate_key /ssl/view.company.com.key; location / { proxy_pass https://hrz-view-cluster;  } } Save file, and restart NginX:\nservice nginx restart Testing Test your http redirect by going to http://view.company.com in your browser, you should be redirected to: https://view.company.com and see something similar to this:\n \nAnd you\u0026rsquo;re done! You can now use this address in your VMWare View Client to connect to your remote desktops:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/using-nginx-load-balancer-vmware-horizon-view-security-servers/","summary":"Introduction I have been deploying a VDI solution recently based on the fantastic VMWare Horizon Suite, one of the important points of deploying the Horizon View component of this is making it highly available and accessible from the outside for on-the-road users.\nThe best way I have found to load-balance incoming connections (both internally and externally) is to set up a linux VM and run NginX, which is a reverse caching proxy - it allows us to terminate the SSL connections and load-balance across our backend View Security Servers in a DMZ.","title":"Using NginX as a load-balancer for VMware Horizon View security servers"},{"content":"In Part 1 we got the prerequisites sorted out for the HA (removed all PPPoE or DHCP address assignment from the FG boxes and VLANed a switch to split the inputs between both boxes).\nPart 2 is considerably easier, the cabling had been done for the VLANs now we had to designate 2x ports as our cluster comms ports, I chose port1 and port2 on each box, each given a weight of 50:\n \nNext we plug configure the cluster and weighting of each box in the cluster, we wanted to run ours in Active/Active - with session pickup and reserve a port for managing the units individually on port3 as you can see from the above settings.\nThe process of them bringing up the cluster goes like so:\n Backup your master config (the one you want to run on the firewalls) Set the master unit to have a higher priority - I set ours to 255 and the other to 0 Shut down both units Plug in port1 on fw-a into port1 on fw-b and the same with port2 Power on the master unit and allow it to boot fully Power on the slave unit and allow it to boot Log into the web interface of the firewall and check to see if the cluster is up as below   \nYou can view stats on the cluster by going to System -\u0026gt; Config -\u0026gt; HA and clicking View HA Statistics here you can view session distribution etc.\n \nAnd that\u0026rsquo;s it, your firewalls are now running Active/Active HA, load sharing, redundancy, the whole lot!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/fortigate-high-availability-activeactive-part-2-implementation/","summary":"In Part 1 we got the prerequisites sorted out for the HA (removed all PPPoE or DHCP address assignment from the FG boxes and VLANed a switch to split the inputs between both boxes).\nPart 2 is considerably easier, the cabling had been done for the VLANs now we had to designate 2x ports as our cluster comms ports, I chose port1 and port2 on each box, each given a weight of 50:","title":"Fortigate High Availability – Active/Active – Part 2 – Implementation"},{"content":"Introduction I recently set up 2x Fortigate 200B units to run in HA Active/Active mode, this posed a number of challenges:\n HA doesn\u0026rsquo;t work if any interfaces use PPPoE or have an address assigned via DHCP How do I effectively split our network communications between both units?  The PPPoE Problem The main problem was that both the internet connections used PPPoE for address assignment and auth - I had taken care of one of these previously as it was a simple ADSL link our Fortigate units didn\u0026rsquo;t allow for so we had a Cisco 837 box to terminate the PPPoE on a virtual interface and unnumber the static external IP to an internal interface. (Read: I used it as a proxy of sorts to get round hardware limitations).\nWe had done it before for an ADSL link so I follow the same methodology for our fiber link, except, with a faster Cisco box - in the form of a very simple, cheap Cisco 1841. Loaded the latest broadband firmware onto it (c1841-broadband-mz.151-4.M7.bin) and did the following:\n Assigned f0/0 to be our internal \u0026ldquo;gateway\u0026rdquo; address (the assigned router address from BT/Zen in the static IP block) Assigned f0/1 to be our external WAN facing address and act as PPPoE client (no ip address) Created a virtual Dialer interface Dialer1 to act as PPPoE terminator Unnumbered Dialer1\u0026rsquo;s IP against f0/0 Set mtu to 1492 on Dialer1 Enable ip cef Set adjust-mss to 1452 on f0/0 Extremely important to match frame size to ISP  Download full (nulled) config here.\nWith that out of the way I then set up our 200B to use this IP as its gateway (via static route 0.0.0.0/0.0.0.0 to go out [router address assigned to f0/0]).\n A static route was used as I can set priorities on these and give our fiber link a higher priority than the ADSL meaning we will always use the fiber link unless it breaks, when it fails over to ADSL.\n The previously configured PPPoE WAN link was changed to be \u0026ldquo;manual mode\u0026rdquo; and assigned it the desired public IP:\n \nThis then left me in a position where I could configure our 200Bs to use HA as now no interface relied on DHCP or PPPoE for addressing.\nSharing Interfaces  How do we effectively split our network communications between both units?\n This was considerably simpler than the first problem I came across - the answer is get a Gb switch - I had a Cisco 3560-X 24P-L to work with.\nI split the ports into groups of 4 ports on VLANs (a separate untagged VLAN for each usable interface on the Fortigate) this gave me:\n 1x input port 1x output port to fw-a 1x output port to fw-b 1x extra port for maintenance access  Download full (nulled) config here.\nHence the groups of 4, if you had 3x or even 4x Firewalls in A/A HA then you would need 5 and 6 ports per VLAN respectively.\nMy show vlan output looked like this (note I am using jumbo frames):\nCisco-3560X-200B-HA#sh vlan VLAN Name Status Ports ---- -------------------------------- --------- ------------------------------- 1 default active 2 lan active Gi0/1, Gi0/2, Gi0/3, Gi0/4 3 mgmt active 4 iscsi active 5 phones active Gi0/5, Gi0/6, Gi0/7, Gi0/8 6 wifi active Gi0/9, Gi0/10, Gi0/11, Gi0/12 7 microwave-wan active Gi0/13, Gi0/14, Gi0/15, Gi0/16 100 adsl active Gi0/17, Gi0/18, Gi0/19, Gi0/20 101 fiber active Gi0/21, Gi0/22, Gi0/23, Gi0/24 1002 fddi-default act/unsup 1003 token-ring-default act/unsup 1004 fddinet-default act/unsup 1005 trnet-default act/unsup VLAN Type SAID MTU Parent RingNo BridgeNo Stp BrdgMode Trans1 Trans2 ---- ----- ---------- ----- ------ ------ -------- ---- -------- ------ ------ 1 enet 100001 1500 - - - - - 0 0 2 enet 100002 9000 - - - - - 0 0 3 enet 100003 9000 - - - - - 0 0 4 enet 100004 9000 - - - - - 0 0 5 enet 100005 9000 - - - - - 0 0 6 enet 100006 9000 - - - - - 0 0 7 enet 100007 9000 - - - - - 0 0 100 enet 100100 9000 - - - - - 0 0 101 enet 100101 9000 - - - - - 0 0 1002 fddi 101002 1500 - - - - - 0 0 1003 tr 101003 1500 - - - - - 0 0 1004 fdnet 101004 1500 - - - ieee - 0 0 1005 trnet 101005 1500 - - - ibm - 0 0 All that needed to be done was plug the input ports into its respective VLAN and then take a cable to each 200B from each VLAN, effectively meaning each 200B could communicate with each input, easy.\nIn part 2 we will talk about setting up the Fortigate units themselves for HA and the proper procedure to employ for this.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/fortigate-ha-activeactive-part-1-preparation/","summary":"Introduction I recently set up 2x Fortigate 200B units to run in HA Active/Active mode, this posed a number of challenges:\n HA doesn\u0026rsquo;t work if any interfaces use PPPoE or have an address assigned via DHCP How do I effectively split our network communications between both units?  The PPPoE Problem The main problem was that both the internet connections used PPPoE for address assignment and auth - I had taken care of one of these previously as it was a simple ADSL link our Fortigate units didn\u0026rsquo;t allow for so we had a Cisco 837 box to terminate the PPPoE on a virtual interface and unnumber the static external IP to an internal interface.","title":"Fortigate High Availability – Active/Active – Part 1 – Preparation"},{"content":"Fortigate units (the big ones at least) come configured in what is called \u0026ldquo;switch mode\u0026rdquo; meaning it groups a number of interfaces together and makes them act as a switch, serves DHCP over these interfaces, etc.\nMost companies don\u0026rsquo;t like to use this - instead if we want to up our throughput for a given zone we\u0026rsquo;d create an 802.3ad aggregate link out of 2 or more of the interfaces.\nDisabling switch mode isn\u0026rsquo;t as straight forward as putting the one command in, there are two factors you need to consider:\n Are you serving DHCP over this switch interface? Have you got any policies relating to this interface?  If the answer is \u0026ldquo;yes\u0026rdquo; to either of these you need to do the following or you will see one of Interface switch is in use or Interface internal is in use or Entry is used later on:\nDelete the DHCP server relating to it (either in the GUI as below):\n \nOr you can do it in the CLI:\nfw-a # config sys dhcp server fw-a (server) # show \u0026lt;look at list and find the entry number relating to your interface\u0026gt; fw-a (server) # delete [entry number here] fw-a (server) # end Next you need to delete all policies relating to the interface again, this can be done in the GUI via Policy -\u0026gt; Policy -\u0026gt; Policy and delete all policies associated with that interface. Again, it can be done with the CLI:\nfw-a # config firewall policy fw-a (policy) # show \u0026lt;look at list and find the entry number(s) relating to your interface\u0026gt; fw-a (policy) # delete [entry number here] fw-a (policy) # end Once all the switch mode interface\u0026rsquo;s related objects are deleted then we can change the global mode from switch to interface via CLI:\nfw-a # config sys global fw-a (global) # set internal-switch-mode interface fw-a (global) # end Changing switch mode will reboot the system! Do you want to continue? (y/n) y The box will reboot and you\u0026rsquo;ll have a host of new interfaces to use as you like.\nN.B: Some boxes are awkward and will require you to deleted the virtual hardware/software switch that is created it you still can\u0026rsquo;t see the individual IFs run the following commands:\nconfigure system virtual-switch delete {interface name e.g. lan, internal} If you are still having difficulty you can run the following to find any remaining related entries to the interface:\ndiagnose sys checkused sys.interface.name {interface name e.g. lan, internal} This command will output any entries that relate to this object and might stop it from being removed.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/changing-fortigate-switch-mode-interface-mode/","summary":"Fortigate units (the big ones at least) come configured in what is called \u0026ldquo;switch mode\u0026rdquo; meaning it groups a number of interfaces together and makes them act as a switch, serves DHCP over these interfaces, etc.\nMost companies don\u0026rsquo;t like to use this - instead if we want to up our throughput for a given zone we\u0026rsquo;d create an 802.3ad aggregate link out of 2 or more of the interfaces.","title":"Changing Fortigate from Switch mode to Interface mode"},{"content":"It\u0026rsquo;s sometimes necessary (say you\u0026rsquo;ve been working on a VM on your local workstation in either VMWare Fusion, or VMWare Workstation) to move the VM you\u0026rsquo;ve been playing with to an ESXi instance to either move into development or to have it properly backed up etc.\nThe easiest way I find to do this is create a .ova file from the VM i\u0026rsquo;ve been working on.\nFirst install the VMWare OVATool found here on whatever flavour your OS is (sign in required): https://my.vmware.com/group/vmware/details?downloadGroup=OVFTOOL350\u0026amp;productId=352\nOnce it\u0026rsquo;s running, navigate to the install folder (i\u0026rsquo;m using OSX, if you use Windows I assume it\u0026rsquo;s installed in the system path and you can execute it directly from any directory) and the syntax is as follows:\n./ovftool [original .vmx location and filename] [new .ova location and filename] So in my case I was working on the wonderful YubiX authentication virtual appliance:\n./ovftool ~/Documents/vms/yubix.vmx ~/Documents/vms/yubix.ova The output will be somewhat similar to the below:\n$ ./ovftool ~/Documents/vms/yubix.vmx ~/Documents/vms/yubix.ova Opening VMX source: /Users/graym/Documents/vms/yubix.vmx Opening OVA target: /Users/graym/Documents/vms/yubix.ova Writing OVA package: /Users/graym/Documents/vms/yubix.ova Transfer Completed Completed successfully Then I just used the deploy OVF Template wizard in vSphere Web Client.\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/virtualisation/using-vmwares-ovftool-convert-vmx-ova/","summary":"It\u0026rsquo;s sometimes necessary (say you\u0026rsquo;ve been working on a VM on your local workstation in either VMWare Fusion, or VMWare Workstation) to move the VM you\u0026rsquo;ve been playing with to an ESXi instance to either move into development or to have it properly backed up etc.\nThe easiest way I find to do this is create a .ova file from the VM i\u0026rsquo;ve been working on.\nFirst install the VMWare OVATool found here on whatever flavour your OS is (sign in required): https://my.","title":"Using VMWare’s OVFTool to convert VMX to OVA"},{"content":"Fortigate\u0026rsquo;s logging typically isn\u0026rsquo;t the best - but it\u0026rsquo;s bad when you have no logs at all, which seems to be the default. To enable logging on fortigate models with an internal SSD/HDD use the following command:\nconfig log disk setting set status enable You can now collect and view your logs in the Log \u0026amp; Report section.\nN.B. As of FortiOS 5.2 this has been disabled on all SMB class (100D and below) units. You will need to use memory logging or export to syslog.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/enabling-disk-logging-fortigates/","summary":"Fortigate\u0026rsquo;s logging typically isn\u0026rsquo;t the best - but it\u0026rsquo;s bad when you have no logs at all, which seems to be the default. To enable logging on fortigate models with an internal SSD/HDD use the following command:\nconfig log disk setting set status enable You can now collect and view your logs in the Log \u0026amp; Report section.\nN.B. As of FortiOS 5.2 this has been disabled on all SMB class (100D and below) units.","title":"Enabling disk logging on a FortiGate"},{"content":"Spent a lot of my free time recently finishing up an edit I was doing for my climbing club, for our trip to El Chorro, Andalucia, Spain in February.\nShot it on 4x GoPro HD Hero 2 cameras over about a week, check it out.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/qubmc-el-chorro-video-2013/","summary":"Spent a lot of my free time recently finishing up an edit I was doing for my climbing club, for our trip to El Chorro, Andalucia, Spain in February.\nShot it on 4x GoPro HD Hero 2 cameras over about a week, check it out.\nWhy not follow @mylesagray on Twitter for more like this!","title":"QUBMC – El Chorro Video 2013"},{"content":"I had problems recently on a Dell R720XD giving problems when trying to install openSUSE, regardless of the mode I set it up in I would get strange vertical coloured lines on the monitor. It\u0026rsquo;s a graphics driver problem clearly - the solution, on the openSUSE boot screen, move to Installation and in the boot options section type in:\nnomodeset Then go ahead and continue your install as normal - seems the 3D driver causes problems (with this box at least). Took me about an hour to figure this one out, I worked through all the graphics options including Text Mode - none worked except the above.\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/software/opensuse-nomodeset/","summary":"I had problems recently on a Dell R720XD giving problems when trying to install openSUSE, regardless of the mode I set it up in I would get strange vertical coloured lines on the monitor. It\u0026rsquo;s a graphics driver problem clearly - the solution, on the openSUSE boot screen, move to Installation and in the boot options section type in:\nnomodeset Then go ahead and continue your install as normal - seems the 3D driver causes problems (with this box at least).","title":"openSUSE Install Graphics Problems?"},{"content":"Introduction Centrally managing your storage is nice - especially when you\u0026rsquo;ve just built your own SANs (or such). I created a synchronous replicating SAN cluster using LSI MegaRAID 9270-8i cards in 2x Dell R720XD chassis built on openSUSE 12.3 (more on that in another article soon).\nWe are migrating from 2x Dell MD3000i to these beasts built on a pure-cli OS. Some people like GUIs and that\u0026rsquo;s okay - so for day-to-day admin, email reporting on problems and basic configuration and tasks LSI offer (free) MegaRAID Storage Manager. It works much in the same way as Dell\u0026rsquo;s MD Storage Manager that we currently use for the MD3000i but (obviously) without the ability to create iSCSI LUNs etc as they are managed by the OS, not the RAID card.\nSo, to get rolling we need to log into openSUSE, and sudo bash your way in there.\nInstalling We need to create a temp directory, download LSI MSM for Linux (x64) into it, extract it and install:\nmkdir temp cd temp/ wget \u0026#34;http://www.lsi.com/downloads/Public/MegaRAID%20Common%20Files/13.08.04.01_Linux(64)_MSM.tar.gz\u0026#34; tar zxvf 13.08.04.01_Linux(64)_MSM.tar.gz cd disk/ We need to install net-snmp as a prerequisite:\nzypper install net-snmp Then go ahead and install MSM server agent (the component that reports back to the management client):\n./install.csh -d See below for complete trigger reference:\n./install.csh -h Usage : install.sh [-option] The options are : a The Complete Installation of MegaRAID Storage Manager (MSM) c The Client components only program of MSM s The StandAlone component of MSM l The Local component of MSM d The Server component of MSM au The upgrade only option for Complete MSM cu The upgrade only option for Client only MSM su The upgrade only option for Standalone MSM lu The upgrade only option for Local MSM du The upgrade only option for Server MSM If all is well you\u0026rsquo;ll see this:\n./install.csh -d .... Checking for any Old Version No Old Version Found Continuing with installation Preparing... ################################# [100%] Installing.... Updating / installing... 1:Lib_Utils2-1.00-05 ################################# [100%] Installing MegaRAID_Storage_Manager-13.08.04-01 Preparing... ################################# [100%] Installing.... Updating / installing... 1:MegaRAID_Storage_Manager-13.08.04################################# [100%] / / / Starting Framework: Installing sas_ir_snmp-13.08-0401 Preparing... ################################# [100%] Updating / installing... 1:sas_ir_snmp-13.08-0401 ################################# [100%] Starting snmpd redirecting to systemctl restart snmpd Registering Service lsi_mrdsnmpd lsi_mrdsnmpd 0:off 1:off 2:on 3:on 4:on 5:on 6:off redirecting to systemctl stop lsi_mrdsnmpd Starting LSI SNMP Agent redirecting to systemctl start lsi_mrdsnmpd Let\u0026rsquo;s install the MSM Management GUI on our Windows/[Linux]x641 box, just run through the installer, this time you just need client installed.\nManaging Storage Open up MegaRAID Storage Manager and click Configure Host, change the radio button to be Display all systems in the network of local server and press Save Settings. It will then scan your local network for hosts:\n \nClick the host and log in with your root account:\n \nAll the metrics, visuals and nice fancy views you could ever desire, along with the ability to manage and rebuild arrays, configure volume groups and all the stuff listed here. Enjoy!\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/installing-megaraid-storage-manager-opensuse/","summary":"Introduction Centrally managing your storage is nice - especially when you\u0026rsquo;ve just built your own SANs (or such). I created a synchronous replicating SAN cluster using LSI MegaRAID 9270-8i cards in 2x Dell R720XD chassis built on openSUSE 12.3 (more on that in another article soon).\nWe are migrating from 2x Dell MD3000i to these beasts built on a pure-cli OS. Some people like GUIs and that\u0026rsquo;s okay - so for day-to-day admin, email reporting on problems and basic configuration and tasks LSI offer (free) MegaRAID Storage Manager.","title":"Installing MegaRAID Storage Manager on openSUSE"},{"content":"So you\u0026rsquo;ve downloaded all the new VMWare 5.5 goodies and you want to upgrade your vCSA install to v5.5 - this is a little more involved than you may think, however it is very much worth the effort:\n In vSphere 5.5, the vCenter Server Appliance limitations have been extremely raised when using the embedded database: Previous to vSphere 5.5, the limits were:\n 5 vSphere Hosts 50 Virtual Machines   With vSphere 5.5, the limits are now:\n  400 vSphere Hosts 4000 Virtual Machines   Referenced article: http://kb.vmware.com/kb/2057376 Original reports denoted 500 vSphere Hosts and 5000 Virtual Machines.\nA tweet Justin King mentioned a 100/3000 limit:\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  Hot Off the Press! I can confirm the vCenter Appliance 5.5 will support up to 100 hosts and/or 3000 VMs with its embedded vPostgres database\n\u0026mdash; Justin King (@VxJustinKing) September 5, 2013 In short the vCenter Server Appliance now has the horsepower to run in many, if not most vSphere Environments – even in the Fed space.\nAnd if that wasn\u0026rsquo;t enough incentive there are all the updates that are included in vSphere Web Client (a total overview with this quick reference is good to look at):\n Console is now HTML5 Web Client is now completely platform agnostic - Mac OSX FTW! SSO greatly improved Recently visited \u0026amp; created objects vSphere Inventory Navigator History Deploy vCenter Operations from vSphere Web Client  Alright so now that we\u0026rsquo;re all psyched to upgrade to vCSA 5.5, lets get to it (very useful KB article)! Download the vCSA 5.5 .ova\nDeploy this to your cluster/host/whatever (with all default settings). (File -\u0026gt; Deploy OVF Template)\nDeploying vCSA v5.5\n \nGoto the IP address of your newly deployed vcsa instance and Accept the EULA, click Next, select Upgrade from previous version.\n \nCopy the key from the new appliance, into the Upgrade section of the old appliance and click Import remote key. Copy the upgrade key out of the old appliance and paste it into the Paste source appliance key section and click Next. Check replace SSL certificates.\n \nAdd the password for the new vcsa appliance and continue through all the prompts, view the list of hosts presented by the vcsa appliance and ensure the ones you want that vcsa instance to manage are checked. Make sure you\u0026rsquo;ve backed up or snapshotted your vcsa instance and continue through the pre-upgrade checker then click upgrade.\n \nThe new appliance shuts down the old appliance and assumes the network identity of the old appliance. If the old appliance was configured to use dynamic addressing, the new appliance will also use dynamic addressing. When the import is complete, the new vCenter Server Appliance starts.\n \nClick close and the vcsa appliance will reboot.\nYou\u0026rsquo;re done - your new vcsa appliance has taken the network identity on of the old one and all it\u0026rsquo;s parameters (you may need to confirm some SSL cert changes for the likes of VUM, vSphere Desktop Client etc).\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/upgrading-vcenter-server-appliance-vcsa-5-5/","summary":"So you\u0026rsquo;ve downloaded all the new VMWare 5.5 goodies and you want to upgrade your vCSA install to v5.5 - this is a little more involved than you may think, however it is very much worth the effort:\n In vSphere 5.5, the vCenter Server Appliance limitations have been extremely raised when using the embedded database: Previous to vSphere 5.5, the limits were:\n 5 vSphere Hosts 50 Virtual Machines   With vSphere 5.","title":"Upgrading vCenter Server Appliance to vCSA 5.5"},{"content":"Again, Fortigate\u0026rsquo;s documentation falls down at the simplest of things, this time, syslogging - To get your Fortigate to log to a syslogger (like Kiwi/Splunk) you\u0026rsquo;ll need to go in via the CLI as they have removed this option from the GUI as of FortiOS v5.0.\nLog in via shell and enter the following:\nconfig log syslogd setting set status enable set server [ip.or.dns-name.here] end I have seen where people say you need to explicitly:\nset port 514 or set facility local7 but these are defaults and implied.\nYou can set up multiple syslog server locations by simply changing the first line to config log [syslog2|syslog3] setting and filling in the details for the other syslog servers.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/syslogd-fortios-5-0-4/","summary":"Again, Fortigate\u0026rsquo;s documentation falls down at the simplest of things, this time, syslogging - To get your Fortigate to log to a syslogger (like Kiwi/Splunk) you\u0026rsquo;ll need to go in via the CLI as they have removed this option from the GUI as of FortiOS v5.0.\nLog in via shell and enter the following:\nconfig log syslogd setting set status enable set server [ip.or.dns-name.here] end I have seen where people say you need to explicitly:","title":"Syslogd on FortiOS 5.0.4"},{"content":"Recently had a problem were Veeam was giving bother on one VM that had a dedicated datastore, not allowing hot-add virtual appliance mode to work.\nI originally thought it was a problem with CBT (changed block tracking) so I disabled that, with no luck, as it transpires there were a few (all datastore formatting related) problems:\n The Veeam proxy\u0026rsquo;s datastore was formatted in VFMS-3 with a 2MB block size and upgraded to VMFS-5 (retaining its 2MB block size of course - otherwise a reformat would be needed). The source machine\u0026rsquo;s datastore was formatted in VMFS-3 with an 8MB block size and later upgraded to VMFS-5 (retaining its 8MB block size). The target datastore was formatted in VMFS-5 natively with a unified 1MB block size.  So when the proxy tries to hot-add the disk the VMFS block size on the source machine\u0026rsquo;s datastore is larger than the proxy\u0026rsquo;s datastore block size and the hot-add fails.\n \nOne solution was to put it in network mode but this can be slow and it\u0026rsquo;s not a nice way of doing things, so I wanted to run it in VA mode.\nWhat I ended up doing was shutting down the source machine, migrating it to a VMFS-5 datastore, reformatting it\u0026rsquo;s original datastore to native VMFS-5 (native VMFS-5 volumes are all created with a unified 1MB block size) and migrating the source VM back to its original location.\nThe hot-add then worked as expected. In an ideal world one would reformat all their datastores to VMFS-5 with the standard 1MB block size and this is what I am working towards.\n\u0026ldquo;What about the VMDK file size limit tied to block size?\u0026rdquo; I hear you say - well, as of VMFS-5 the 1MB block size now supports 2TB .vmdk files:\nThe limits that apply to VMFS-5 datastores are:\n The maximum virtual disk (VMDK) size is 2 TB minus 512 B. The maximum\nvirtual-mode RDM size is 2 TB minus 512 B. Physical-mode RDMs are\nsupported up to 64 TB.\n As of VSphere 5.5 this will change to 64TB - though why you would want a .vmdk this size beats me - i\u0026rsquo;d have the disk split and clustered, if it was a Windows box e.g. SBS, Exchange or SQL - though, if you need this disk size you\u0026rsquo;re likely already using RDM for those.\nAny input on this however is welcome.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/veeam-hot-add-mode-fails/","summary":"Recently had a problem were Veeam was giving bother on one VM that had a dedicated datastore, not allowing hot-add virtual appliance mode to work.\nI originally thought it was a problem with CBT (changed block tracking) so I disabled that, with no luck, as it transpires there were a few (all datastore formatting related) problems:\n The Veeam proxy\u0026rsquo;s datastore was formatted in VFMS-3 with a 2MB block size and upgraded to VMFS-5 (retaining its 2MB block size of course - otherwise a reformat would be needed).","title":"Veeam Hot-Add Mode Fails – Mismatching VMFS block size"},{"content":"Introduction Netgear for some reason believe that ReadyNAS models that aren\u0026rsquo;t the \u0026ldquo;Pro\u0026rdquo; line don\u0026rsquo;t require network teaming across both their ethernet ports, so you have 2 network ports on your NAS, you\u0026rsquo;ve got your jumbo frames on and you want to configure load balancing/failover via the 2 interfaces.\nOf course the ReadyNAS is based on Debian linux, you could SSH into the box and use /etc/network/interfaces to configure a networking bond using: mode=balance-rr or using aggregated link spec 802.3ad if you have a switch that supports it: mode=802.3ad.\nHowever, Netgear also think it is a good idea to \u0026ldquo;bork\u0026rdquo; your install on reboot if you mess with your networking in such a way even though it\u0026rsquo;s a standard Linux package and kernel.\nEnabling NIC Teaming As such the best way I have found to achieve what we are after on the non-pro models is to simply use an addon.\nIt is meant to be for the Pioneer models but works fine on my Ultra-6, wish i\u0026rsquo;d have found this sooner and not spent so much time trying to do it natively!\nConfiguring is simple, download go to your NAS\u0026rsquo;s admin page -\u0026gt; add-ons -\u0026gt; add new, upload \u0026amp; verify the addon:\n \nGoto add-ons -\u0026gt; installed and enable Teaming for Pioneer, Choose your teaming method, I am running mine in round-robin at the moment with jumbo frames enabled:\n \nVerification Check it all worked in your Network -\u0026gt; Interfaces section - It should display Ethernet 1+2 at the top and the link as 2Gbit:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/teaming-readynas-ultra-nics/","summary":"Introduction Netgear for some reason believe that ReadyNAS models that aren\u0026rsquo;t the \u0026ldquo;Pro\u0026rdquo; line don\u0026rsquo;t require network teaming across both their ethernet ports, so you have 2 network ports on your NAS, you\u0026rsquo;ve got your jumbo frames on and you want to configure load balancing/failover via the 2 interfaces.\nOf course the ReadyNAS is based on Debian linux, you could SSH into the box and use /etc/network/interfaces to configure a networking bond using: mode=balance-rr or using aggregated link spec 802.","title":"Teaming ReadyNAS Ultra NICs"},{"content":"Obviously nowadays when admining we mostly have laptops - laptops don\u0026rsquo;t tend to come with serial I/O ports anymore, so you buy a Serial -\u0026gt; USB adapter, say this one or any one with a legit (there are fakes) FDTI FT232RL chipset.\nDownload and install the relevant drivers but where do we go from here?\nSpecifically on mac, find your device\u0026rsquo;s tty name:\ncd /dev ls -ltr *usb* I added a handy little alias to my\n.bash_profile so i don\u0026rsquo;t have to remember the screen\u0026rsquo;s tty connection name (obviously replace the tty.usbserial-XXXXXXXX with your converter\u0026rsquo;s tty):\nalias serial=\u0026#39;screen /dev/tty.usbserial-XXXXXXXX\u0026#39; So you can use this to connect instead:\nserial [baudrate] You can of course use the same method to connect to Cisco switches and routers that have USB consoles:\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/serial-usb-console-osx/","summary":"Obviously nowadays when admining we mostly have laptops - laptops don\u0026rsquo;t tend to come with serial I/O ports anymore, so you buy a Serial -\u0026gt; USB adapter, say this one or any one with a legit (there are fakes) FDTI FT232RL chipset.\nDownload and install the relevant drivers but where do we go from here?\nSpecifically on mac, find your device\u0026rsquo;s tty name:\ncd /dev ls -ltr *usb* I added a handy little alias to my","title":"Serial and USB Console on Mac OSX"},{"content":"This info is quite hard to come across and Fortigate don\u0026rsquo;t have it in their GUI from FortiOS v5.0+, SSH into your Fortigate\u0026rsquo;s CLI and enter the following (it can be done on both software aggregated and standard interfaces):\nconfig system interface edit [interfacename] set mtu-override enable set mtu 9208 end end Confirm your MTU size change has worked on the given interface by plugging directly into it (test MTU in accordance to my guide here).\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/change-mtu-support-jumbo-frames-fortios/","summary":"This info is quite hard to come across and Fortigate don\u0026rsquo;t have it in their GUI from FortiOS v5.0+, SSH into your Fortigate\u0026rsquo;s CLI and enter the following (it can be done on both software aggregated and standard interfaces):\nconfig system interface edit [interfacename] set mtu-override enable set mtu 9208 end end Confirm your MTU size change has worked on the given interface by plugging directly into it (test MTU in accordance to my guide here).","title":"Change MTU to support Jumbo Frames in FortiOS"},{"content":"Introduction Fairly straight forward this time, you\u0026rsquo;ve configured your MTU/jumbo frames to be 9000 on your client and destination devices (say a laptop/desktop/server/san/nas) and on ALL your switching devices in between - you\u0026rsquo;ve done that right? ;)\nTesting So the next step is, we want to test if our new 9000 byte MTU is actually working and we can reap the benefits of a larger packet size (whether it\u0026rsquo;s on iSCSI, LAN, whatever) being of course a higher latency but also higher throughput. This depends on the OS you are running.\nMacOS On Mac OSX (that I run) it\u0026rsquo;s:\nping -D -s 8184 [destinationIP] Linux On Linux it\u0026rsquo;s:\nping -M do -s 8972 [destinationIP] Windows On Windows it\u0026rsquo;s:\nping -f -l 9000 [destinationIP] Additional Context The reason for the 8972 on *nix devices is that the ICMP/ping implementation doesn\u0026rsquo;t encapsulate the 28 byte ICMP (8) + IP (20) (ping + standard internet protocol packet) header - thus we must take the 9000 and subtract 28 = 8972.\nOn Mac\u0026rsquo;s even though they are *nix kernels, the ping implementation only supports packets 8192 in size so we must remove the ICMP (8 byte) header as the ping implementation has already included the 20 byte IP header, 8192 - 8 = 8184.\n(Apple macs DO support packets up to 9000 bytes, just the ICMP implementation they sport doesn\u0026rsquo;t\u0026hellip;)\nEDIT 31/10/13: According to BernieC in a comment here OSX does support 9000+ byte packets if you run the following command to increase its maximum datagram size:\nsudo sysctl -w net.inet.raw.maxdgram=16384 It is also important to understand where I got my values from this is an IP packet\u0026rsquo;s layout, you can see the IP info is 20 bytes:\n \nTroubleshooting If you\u0026rsquo;ve forgotten to enable jumbo frames/9k MTU on your client device you\u0026rsquo;re sending the ping from you\u0026rsquo;ll see:\nPING xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx): 8184 data bytes ping: sendto: Message too long If you have enabled jumbo frames on your client but not the destination (or a switch in between) you\u0026rsquo;ll see:\nPING xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx): 8184 data bytes Request timeout for icmp_seq 0 If you\u0026rsquo;ve done everything right and you\u0026rsquo;re set up ready to go you\u0026rsquo;ll get this:\nPING xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx): 8184 data bytes 8192 bytes from xxx.xxx.xxx.xxx: icmp_seq=0 ttl=128 time=0.714 ms Now rejoice in your lovely jumbo-framey goodness and a good 20-30% in sustained data throughput.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/networks/test-jumbo-frames-working/","summary":"Introduction Fairly straight forward this time, you\u0026rsquo;ve configured your MTU/jumbo frames to be 9000 on your client and destination devices (say a laptop/desktop/server/san/nas) and on ALL your switching devices in between - you\u0026rsquo;ve done that right? ;)\nTesting So the next step is, we want to test if our new 9000 byte MTU is actually working and we can reap the benefits of a larger packet size (whether it\u0026rsquo;s on iSCSI, LAN, whatever) being of course a higher latency but also higher throughput.","title":"How to test if 9000 MTU/Jumbo Frames are working"},{"content":"Introduction Some things should be simple, shrinking a thin provisioned virtual disk should be one of them, it\u0026rsquo;s not. N.B. This will just reduce the VMDK\u0026rsquo;s usage on the VMFS datastore NOT resize the \u0026ldquo;provisioned size\u0026rdquo; of a thin disk.\nTo shrink a VMDK we can use an ESX command line tool vmkfstools, but first you have to zero out any free space on your thin provisioned disk.\nWindows On Windows guests we can use the sysinternals tool SDelete (replace the [DRIVE:] with the relevant Windows drive letter) you must use v1.6 or later!:\nsdelete.exe -z [DRIVE:] This will fill any unused space on the drive specified with zero-blocks.\nCaution: This operation will expand your thin-disk to its maximum size, ensure your datastore has the capacity to do this before you run this operation.\nAs of v1.6 -c and -z have changed meanings, many instructions say -c zeros free space, this is no longer the case, it zeros the space then fills with random data in accordance with DOD spec: DOD 5220.22-M, the trigger to zero space with 0x00 has changed to -z!\nLinux On linux guests use:\ndd if=/dev/zero of=/[PATH]/zeroes bs=4096 \u0026amp;\u0026amp; rm -f /[PATH]/zeroes Again, replace [PATH] with the relevant path to a location on the target storage device. Next we will shut down the guest OS and SSH into the ESX shell, once in the shell we need to navigate to the VMDK\u0026rsquo;s datastore -\u0026gt; directory and we\u0026rsquo;ll check the VM\u0026rsquo;s actual size:\ndu -h [DISKNAME].vmdk Punch all zeroed blocks out of the VMDK:\nvmkfstools --punchzero [DISKNAME].vmdk Check the size again (will now be less):\ndu -h [DISKNAME].vmdk Of course, replace [DISKNAME] with your VMDK\u0026rsquo;s actual name. There we have it, all that free space, now reclaimed.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/infrastructure/zero-free-space-using-sdelete-shrink-thin-provisioned-vmdk/","summary":"Introduction Some things should be simple, shrinking a thin provisioned virtual disk should be one of them, it\u0026rsquo;s not. N.B. This will just reduce the VMDK\u0026rsquo;s usage on the VMFS datastore NOT resize the \u0026ldquo;provisioned size\u0026rdquo; of a thin disk.\nTo shrink a VMDK we can use an ESX command line tool vmkfstools, but first you have to zero out any free space on your thin provisioned disk.\nWindows On Windows guests we can use the sysinternals tool SDelete (replace the [DRIVE:] with the relevant Windows drive letter) you must use v1.","title":"Zero free space using SDelete to shrink Thin Provisioned VMDK"},{"content":"I have had the need recently to expand a LUN on a Dell MD3000i SAN to above 2TB that is presented to VMWare ESX 5.1 hosts.\nThere are a few caveats here:\n The VMWare datastore for 2TB+ LUNs must be VMFS-5 as it is now GPT based, not MBR. This can be updated on the fly without shutting down VMs  (Configuration -\u0026gt; Storage, Click the Datastore -\u0026gt; \u0026ldquo;Upgrade to VMFS-5\u0026rdquo;)   Expanding the virtual disks on MD3000i\u0026rsquo;s can only be done in CLI.  First, add your new physical disks to the box and add them to the appropriate RAID volume group. Next, you will be presented your space as \u0026ldquo;Free Capacity\u0026rdquo; - copy down the size of this in GB. Convert GB to Bytes here.\n \nOn the computer running MD Storage Manager open cmd and navigate to C:\\Program Files\\Dell\\MD Storage Manager\\Client\nThe command you need to run is:\nSMCli.exe [your.san.ip.address] -c \u0026#34;set VirtualDisk [\u0026#34;[VDNAME]\u0026#34;] addCapacity=XXXXXXXXXX;\u0026#34; -p [password] Of course, replace the [your.san.ip.address], [password], [VDNAME] (of the disk you wish to expand) and XXXXXXXXX capacity (in Bytes) to those appropriate to you. You\u0026rsquo;ll see the following output if the command runs successfully:\nPerforming syntax check... Syntax check complete. Executing script... Script execution complete. SMcli completed successfully. You can then watch your initialisation progress with (follow same replacements as above):\nSMCli.exe [your.san.ip.address] -c \u0026#34;show VirtualDisk [\u0026#34;[VDNAME]\u0026#34;] actionprogress;\u0026#34; -p [password] N.B: Sorry to all my linux friends - Dell don\u0026rsquo;t let you SSH into the box - you\u0026rsquo;ll have to use a VM :(\nYou can then go back to VSphere Client and choose your datastore - Right click, Properties -\u0026gt; Increase -\u0026gt; Choose the LUN you just expanded, expand VMFS to maximum size available, Finish, your datastore is now expanded.\n \nAll the above can be done on a live system - though due to the I/O from the volume initialization and inherent risks make sure you have backups and that you do this after hours ;)\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/extend-dell-md3000i-virtual-disk-lun-size/","summary":"I have had the need recently to expand a LUN on a Dell MD3000i SAN to above 2TB that is presented to VMWare ESX 5.1 hosts.\nThere are a few caveats here:\n The VMWare datastore for 2TB+ LUNs must be VMFS-5 as it is now GPT based, not MBR. This can be updated on the fly without shutting down VMs  (Configuration -\u0026gt; Storage, Click the Datastore -\u0026gt; \u0026ldquo;Upgrade to VMFS-5\u0026rdquo;)   Expanding the virtual disks on MD3000i\u0026rsquo;s can only be done in CLI.","title":"Extend Dell MD3000i Virtual Disk LUN Size"},{"content":"Video I shambled together for my university climbing club\u0026rsquo;s recent trip to Scotland.\n  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/ice-climbing-trip-to-scotland/","summary":"Video I shambled together for my university climbing club\u0026rsquo;s recent trip to Scotland.\n  Why not follow @mylesagray on Twitter for more like this!","title":"Ice Climbing trip to Scotland"},{"content":"For those of you that don\u0026rsquo;t know, emoncms is a small cms that will accept inputs via GET requests for things like power meters, temp probes for measuring household power usage, PV panel, windmill etc power production levels.\nTo achieve this you need to use git to download the newest version of emoncms (the new more modularised version):\ngit clone git://github.com/emoncms/emoncms.git Next step is to set up a mysql db:\n$mysql-uroot-pmysql\u0026gt;CREATEDATABASEemoncms;mysql\u0026gt;exitNext we are going to write and nginx config for emoncms I have hosted mine on https w/ SPDY however for simplicity this config is for http:\nserver { listen 80; server_name sub.domain.name; location / { root /path/to/your/emoncms; index index.php; rewrite ^/(.*)$ /index.php?q=$1 last; } location ~* ^.+.(jpg|jpeg|gif|css|png|js|ico|xml)$ { expires 30d; root /path/to/your/emoncms; } location ~ .php$ { fastcgi_split_path_info ^(.+.php)(.*)$; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /path/to/your/emoncms$fastcgi_script_name; include fastcgi_params; fastcgi_intercept_errors on; } } I\u0026rsquo;d like to highlight this line:\nrewrite ^/(.*)$ /index.php?q=$1 last; This is extremely important to make emoncms work, it rewrites the pretty URLs to reference them to the index file. Without this you will get \u0026ldquo;Invalid Username/Password\u0026rdquo; when you try to log in or register. cd to your emoncms folder and move the default settings file to make it active, then open it:\ncd /var/www/emoncms/ mv default.settings.php settings.php nano settings.php Then change your DB settings like so:\n/* Database connection settings */ $username = \u0026#34;youruser\u0026#34;; $password = \u0026#34;yourpassword\u0026#34;; $server = \u0026#34;localhost\u0026#34;; $database = \u0026#34;emoncms\u0026#34;; Now restart NginX:\nservice nginx restart If all is well you will be able to navigate to your URL, enter a username and password then click Register, a bit counter-intuitive but there we are.\n \nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/how-to-run-emoncms-on-nginx-and-php5-fpm/","summary":"For those of you that don\u0026rsquo;t know, emoncms is a small cms that will accept inputs via GET requests for things like power meters, temp probes for measuring household power usage, PV panel, windmill etc power production levels.\nTo achieve this you need to use git to download the newest version of emoncms (the new more modularised version):\ngit clone git://github.com/emoncms/emoncms.git Next step is to set up a mysql db:","title":"How to: Run emoncms on NginX and PHP5-FPM"},{"content":"Spent a good deal of my summer building the engine in my R53 Mini back up from scratch with the help from an American friend. Car now produces 293bhp and is good to rev up to 8.3-8.5K rpm, a full spec list can be found here.\nNice little time-lapse of the build:\n  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/r53-mini-cooper-s-jcw-engine-rebuild/","summary":"Spent a good deal of my summer building the engine in my R53 Mini back up from scratch with the help from an American friend. Car now produces 293bhp and is good to rev up to 8.3-8.5K rpm, a full spec list can be found here.\nNice little time-lapse of the build:\n  Why not follow @mylesagray on Twitter for more like this!","title":"R53 Mini Cooper S JCW Engine Rebuild"},{"content":"Background So this was me when i first got the motherboard:\n Got a Blitz formula today and i thought all was well plugged in the 24pin ATX and EATX power and all the lights were on (good stuff) Clicked the on button, the LCD was stuck with CPU INIT, I\u0026rsquo;ve tried clearing CMOS everything I don\u0026rsquo;t know what the hell is wrong, currently in the process of resetting the CMOS (press CLR_CMOS button and take out the battery for 2 hours). The board is spotless, absolutely perfect, all the lights come on and even when you install the GPU wrong the little warning light comes on but it will not POST, just says CPU INIT all the time and restarts every 3/4 seconds as if there was a bad overclock and it was resetting to default.\n As you can see something was obviously up with it and as it wouldn\u0026rsquo;t even POST i couldn\u0026rsquo;t flash the BIOS. So I looked for alternate methods and there were 2 open to me:\n De/Re-Solder the BIOS chip with a new one Work out how to flash using the SPI Port and flash from another computer (or in my case a very old laptop with an LPT port on it)  So naturally I chose the latter, but the next challenge was to find out how I go about using this SPI port (which looks very similar to a USB header).\nYou will need  Broken Motherboard Spare PSU Paperclip Laptop/Desktop with LPT/Serial 100 Ohm Resistors (x4) An old unused cable with a 2*5 header on one end Universal Boot CD v4.1.1 (Version Important) SPIPGM CWSDPMI7 (Copy contents of /bin folder to the same directory as SPIPGM2) Cable Wiring Guide A BIOS ROM for your motherboard (download the latest) Basic DOS knowledge  Method First things first, you want to download the 3 files (The Boot CD .iso, SPIPGM (Used to flash the ROM), CWSDPMI7 (DPMI host process needed by SPIPGM)).\nBurn the Universal Boot to a CD, place both SPIPGM and CWSDPMI7\u0026rsquo;s /bin files as well as the BIOS ROM in the C: directory on your laptop/desktop that you will be doing the flashing from. Butcher up the header cable (i.e. take off the outer sleeving so all you are left with is the header that will connect to the SPI Port and about 1M of wires.\nThe guide to creating this cable is detailed here, note it is VERY important to use the 3V line from the spare PSU (to hot-wire the spare PSU use the paperclip and make a connection between the green wire and ANY black wire) and NOT 2x AA batteries as 2x AA\u0026rsquo;s will not work (believe me I\u0026rsquo;ve tried), also ignore the bootable USB as were using a CD.\nOnce you have created the flashing cable then it is time to plug it into the Serial Port on your chosen flashing computer (Make sure it\u0026rsquo;s mode is set to LPT port as detailed in the pdf, check and recheck these!) The ports should be as so:\n   LPT Port SPI Port     7 3   8 4   9 6   10 5   18 2   DB25 (LPT Port Pinout) SPI Port Pinout          Once you have everything hooked up and triple checked (don\u0026rsquo;t forget to hook up port 1 to +3V and 2 (that is also connected to 18 on the LPT) to 0V), then it\u0026rsquo;s time to shut down your laptop/desktop that you wish to flash from and change the BIOS to boot from CD, restart again and boot into the CD.\n(BEFORE BOOTING MAKE SURE PARALLEL PORT IS SET TO LPT/378h IN BIOS!)\nOnce in the CD select a program called _NTFS4DOS (In File System-\u0026gt;NTFS Tools-\u0026gt;Avira NTFS4DOS) This will give you access to your C: drive where you saved the CWSDPMI7 and SPIPGM and your BIOS\u0026rsquo;s ROM earlier. Once there the next thing to do is execute this from the DOS cmd line:\nSPIPGM2 /d DUMP.ROM This dumps the ROM to a file in C: called DUMP.ROM To analyze your dumped ROM upload DUMP.ROM to here:\nhttp://www.fileformat.info/tool/hexdump.htm\nSelect to 10000 characters Compare this to the first 10000 characters of the downloaded ROM (upload this via the same method).\nNext you have to flash the ROM do this by executing these commands in DOS:\nCWSDPMI SPIPGM2 /i SPIPGM2 /u SPIPGM2 /e SPIPGM2 /s BIOSNAME.rom And your done! Maybe one last ROM dump to make sure all has gone to plan and boot your broken mobo up!\nCredit to:\n http://www.fccps.cz/download/adv/frr/spi/msi_spi.html http://rayer.ic.cz/elektro/spipgm.htm http://mondotech.blogspot.com/2009/05/asus-p5b-deluxe-bios-recovery-spi-flash.html  Any problems/error codes leave a comment and I\u0026rsquo;ll do all i can to help! Just covering my ass: By carrying out these actions your are individually and solely responsible for anything that may/may not happen to your motherboard/other devices.\nWhy not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/hardware/fix-broken-motherboard/","summary":"This details how to use a serial port and custom made cable to flash the BIOS on a motherboard that is not POSTing.","title":"Fixing/Flashing a broken motherboard w/ SPIPGM2 and Serial"},{"content":"For those of you wondering how weather detection works (had it on the old site), it works through using a geolocation API to look up your IP address and map it against a database of IP locations, which then queries the Yahoo! Weather API. This can be handy for changing your site\u0026rsquo;s background to match the weather or the local time of the user.\nUpdated 15/05/2012 - Changes to Yahoo! APIs fixed in newest version below.\nFirst we need to assign the user\u0026rsquo;s IP address from the user agent to a variable.\nif (!empty($_SERVER[\u0026#39;HTTP_CLIENT_IP\u0026#39;])) { $ip=$_SERVER[\u0026#39;HTTP_CLIENT_IP\u0026#39;]; } elseif (!empty($_SERVER[\u0026#39;HTTP_X_FORWARDED_FOR\u0026#39;])) { $ip=$_SERVER[\u0026#39;HTTP_X_FORWARDED_FOR\u0026#39;]; } else { $ip=$_SERVER[\u0026#39;REMOTE_ADDR\u0026#39;]; } Now we need to get define the variable that passes the string from here to the master PHP file.\n$weather = getWeather($ip); Next we implement the main function of this file that contains the whole process, and calls all the other functions and requests.\nfunction getWeather($ip){ Next we use ipinfodb.com\u0026rsquo;s API to get the latitude and longitude for the user\u0026rsquo;s IP address. We then get the XML response from the server and assign it to the $location_xml variable. You will need to get an API key from them here (it\u0026rsquo;s free). Don\u0026rsquo;t forget to plug in your API key into the below URL.\n$url = \u0026#34;http://api.ipinfodb.com/v2/ip_query.php?key=[YOUR-API-KEY-HERE]\u0026amp;ip=\u0026#34;.$ip.\u0026#34;\u0026amp;timezone=false\u0026#34;; $location_xml = get_response($url); Then we parse the XML response with regex to find the latitude and longitude and assign them to variables.\n$lat = get_match(\u0026#39;/(.*)(.*) We then plug the latitude and longitude into the reverse geo-coder from Yahoo!, this will give us Yahoo!\u0026rsquo;s WOEID for the location (we use this to lookup the Yahoo! weather API later). And get the response from the server.\n$api_url = \u0026#34;http://where.yahooapis.com/geocode?q=\u0026#34;.$lat.\u0026#34;,+\u0026#34;.$long.\u0026#34;\u0026amp;gflags=R\u0026amp;appid=[YOUR-APP-ID]\u0026#34;; $response = get_response($api_url); Next up, regex to match the WOEID from the XML response\n$woeid = get_match(\u0026#39;/(.*) The WOEID is then passed into the Yahoo! weather API.\n$yahoo_url = \u0026#34;http://weather.yahooapis.com/forecastrss?w=\u0026#34;.$woeid; The response is retrieved from the Yahoo weather server.\n$yahoo_response = get_response($yahoo_url); Regex again, this time to extract the weather code from Yahoo!\u0026rsquo;s XMl response. This is then passed into the getWeather function.\n$weather_code = get_match(\u0026#39;/ code=\u0026#34;(.*)\u0026#34;/isU\u0026#39;,$yahoo_response); return getWeatherCode($weather_code); } This function is very simplistic. All it really does is group the weather codes into arrays, this way we don\u0026rsquo;t have to write a comment for every weather condition as we have grouped the similar ones together. It then takes the groups and assigns a text response to them.\nfunction getWeatherCode($code){ $storm = array(0,1,2,3,4,17,35,37,38,39,40,45,47); $snow = array(13,14,15,16,18,25,41,42,46); $fog = array(19,20,21,22); $windy = array(23,24); $rain = array(5,6,7,8,9,10,11,12); $cloudy = array(26,28,27); $partlycloudy = array(29,30,44); $clear = array(33,34,32,31,36); Here we use if statements to assign the text responses to the grouped weather code arrays. Smart/sarcastic responses are optional.\nif(in_array($code,$storm)){ return \u0026#34;Storms in movies never end well, so get inside. NOW.\u0026#34;; } else if(in_array($code,$snow)){ return \u0026#34;It\u0026#39;s either Eyjafjallajokull or it\u0026#39;s snowing\u0026#34;; }else if(in_array($code,$fog)){ return \u0026#34;Foggy... like Stevie Wonder in a maze\u0026#34;; }else if(in_array($code,$windy)){ return \u0026#34;Dayum it\u0026#39;s windy outside\u0026#34;; }else if(in_array($code,$rain)){ return \u0026#34;It\u0026#39;s wetter than a rainforst outside\u0026#34;; }else if(in_array($code,$cloudy)){ return \u0026#34;Dark and dingey, don\u0026#39;t you love where you live?\u0026#34;; }else if(in_array($code,$partlycloudy)){ return \u0026#34;Partly Cloudy, like last nights memories\u0026#34;; }else if(in_array($code,$clear)){ return \u0026#34;Ahh tranquility :)\u0026#34;; }else{ return \u0026#34;Your location is so remote I don\u0026#39;t know what the weather is...\u0026#34;; } } This function takes the URL\u0026rsquo;s inserted above and then parses the info so just what we need from the page remains.\nfunction get_response($url){ $request = $url; $postargs = \u0026#39;u=\u0026#39;.urlencode(\u0026#39;c\u0026#39;).\u0026#39;\u0026amp;p=\u0026#39;.urlencode(\u0026#39;GMXX6091\u0026#39;); $ch = curl_init($request); curl_setopt($ch, CURLOPT_VERBOSE, 1); curl_setopt($ch, CURLOPT_NOBODY, 0); curl_setopt($ch, CURLOPT_HEADER, 0); curl_setopt($ch, CURLOPT_USERAGENT, \u0026#39;\u0026#39;); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); $response = curl_exec($ch); $responseInfo = curl_getinfo($ch); curl_close($ch); return $response; } This last function regex\u0026rsquo;s the parameters passed into it and returns only one match.\nfunction get_match($regex,$content){ preg_match($regex,$content,$matches); return $matches[1]; } You will then need to include the file in your page above where you call it using (assuming you called it weather.php):\ninclude \u0026#34;weather.php\u0026#34;; Then call the function from the file:\necho $weather_class; Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/use-geolocation-get-user-location-weather-ip-address/","summary":"For those of you wondering how weather detection works (had it on the old site), it works through using a geolocation API to look up your IP address and map it against a database of IP locations, which then queries the Yahoo! Weather API. This can be handy for changing your site\u0026rsquo;s background to match the weather or the local time of the user.\nUpdated 15/05/2012 - Changes to Yahoo! APIs fixed in newest version below.","title":"How To: Use geolocation to get a user's location and weather from IP address"},{"content":"My friend and I bought 7Kg of thermite (5kg Fe2O3 + 2kg Al) to have some fun with\u0026hellip; This is what we came up with:\nThermite - 1Kg - Plastic Bottle    Thermite - 1Kg - Cardboard Tube    Thermite - 4Kg    Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/thermite-ftw/","summary":"My friend and I bought 7Kg of thermite (5kg Fe2O3 + 2kg Al) to have some fun with\u0026hellip; This is what we came up with:\nThermite - 1Kg - Plastic Bottle    Thermite - 1Kg - Cardboard Tube    Thermite - 4Kg    Why not follow @mylesagray on Twitter for more like this!","title":"Thermite FTW!"},{"content":"A system optimizer primarily for stripped overclocking the Windows XP operating system, built in Visual Studio 2010 for Benchtec UK by Adrian (ARandomOWl) and I.\nDownload Benchtec Toolbox V1.5.1\nSoftpedia Verified!\nUpdates V1.5.1  Added - Checkbox to change ALL other processes to low priority Added - Ability to set custom CDT file size Changed - Link on BTUK Logo To-Do - Add HWBot submission API (to submit results from desktop) To-Do - Add ability to change LOD for GTX4xx Series \u0026amp; V2xx.xx Drivers  V1.5  Fix - On Wazza the dialogues when Stabilization period was selected were in a strange order, now working okay Added - PCM05 - Transparency disable/enable tweak (System Tweaks section) Added - Screenshot - Save to dialogue to allow you to have them taken to a specific location  A system optimizer primarily for stripped overclocking operating systems.\nFeatures System Tweaks Dialogue  Pagefile control – Allows users to set and view pagefile info as well as control the initial and max sizes of the file as well as the drive it is hosted on, If no pagefile exists or it is set by the system then it will alert you to this. Maxmem – Allows users to set maxmem in XP, Vista and Windows7 – If left at 0 MaxMem limit will be removed, anything above 0 and MaxMem will be applied with that value – XP MaxMem assumes that the benching OS is the first partition in the boot.ini file. Disable Unecessary Services – Does what is says on the tin. Enable Large System Cache – Checkbox indicates the current setting of this variable, If left blank LSC will be left/turned off, if it is checked it will be left/turned on. Disable Paging Executive – Checkbox indicates the current setting of this variable, If left blank PE will be left/turned off, if it is checked it will be left/turned on – (Thanks to Jabski for this tweak). Win32 Priority Separation – Checkbox indicates the current setting of this variable, If left blank Win32PS will be set a value of 2 (default), if it is checked it will be given a value of 26 – (Thanks to Jabski for this tweak) Other Handy System Tweaks – The app will auto detect your OS and apply tweaks from 2x tweaks for Vista/7 to 4x tweaks for XP – (Thanks to Jabski for this tweak). OPB Cleaner – Very handy “Junk” cleaner for all OS’s – safe to use on 24/7 OS  Disable Cores  If the number in the box = 0 then no cores are disabled and your settings are default. Type in a number to limit the CPU cores seen by the OS Then press the “Limit Cores To” Button to apply the change and restart on.prompt To return to default type in 0 and press the “Limit Cores To” button.  WPrime  Start WPrime Set number of threads Open WPrime Tuner Start Calculation. Once specified number of threads have been started press “Start WPrime Tweak” WPrime will now run at realtime priority.  PiFast  Start HexusPiFast.bat – With pause added at the start Check Processor Affinity if you want to have the thread run on one specific core. Input number of the core that you want pifast to run on. Press Enter on the PiFast CMD Window Press “Start PiFast Tweak” PiFast41.exe will now run in realtime priority with selected affinity.  SuperPi  Start SuperPi Check Processor Affinity if you want to have the thread run on one specific core. Input number of the core that you want SuperPi to run on. Choose Wazza method and its respetive variables of your choosing Press “Start SuperPi Tweak” SuperPi will now run in realtime priority with selected affinity.  Screenshots  Insert Filename (If you want to). Choose Format (.jpg or .png). Click “Take Screenshot” Screenshot saved in application’s directory. Application Shutdown: If box is checked then the app will shutdown as soon as tweak is applied If box is unchecked the app will post a message box when tweak is complete and will not shutdown.  System Tweaks  Edit all the values you want to change (or leave the ones that you want to be left unchanged). Press the “Apply System Tweaks” Button Restart on prompt (if necessary).  OPB Cleaner  Press “Run OPB Cleaner” Button Wait 2-3 mins up to 10 if you have a dirty drive  Why not follow @mylesagray on Twitter for more like this!\n","permalink":"https://blah.cloud/miscellaneous/benchtec-toolbox/","summary":"A system optimizer primarily for stripped overclocking the Windows XP operating system, built in Visual Studio 2010 for Benchtec UK by Adrian (ARandomOWl) and I.\nDownload Benchtec Toolbox V1.5.1\nSoftpedia Verified!\nUpdates V1.5.1  Added - Checkbox to change ALL other processes to low priority Added - Ability to set custom CDT file size Changed - Link on BTUK Logo To-Do - Add HWBot submission API (to submit results from desktop) To-Do - Add ability to change LOD for GTX4xx Series \u0026amp; V2xx.","title":"BenchTec Toolbox"}]