<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Setting up K8s and the vSphere Cloud Provider using kubeadm | Blah, Cloud</title><meta name=keywords content="cloud provider,kubeadm,Kubernetes,linux,VMware,vSphere"><meta name=description content="How to enable the vSphere Cloud Provider with kubeadm"><meta name=author content="Myles Gray"><link rel=canonical href=https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/><link crossorigin=anonymous href=/assets/css/stylesheet.min.b1da2895238dfeedf27f032004268905e3f3ba403dec0ceb07be46cce8ac5b96.css integrity="sha256-sdoolSON/u3yfwMgBCaJBePzukA97AzrB75GzOisW5Y=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/scroll-toc.min.c3439d5ba4b7e2fc9f6a9ce0d863c91fdf56d0d4d5cfe1f5762a2bdcfb69efd3.js integrity="sha256-w0OdW6S34vyfapzg2GPJH99W0NTVz+H1dior3Ptp79M="></script>
<link rel=icon href=https://blah.cloud/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blah.cloud/images/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blah.cloud/images/favicon-32x32.png><link rel=apple-touch-icon href=https://blah.cloud/images/apple-touch-icon.png><link rel=mask-icon href=https://blah.cloud/images/logo.png><meta name=theme-color media="(prefers-color-scheme: dark)" content="rgba(88, 89, 91, 1)"><meta name=theme-color content="rgba(240, 202, 102, 1)"><meta name=msapplication-TileColor content="rgba(240, 202, 102, 1)"><meta name=generator content="Hugo 0.110.0"><meta property="og:title" content="Setting up K8s and the vSphere Cloud Provider using kubeadm"><meta property="og:description" content="How to enable the vSphere Cloud Provider with kubeadm"><meta property="og:type" content="article"><meta property="og:url" content="https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/"><meta property="og:image" content="https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/og-card.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-01-28T11:45:57+00:00"><meta property="article:modified_time" content="2021-10-25T15:10:00+00:00"><meta property="og:site_name" content="Blah, Cloud"><meta property="og:see_also" content="https://blah.cloud/kubernetes/clusterapi-for-vsphere-now-with-cns-support/"><meta property="og:see_also" content="https://blah.cloud/automation/using-velero-for-k8s-backup-and-restore-of-csi-volumes/"><meta property="og:see_also" content="https://blah.cloud/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/"><meta property="og:see_also" content="https://blah.cloud/infrastructure/using-cloud-init-for-vm-templating-on-vsphere/"><meta property="og:see_also" content="https://blah.cloud/kubernetes/using-the-vsphere-cloud-provider-for-k8s-to-dynamically-deploy-volumes/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/og-card.png"><meta name=twitter:title content="Setting up K8s and the vSphere Cloud Provider using kubeadm"><meta name=twitter:description content="How to enable the vSphere Cloud Provider with kubeadm"><meta name=twitter:site content="@mylesagray"><meta name=twitter:creator content="@mylesagray"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Setting up K8s and the vSphere Cloud Provider using kubeadm","item":"https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Setting up K8s and the vSphere Cloud Provider using kubeadm","name":"Setting up K8s and the vSphere Cloud Provider using kubeadm","description":"How to enable the vSphere Cloud Provider with kubeadm","keywords":["cloud provider","kubeadm","Kubernetes","linux","VMware","vSphere"],"wordCount":"2184","inLanguage":"en","image":"https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/Screenshot-2019-01-28-00.55.21.webp","datePublished":"2019-01-28T11:45:57Z","dateModified":"2021-10-25T15:10:00Z","author":{"@type":"Person","name":"Myles Gray","url":"https:\/\/blah.cloud\/about"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/"},"copyrightHolder":"Myles Gray","copyrightYear":"2019","isFamilyFriendly":"true","publisher":{"@type":"Person","name":"Myles Gray","logo":{"@type":"ImageObject","url":"https://blah.cloud/images/me.jpg"}}}</script><script defer data-domain=blah.cloud data-api=/backend/api/event src=/backend/js/script.outbound-links.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body id=top><script>window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?(document.body.classList.add("dark"),document.body.classList.remove("light")):(document.body.classList.remove("dark"),document.body.classList.add("light"));const darkModeMediaQuery=window.matchMedia("(prefers-color-scheme: dark)");darkModeMediaQuery.addListener(e=>{const t=e.matches;t?(document.body.classList.add("dark"),document.body.classList.remove("light")):(document.body.classList.remove("dark"),document.body.classList.add("light"))})</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(240, 202, 102, 1);--secondary:rgba(216, 214, 197, 1);--tertiary:rgb(75, 75, 75);--content:rgba(206, 205, 188, 1);--hljs-bg:#282a36;--code-bg:#282a36;--border:rgba(240, 202, 102, 1);--highlight:rgba(88, 89, 91, 1)}.list{background:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://blah.cloud/ accesskey=h title="Blah, Cloud. (Alt + H)"><picture><source media="(min-width: 768px)" srcset=/images/logo-title.avif type=image/avif alt=logo width=245 height=34><source media="(min-width: 768px)" srcset=/images/logo-title.webp type=image/webp alt=logo width=245 height=34><source media="(min-width: 768px)" srcset=/images/logo-title.png type=image/png alt=logo width=245 height=34><source srcset=/images/logo.avif type=image/avif alt=logo width=65 height=65><source srcset=/images/logo.webp type=image/webp alt=logo width=65 height=65><img class=logo src=/images/logo-title.png alt=logo aria-label=logo width=245 height=34></picture></a></div><span class=logo-switches></span><span class=hamburger><button id=hamburger-toggle accesskey=m title="(Alt + M)"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="28" viewBox="0 0 24 28"><path d="M24 21v2c0 .547-.453 1-1 1H1c-.547.0-1-.453-1-1v-2c0-.547.453-1 1-1h22c.547.0 1 .453 1 1zm0-8v2c0 .547-.453 1-1 1H1c-.547.0-1-.453-1-1v-2c0-.547.453-1 1-1h22c.547.0 1 .453 1 1zm0-8v2c0 .547-.453 1-1 1H1c-.547.0-1-.453-1-1V5c0-.547.453-1 1-1h22c.547.0 1 .453 1 1z"/></svg></button></span><ul id=menu><li><a href=https://blah.cloud/now/ title=now><span>now</span></a></li><li><a href=https://blah.cloud/blog/ title=blog><span>blog</span></a></li><li><a href=https://blah.cloud/bio/ title=bio><span>bio</span></a></li><li><a href=https://blah.cloud/works/ title=works><span>works</span></a></li><li><a href=https://blah.cloud/search/ title=" (Alt + /)" accesskey=/><span><svg style="height:1em" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="fill-current w-5" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></a></li></ul></nav></header><div class=container><main class=main><div class=wrapper><article class=post-single><header class=post-header><h1 class=post-title>Setting up K8s and the vSphere Cloud Provider using kubeadm</h1><div class=post-description>How to enable the vSphere Cloud Provider with kubeadm</div><div class=post-meta><span title='2019-01-28 11:45:57 +0000 UTC'>January 28, 2019</span>&nbsp;·&nbsp;Myles Gray&nbsp;|&nbsp;<a href=https://github.com/mylesagray/blog/blob/master/content/posts/2019-01-28-setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img srcset="https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/Screenshot-2019-01-28-00.55.21_huf852c2ac4212933935884267b7cfc2b7_24564_360x0_resize_q75_h2_box_2.webp 360w ,https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/Screenshot-2019-01-28-00.55.21_huf852c2ac4212933935884267b7cfc2b7_24564_480x0_resize_q75_h2_box_2.webp 480w ,https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/Screenshot-2019-01-28-00.55.21_huf852c2ac4212933935884267b7cfc2b7_24564_720x0_resize_q75_h2_box_2.webp 720w ,https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/Screenshot-2019-01-28-00.55.21.webp 740w" sizes="(min-width: 768px) 720px, 100vw" src=https://blah.cloud/kubernetes/setting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm/images/Screenshot-2019-01-28-00.55.21.webp alt="Running K8s cluster with VCP" width=740 height=271></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#intro aria-label=Intro>Intro</a></li><li><a href=#prerequisites aria-label=Prerequisites>Prerequisites</a><ul><li><a href=#tools aria-label=Tools>Tools</a></li><li><a href=#optional-use-of-tmux aria-label="Optional use of tmux">Optional use of tmux</a></li></ul></li><li><a href=#setting-up-vms-with-k8s-components aria-label="Setting up VMs with K8s components">Setting up VMs with K8s components</a><ul><li><a href=#on-all-nodes aria-label="On all nodes">On all nodes</a></li></ul></li><li><a href=#enabling-the-vmware-vsphere-cloud-provider aria-label="Enabling the VMware vSphere Cloud Provider">Enabling the VMware vSphere Cloud Provider</a><ul><li><a href=#on-the-masters aria-label="On the master(s)">On the master(s)</a><ul><li><a href=#create-your-vsphereconf-file-with-vcenter-details aria-label="Create your vsphere.conf file with vCenter details">Create your <code>vsphere.conf</code> file with vCenter details</a></li></ul></li></ul></li><li><a href=#initialising-the-cluster-with-kubeadm aria-label="Initialising the cluster with kubeadm">Initialising the cluster with kubeadm</a><ul><li><a href=#on-all-nodes-1 aria-label="On all nodes">On all nodes</a></li><li><a href=#on-the-master-nodes aria-label="On the master node(s)">On the master node(s)</a></li><li><a href=#on-your-laptop aria-label="On your laptop">On your laptop</a></li><li><a href=#on-the-worker-nodes aria-label="On the worker nodes">On the worker nodes</a></li></ul></li><li><a href=#verify-setup aria-label="Verify setup">Verify setup</a></li></ul></div></details></div><div class=post-content><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>In the <a href=/kubernetes/creating-an-ubuntu-18-04-lts-cloud-image-for-cloning-on-vmware/>last installment</a> we created an Ubuntu 18.04 LTS image to use to clone VMs from for spinning up our K8s nodes, we then cloned four VMs out, one as the master and three to be used as workers.</p><p>This time we are going to step through installing all the necessary K8s components on each of the nodes (<code>kubeadm</code>, <code>kubectl</code> and <code>kubelet</code>), the container runtime (Docker) and configuring the vSphere Cloud Provider for Kubernetes using <code>kubeadm</code> to bootstrap the cluster. We have a lot to cover, so let&rsquo;s get to it!</p><h2 id=prerequisites>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites>#</a></h2><h3 id=tools>Tools<a hidden class=anchor aria-hidden=true href=#tools>#</a></h3><p>I am using macOS, so will be using the <code>brew</code> package manager to install and manage my tools, if you are using Linux or Windows, use the appropriate install guide for each tool, according to your OS.</p><p>For each tool I will list the <code>brew</code> install command and the link to the install instructions for other OSes.</p><ul><li>brew<ul><li><a href=https://brew.sh target=_blank>https://brew.sh ↗</a></li></ul></li><li>govc - <code>brew tap govmomi/tap/govc && brew install govmomi/tap/govc</code><ul><li><a href=https://github.com/vmware/govmomi/tree/master/govc target=_blank>https://github.com/vmware/govmomi/tree/master/govc ↗</a></li></ul></li><li>kubectl - <code>brew install kubernetes-cli</code><ul><li><a href=https://kubernetes.io/docs/tasks/tools/install-kubectl/ target=_blank>https://kubernetes.io/docs/tasks/tools/install-kubectl/ ↗</a></li></ul></li><li>tmux (optional) - <code>brew install tmux</code><ul><li><a href=https://github.com/tmux/tmux target=_blank>https://github.com/tmux/tmux ↗</a></li></ul></li></ul><h3 id=optional-use-of-tmux>Optional use of tmux<a hidden class=anchor aria-hidden=true href=#optional-use-of-tmux>#</a></h3><p>If you want to speed things up and type the same commands to multiple sessions at once (there is going to be a lot or repetition otherwise), use <code>tmux</code> to open a SSH session to each of the IP addresses for your VMs (for more info see <a href=https://hackernoon.com/a-gentle-introduction-to-tmux-8d784c404340 target=_blank>here ↗</a>)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tmux new<span class=se>\;</span> split-window<span class=se>\;</span> split-window<span class=se>\;</span> split-window<span class=se>\;</span> <span class=k>select</span>-layout even-vertical
</span></span><span class=line><span class=cl><span class=c1># Use ctrl b, then the arrow keys to cycle through the tmux panes and SSH to each box independently</span>
</span></span><span class=line><span class=cl>ssh ubuntu@vm.ip.address.here
</span></span></code></pre></div><p>If you followed my tutuorial last time and all your boxes are named in the <code>k8s*</code> pattern, you can use the below command to get their IP addresses</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>govc find / -type m -name <span class=s1>&#39;k8s*&#39;</span> <span class=p>|</span> xargs govc vm.info <span class=p>|</span> grep <span class=s1>&#39;Name:\|IP&#39;</span>
</span></span></code></pre></div><p>Once you have SSH&rsquo;d in to each box independently, you can turn on synchronisation</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ctrl b, <span class=nb>shift</span> :, <span class=nb>set</span> synchronize-panes on
</span></span></code></pre></div><p>I did up a quick <code>asciinema</code> to <a href=https://asciinema.org/a/223790 target=_blank>illustrate setup and use ↗</a>:</p><p><a href=https://asciinema.org/a/223790 target=_blank><img loading=lazy src=https://asciinema.org/a/223790.svg alt=asciicast> ↗</a></p><h2 id=setting-up-vms-with-k8s-components>Setting up VMs with K8s components<a hidden class=anchor aria-hidden=true href=#setting-up-vms-with-k8s-components>#</a></h2><h3 id=on-all-nodes>On all nodes<a hidden class=anchor aria-hidden=true href=#on-all-nodes>#</a></h3><p>Install the container runtime (in our case Docker)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install Docker CE</span>
</span></span><span class=line><span class=cl><span class=c1># Update the apt package index</span>
</span></span><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Install packages to allow apt to use a repository over HTTPS</span>
</span></span><span class=line><span class=cl>sudo apt install ca-certificates software-properties-common apt-transport-https curl -y
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Add Docker’s official GPG key</span>
</span></span><span class=line><span class=cl>curl -fsSL https://download.docker.com/linux/ubuntu/gpg <span class=p>|</span> sudo apt-key add -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Add docker apt repository.</span>
</span></span><span class=line><span class=cl>sudo add-apt-repository <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=s2>&#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
</span></span></span><span class=line><span class=cl><span class=s2></span><span class=k>$(</span>lsb_release -cs<span class=k>)</span><span class=s2> \
</span></span></span><span class=line><span class=cl><span class=s2>stable&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install docker ce (latest supported for K8s 1.13 is Docker 18.06)</span>
</span></span><span class=line><span class=cl>sudo apt update <span class=o>&amp;&amp;</span> sudo apt install docker-ce<span class=o>=</span>18.06.1~ce~3-0~ubuntu -y
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Setup daemon parameters, like log rotation and cgroups</span>
</span></span><span class=line><span class=cl>sudo tee /etc/docker/daemon.json &gt;/dev/null <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>{
</span></span></span><span class=line><span class=cl><span class=s>  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
</span></span></span><span class=line><span class=cl><span class=s>  &#34;log-driver&#34;: &#34;json-file&#34;,
</span></span></span><span class=line><span class=cl><span class=s>  &#34;log-opts&#34;: {
</span></span></span><span class=line><span class=cl><span class=s>    &#34;max-size&#34;: &#34;100m&#34;
</span></span></span><span class=line><span class=cl><span class=s>  },
</span></span></span><span class=line><span class=cl><span class=s>  &#34;storage-driver&#34;: &#34;overlay2&#34;
</span></span></span><span class=line><span class=cl><span class=s>}
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo mkdir -p /etc/systemd/system/docker.service.d
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Restart docker.</span>
</span></span><span class=line><span class=cl>sudo systemctl daemon-reload
</span></span><span class=line><span class=cl>sudo systemctl restart docker
</span></span></code></pre></div><p>Install the K8s components</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Add the K8s repo to apt</span>
</span></span><span class=line><span class=cl>curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg <span class=p>|</span> sudo apt-key add -
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;deb https://apt.kubernetes.io/ kubernetes-xenial main&#34;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/kubernetes.list &gt;/dev/null
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install kubelet, kubectl and kubeadm for cluster spinup</span>
</span></span><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>sudo apt install kubelet kubeadm kubectl -y
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Hold K8s packages at their installed version so as not to upgrade unexpectedly on an apt upgrade</span>
</span></span><span class=line><span class=cl>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div><p>We will be using <a href=https://github.com/coreos/flannel target=_blank><code>flannel</code> ↗</a> for pod networking in this example, so the below needs to be run on all nodes to pass <a href=https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#tabs-pod-install-4 target=_blank>bridged IPv4 traffic to iptables chains ↗</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo sysctl net.bridge.bridge-nf-call-iptables<span class=o>=</span><span class=m>1</span>
</span></span></code></pre></div><h2 id=enabling-the-vmware-vsphere-cloud-provider>Enabling the VMware vSphere Cloud Provider<a hidden class=anchor aria-hidden=true href=#enabling-the-vmware-vsphere-cloud-provider>#</a></h2><h3 id=on-the-masters>On the master(s)<a hidden class=anchor aria-hidden=true href=#on-the-masters>#</a></h3><h4 id=create-your-vsphereconf-file-with-vcenter-details>Create your <code>vsphere.conf</code> file with vCenter details<a hidden class=anchor aria-hidden=true href=#create-your-vsphereconf-file-with-vcenter-details>#</a></h4><p>Edit the below command to fill in your vCenter details before running.</p><p>If you don&rsquo;t have a folder created with your kubernetes node VMs added we can do that quickly with <code>govc</code> (note, change <code>vSAN-DC</code> to your Datacenter name in vCenter):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>govc folder.create /vSAN-DC/vm/k8s
</span></span><span class=line><span class=cl>govc object.mv /vSAN-DC/vm/k8s-<span class=se>\*</span> /vSAN-DC/vm/k8s
</span></span></code></pre></div><p>Details on <a href=https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/existing.html target=_blank>syntax can be found here ↗</a>. It is important to note, whatever VM folder you specify below needs to be pre-created in your vCenter, in my case the folder is called <code>k8s</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo tee /etc/kubernetes/vsphere.conf &gt;/dev/null <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>[Global]
</span></span></span><span class=line><span class=cl><span class=s>user = &#34;administrator@vsphere.local&#34;
</span></span></span><span class=line><span class=cl><span class=s>password = &#34;Admin!23&#34;
</span></span></span><span class=line><span class=cl><span class=s>port = &#34;443&#34;
</span></span></span><span class=line><span class=cl><span class=s>insecure-flag = &#34;1&#34;
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[VirtualCenter &#34;10.198.17.154&#34;]
</span></span></span><span class=line><span class=cl><span class=s>datacenters = &#34;vSAN-DC&#34;
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[Workspace]
</span></span></span><span class=line><span class=cl><span class=s>server = &#34;10.198.17.154&#34;
</span></span></span><span class=line><span class=cl><span class=s>datacenter = &#34;vSAN-DC&#34;
</span></span></span><span class=line><span class=cl><span class=s>default-datastore = &#34;vsanDatastore&#34;
</span></span></span><span class=line><span class=cl><span class=s>resourcepool-path = &#34;vSAN-Cluster/Resources&#34;
</span></span></span><span class=line><span class=cl><span class=s>folder = &#34;k8s&#34;
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[Disk]
</span></span></span><span class=line><span class=cl><span class=s>scsicontrollertype = pvscsi
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[Network]
</span></span></span><span class=line><span class=cl><span class=s>public-network = &#34;VM Network&#34;
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></div><p>Activate the vSphere Cloud Provider in our <code>kubeadm init</code> config file. Additionally, as we are deploying <code>flannel</code> as our overlay network for pods and it requires the below subnet CIDR in order for the overlay to work.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=l>sudo tee /etc/kubernetes/kubeadminitmaster.yaml &gt;/dev/null &lt;&lt;EOF</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>kubeadm.k8s.io/v1beta1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>InitConfiguration</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>bootstrapTokens</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span>- <span class=nt>groups</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span>- <span class=l>system:bootstrappers:kubeadm:default-node-token</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=nt>token</span><span class=p>:</span><span class=w> </span><span class=l>y7yaev.9dvwxx6ny4ef8vlq</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=nt>ttl</span><span class=p>:</span><span class=w> </span><span class=l>0s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=nt>usages</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span>- <span class=l>signing</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span>- <span class=l>authentication</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>nodeRegistration</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kubeletExtraArgs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-provider</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;vsphere&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-config</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>kubeadm.k8s.io/v1beta1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ClusterConfiguration</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kubernetesVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1.13.3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiServer</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>extraArgs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-provider</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;vsphere&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-config</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>extraVolumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>cloud</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>controllerManager</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>extraArgs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-provider</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;vsphere&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-config</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>extraVolumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>cloud</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/kubernetes/vsphere.conf&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>networking</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>podSubnet</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;10.244.0.0/16&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>EOF</span><span class=w>
</span></span></span></code></pre></div><p>Restart the kubelet daemon to reload the configuration</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl daemon-reload
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span></code></pre></div><h2 id=initialising-the-cluster-with-kubeadm>Initialising the cluster with kubeadm<a hidden class=anchor aria-hidden=true href=#initialising-the-cluster-with-kubeadm>#</a></h2><h3 id=on-all-nodes-1>On all nodes<a hidden class=anchor aria-hidden=true href=#on-all-nodes-1>#</a></h3><p>Firstly, verify that connectivity to the required <code>gcr.io</code> registries is working by pulling the containers required by <code>kubeadm</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ sudo kubeadm config images pull
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/kube-apiserver:v1.13.2
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/kube-controller-manager:v1.13.2
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/kube-scheduler:v1.13.2
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/kube-proxy:v1.13.2
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/pause:3.1
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/etcd:3.2.24
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled k8s.gcr.io/coredns:1.2.6
</span></span></code></pre></div><h3 id=on-the-master-nodes>On the master node(s)<a hidden class=anchor aria-hidden=true href=#on-the-master-nodes>#</a></h3><p>Initialise <code>kubeadm</code> with the config file from above which includes our vSphere Cloud Provider and Flannel CIDR configurations.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ sudo kubeadm init --config /etc/kubernetes/kubeadminitmaster.yaml
</span></span><span class=line><span class=cl><span class=o>[</span>init<span class=o>]</span> Using Kubernetes version: v1.13.0
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Running pre-flight checks
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Pulling images required <span class=k>for</span> setting up a Kubernetes cluster
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> This might take a minute or two, depending on the speed of your internet connection
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> You can also perform this action in beforehand using <span class=s1>&#39;kubeadm config images pull&#39;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet environment file with flags to file <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet configuration to file <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Activating the kubelet service
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Using certificateDir folder <span class=s2>&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/peer&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> etcd/peer serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>k8s-master localhost<span class=o>]</span> and IPs <span class=o>[</span>10.198.17.177 127.0.0.1 ::1<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/healthcheck-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver-etcd-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/server&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> etcd/server serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>k8s-master localhost<span class=o>]</span> and IPs <span class=o>[</span>10.198.17.177 127.0.0.1 ::1<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> apiserver serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local<span class=o>]</span> and IPs <span class=o>[</span>10.96.0.1 10.198.17.177<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver-kubelet-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;front-proxy-ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;front-proxy-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;sa&#34;</span> key and public key
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Using kubeconfig folder <span class=s2>&#34;/etc/kubernetes&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;admin.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;kubelet.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;controller-manager.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;scheduler.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Using manifest folder <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>controlplane<span class=o>]</span> Adding extra host path mount <span class=s2>&#34;cloud&#34;</span> to <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>controlplane<span class=o>]</span> Adding extra host path mount <span class=s2>&#34;cloud&#34;</span> to <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>controlplane<span class=o>]</span> Adding extra host path mount <span class=s2>&#34;cloud&#34;</span> to <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>controlplane<span class=o>]</span> Adding extra host path mount <span class=s2>&#34;cloud&#34;</span> to <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-scheduler&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>controlplane<span class=o>]</span> Adding extra host path mount <span class=s2>&#34;cloud&#34;</span> to <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>controlplane<span class=o>]</span> Adding extra host path mount <span class=s2>&#34;cloud&#34;</span> to <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>etcd<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=nb>local</span> etcd in <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>wait-control-plane<span class=o>]</span> Waiting <span class=k>for</span> the kubelet to boot up the control plane as static Pods from directory <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
</span></span><span class=line><span class=cl><span class=o>[</span>apiclient<span class=o>]</span> All control plane components are healthy after 23.503056 seconds
</span></span><span class=line><span class=cl><span class=o>[</span>uploadconfig<span class=o>]</span> storing the configuration used in ConfigMap <span class=s2>&#34;kubeadm-config&#34;</span> in the <span class=s2>&#34;kube-system&#34;</span> Namespace
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet<span class=o>]</span> Creating a ConfigMap <span class=s2>&#34;kubelet-config-1.13&#34;</span> in namespace kube-system with the configuration <span class=k>for</span> the kubelets in the cluster
</span></span><span class=line><span class=cl><span class=o>[</span>patchnode<span class=o>]</span> Uploading the CRI Socket information <span class=s2>&#34;/var/run/dockershim.sock&#34;</span> to the Node API object <span class=s2>&#34;k8s-master&#34;</span> as an annotation
</span></span><span class=line><span class=cl><span class=o>[</span>mark-control-plane<span class=o>]</span> Marking the node k8s-master as control-plane by adding the label <span class=s2>&#34;node-role.kubernetes.io/master=&#39;&#39;&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>mark-control-plane<span class=o>]</span> Marking the node k8s-master as control-plane by adding the taints <span class=o>[</span>node-role.kubernetes.io/master:NoSchedule<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Using token: p8iv6v.zu8eofjtbc9r54dd
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
</span></span><span class=line><span class=cl><span class=o>[</span>bootstraptoken<span class=o>]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span class=k>for</span> nodes to get long term certificate credentials
</span></span><span class=line><span class=cl><span class=o>[</span>bootstraptoken<span class=o>]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
</span></span><span class=line><span class=cl><span class=o>[</span>bootstraptoken<span class=o>]</span> configured RBAC rules to allow certificate rotation <span class=k>for</span> all node client certificates in the cluster
</span></span><span class=line><span class=cl><span class=o>[</span>bootstraptoken<span class=o>]</span> creating the <span class=s2>&#34;cluster-info&#34;</span> ConfigMap in the <span class=s2>&#34;kube-public&#34;</span> namespace
</span></span><span class=line><span class=cl><span class=o>[</span>addons<span class=o>]</span> Applied essential addon: CoreDNS
</span></span><span class=line><span class=cl><span class=o>[</span>addons<span class=o>]</span> Applied essential addon: kube-proxy
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Your Kubernetes master has initialized successfully!
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>To start using your cluster, you need to run the following as a regular user:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>  sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>  sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>You should now deploy a pod network to the cluster.
</span></span><span class=line><span class=cl>Run <span class=s2>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span class=line><span class=cl>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>You can now join any number of machines by running the following on each node
</span></span><span class=line><span class=cl>as root:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  kubeadm join 10.198.17.177:6443 --token p8iv6v.zu8eofjtbc9r54dd --discovery-token-ca-cert-hash sha256:398f667fb3a6ffe6296e4d07c825834b54cce73bacf58641915cf79a1d1895f7
</span></span></code></pre></div><p>A lot of text will output as it spins up the cluster components, if all is successful, we can start using the cluster now by importing the <code>kubeconfig</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span></code></pre></div><p>You can also use it on external systems by copying the output from the below command into your local computer&rsquo;s <code>~/.kube/config</code> file:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo cat /etc/kubernetes/admin.conf
</span></span></code></pre></div><p>Let&rsquo;s deploy our <code>flannel</code> pod overlay networking so the pods can communicate with each other.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml
</span></span></code></pre></div><p>Check to make sure the pods are all in the status <code>Running</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ kubectl get pods --all-namespaces
</span></span><span class=line><span class=cl>NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE
</span></span><span class=line><span class=cl>kube-system   coredns-86c58d9df4-fqbdm             1/1     Running   <span class=m>0</span>          2m19s
</span></span><span class=line><span class=cl>kube-system   coredns-86c58d9df4-zhpj6             1/1     Running   <span class=m>0</span>          2m19s
</span></span><span class=line><span class=cl>kube-system   etcd-k8s-master                      1/1     Running   <span class=m>0</span>          2m37s
</span></span><span class=line><span class=cl>kube-system   kube-apiserver-k8s-master            1/1     Running   <span class=m>0</span>          68s
</span></span><span class=line><span class=cl>kube-system   kube-controller-manager-k8s-master   1/1     Running   <span class=m>0</span>          2m36s
</span></span><span class=line><span class=cl>kube-system   kube-flannel-ds-amd64-8cst6          1/1     Running   <span class=m>0</span>          26s
</span></span><span class=line><span class=cl>kube-system   kube-proxy-6grkv                     1/1     Running   <span class=m>0</span>          2m19s
</span></span><span class=line><span class=cl>kube-system   kube-scheduler-k8s-master            1/1     Running   <span class=m>0</span>          2m36s
</span></span></code></pre></div><p>Export the master node config used to point the workers being joined to the master:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl -n kube-public get configmap cluster-info -o <span class=nv>jsonpath</span><span class=o>=</span><span class=s1>&#39;{.data.kubeconfig}&#39;</span> &gt; discovery.yaml
</span></span></code></pre></div><h3 id=on-your-laptop>On your laptop<a hidden class=anchor aria-hidden=true href=#on-your-laptop>#</a></h3><p>Copy the <code>discovery.yaml</code> to your local machine with <code>scp</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>scp ubuntu@10.198.17.177:~/discovery.yaml discovery.yaml
</span></span></code></pre></div><p>Then upload it to the worker nodes.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>scp discovery.yaml ubuntu@10.198.17.189:~/discovery.yaml
</span></span><span class=line><span class=cl>scp discovery.yaml ubuntu@10.198.17.190:~/discovery.yaml
</span></span><span class=line><span class=cl>scp discovery.yaml ubuntu@10.198.17.191:~/discovery.yaml
</span></span></code></pre></div><h3 id=on-the-worker-nodes>On the worker nodes<a hidden class=anchor aria-hidden=true href=#on-the-worker-nodes>#</a></h3><p>To check and make sure the <code>discovery.yaml</code> file was copied correctly, do a quick <code>cat</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/discovery.yaml
</span></span></code></pre></div><p>Then create the worker node <code>kubeadm</code> config yaml file (notice it&rsquo;s using our <code>discovery.yaml</code> as the input for master discovery) and the <code>token</code> is the same as we put in the master <code>kubeadminitmaster.yaml</code> configuration above and we specify the <code>cloud-provider</code> as <code>vsphere</code> for the workers:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=l>sudo tee /etc/kubernetes/kubeadminitworker.yaml &gt;/dev/null &lt;&lt;EOF</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>kubeadm.k8s.io/v1alpha3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>JoinConfiguration</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>discoveryFile</span><span class=p>:</span><span class=w> </span><span class=l>discovery.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>token</span><span class=p>:</span><span class=w> </span><span class=l>y7yaev.9dvwxx6ny4ef8vlq</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>nodeRegistration</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kubeletExtraArgs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud-provider</span><span class=p>:</span><span class=w> </span><span class=l>vsphere</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>EOF</span><span class=w>
</span></span></span></code></pre></div><p>And now we should be able to join our workers to the cluster.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ sudo kubeadm join --config /etc/kubernetes/kubeadminitworker.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Running pre-flight checks
</span></span><span class=line><span class=cl><span class=o>[</span>discovery<span class=o>]</span> Trying to connect to API Server <span class=s2>&#34;10.198.17.177:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>discovery<span class=o>]</span> Created cluster-info discovery client, requesting info from <span class=s2>&#34;https://10.198.17.177:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>discovery<span class=o>]</span> Requesting info from <span class=s2>&#34;https://10.198.17.177:6443&#34;</span> again to validate TLS against the pinned public key
</span></span><span class=line><span class=cl><span class=o>[</span>discovery<span class=o>]</span> Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server <span class=s2>&#34;10.198.17.177:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>discovery<span class=o>]</span> Successfully established connection with API Server <span class=s2>&#34;10.198.17.177:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>join<span class=o>]</span> Reading configuration from the cluster...
</span></span><span class=line><span class=cl><span class=o>[</span>join<span class=o>]</span> FYI: You can look at this config file with <span class=s1>&#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet<span class=o>]</span> Downloading configuration <span class=k>for</span> the kubelet from the <span class=s2>&#34;kubelet-config-1.13&#34;</span> ConfigMap in the kube-system namespace
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet configuration to file <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet environment file with flags to file <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Activating the kubelet service
</span></span><span class=line><span class=cl><span class=o>[</span>tlsbootstrap<span class=o>]</span> Waiting <span class=k>for</span> the kubelet to perform the TLS Bootstrap...
</span></span><span class=line><span class=cl><span class=o>[</span>patchnode<span class=o>]</span> Uploading the CRI Socket information <span class=s2>&#34;/var/run/dockershim.sock&#34;</span> to the Node API object <span class=s2>&#34;k8s-worker1&#34;</span> as an annotation
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>This node has joined the cluster:
</span></span><span class=line><span class=cl>*Certificate signing request was sent to apiserver and a response was received.
</span></span><span class=line><span class=cl>* The Kubelet was informed of the new secure connection details.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Run <span class=s1>&#39;kubectl get nodes&#39;</span> on the master to see this node join the cluster.
</span></span></code></pre></div><h2 id=verify-setup>Verify setup<a hidden class=anchor aria-hidden=true href=#verify-setup>#</a></h2><p>Now, as the output says above, back on the master check that all nodes have joined the cluster</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ubuntu@k8s-master:~$ kubectl get nodes -o wide
</span></span><span class=line><span class=cl>NAME          STATUS   ROLES    AGE     VERSION   INTERNAL-IP     EXTERNAL-IP     OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
</span></span><span class=line><span class=cl>k8s-master    Ready    master   4m44s   v1.13.2   10.198.17.177   10.198.17.177   Ubuntu 18.04.1 LTS   4.15.0-43-generic   docker://18.6.0
</span></span><span class=line><span class=cl>k8s-worker1   Ready    &lt;none&gt;   33s     v1.13.2   10.198.17.174   &lt;none&gt;          Ubuntu 18.04.1 LTS   4.15.0-43-generic   docker://18.6.0
</span></span><span class=line><span class=cl>k8s-worker2   Ready    &lt;none&gt;   32s     v1.13.2   10.198.17.175   &lt;none&gt;          Ubuntu 18.04.1 LTS   4.15.0-43-generic   docker://18.6.0
</span></span><span class=line><span class=cl>k8s-worker3   Ready    &lt;none&gt;   32s     v1.13.2   10.198.17.176   &lt;none&gt;          Ubuntu 18.04.1 LTS   4.15.0-43-generic   docker://18.6.0
</span></span></code></pre></div><p>Verify the <code>providerID</code> is set on all the nodes for the VCP to operate correctly:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ubuntu@k8s-master:~$ kubectl describe nodes <span class=p>|</span> grep <span class=s2>&#34;ProviderID&#34;</span>
</span></span><span class=line><span class=cl>ProviderID:                  vsphere://420f0d85-cf4a-c7a7-e52d-18e9b4b71dec
</span></span><span class=line><span class=cl>ProviderID:                  vsphere://420fc2b2-64ab-a477-f7b1-37d4e6747abf
</span></span><span class=line><span class=cl>ProviderID:                  vsphere://420f2d75-37bd-8b56-4e2f-421cbcbbb0b2
</span></span><span class=line><span class=cl>ProviderID:                  vsphere://420f7ec3-2dbd-601e-240b-4ee6d8945210
</span></span></code></pre></div><p>We now have a fully up and running k8s cluster with the vSphere Cloud Provider installed! Check out <a href=/kubernetes/using-the-vsphere-cloud-provider-for-k8s-to-dynamically-deploy-volumes/>part 3 where we install</a> the K8s dashboard and show how the integration with the vSphere Cloud Provider really works!</p><p>Why not follow <a href=https://twitter.com/mylesagray target=_blank>@mylesagray on Twitter ↗</a> for more like this!</p></div><footer class=post-footer><section class="section post-tags"><div class=content><h2>Tagged with</h2></div><ul class=post-tags><li><a href=https://blah.cloud/tags/cloud-provider/>cloud provider</a></li><li><a href=https://blah.cloud/tags/kubeadm/>kubeadm</a></li><li><a href=https://blah.cloud/tags/kubernetes/>Kubernetes</a></li><li><a href=https://blah.cloud/tags/linux/>linux</a></li><li><a href=https://blah.cloud/tags/vmware/>VMware</a></li><li><a href=https://blah.cloud/tags/vsphere/>vSphere</a></li></ul></section><nav class=paginav><a class=prev href=https://blah.cloud/kubernetes/using-the-vsphere-cloud-provider-for-k8s-to-dynamically-deploy-volumes/><span class=title>« Prev Page</span><br><span>Using the vSphere Cloud Provider for K8s to dynamically deploy volumes</span></a>
<a class=next href=https://blah.cloud/kubernetes/creating-an-ubuntu-18-04-lts-cloud-image-for-cloning-on-vmware/><span class=title>Next Page »</span><br><span>Creating an Ubuntu 18.04 LTS cloud image for cloning on VMware</span></a></nav><section class="section related-links"><div class="columns is-centered"><div class="column max-800px"><div class=content><h2>Related content</h2></div><div class="columns related-links-columns"><div class="column is-one-third"><div class=card><div class=card-image><figure class="image is-3by2"><a href=/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/><picture><source srcset=/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/images/capv-vcenter.avif type=image/avif><source srcset=/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/images/capv-vcenter.webp type=image/webp><img src=/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/images/capv-vcenter_huc6e0049c280624f8a8590b6cf1c3b77a_78217_240x0_resize_box_3.png alt="K8s cluster running on vSphere" loading=lazy decoding=async></picture></a></figure></div><div class=card-content><a class="title is-5" href=https://blah.cloud/kubernetes/first-look-automated-k8s-lifecycle-with-clusterapi/>First-look: Automated K8s lifecycle with ClusterAPI</a></div></div></div><div class="column is-one-third"><div class=card><div class=card-image><figure class="image is-3by2"><a href=/kubernetes/creating-an-ubuntu-18-04-lts-cloud-image-for-cloning-on-vmware/><picture><img src=/kubernetes/creating-an-ubuntu-18-04-lts-cloud-image-for-cloning-on-vmware/images/Screenshot-2019-01-27-22.07.55_hu8d87a1ddb8b24fb9202e54ff2c938669_17320_240x0_resize_q75_h2_box_2.webp alt loading=lazy decoding=async></picture></a></figure></div><div class=card-content><a class="title is-5" href=https://blah.cloud/kubernetes/creating-an-ubuntu-18-04-lts-cloud-image-for-cloning-on-vmware/>Creating an Ubuntu 18.04 LTS cloud image for cloning on VMware</a></div></div></div><div class="column is-one-third"><div class=card><div class=card-image><figure class="image is-3by2"><a href=/infrastructure/using-cloud-init-for-vm-templating-on-vsphere/><picture><img src=/infrastructure/using-cloud-init-for-vm-templating-on-vsphere/images/Screenshot-2019-06-09-19.36.35_hu17e2ae314517cc6c9d3df4bcf7e2a404_13490_240x0_resize_q75_h2_box_2.webp alt="vSphere events showing cloud-init customisation" loading=lazy decoding=async></picture></a></figure></div><div class=card-content><a class="title is-5" href=https://blah.cloud/infrastructure/using-cloud-init-for-vm-templating-on-vsphere/>Using cloud-init for VM templating on vSphere</a></div></div></div></div></div></div></section><section class="section share-icons"><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Setting up K8s and the vSphere Cloud Provider using kubeadm on twitter" href="https://twitter.com/intent/tweet/?text=Setting%20up%20K8s%20and%20the%20vSphere%20Cloud%20Provider%20using%20kubeadm&url=https%3a%2f%2fblah.cloud%2fkubernetes%2fsetting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm%2f&hashtags=cloudprovider%2ckubeadm%2cKubernetes%2clinux%2cVMware%2cvSphere"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setting up K8s and the vSphere Cloud Provider using kubeadm on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblah.cloud%2fkubernetes%2fsetting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm%2f&title=Setting%20up%20K8s%20and%20the%20vSphere%20Cloud%20Provider%20using%20kubeadm"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setting up K8s and the vSphere Cloud Provider using kubeadm on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblah.cloud%2fkubernetes%2fsetting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm%2f&title=Setting%20up%20K8s%20and%20the%20vSphere%20Cloud%20Provider%20using%20kubeadm&summary=Setting%20up%20K8s%20and%20the%20vSphere%20Cloud%20Provider%20using%20kubeadm&source=https%3a%2f%2fblah.cloud%2fkubernetes%2fsetting-up-k8s-and-the-vsphere-cloud-provider-using-kubeadm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></div></section></footer><script src=https://utteranc.es/client.js repo=mylesagray/blog-comments issue-term=title theme=preferred-color-scheme crossorigin=anonymous async></script></article><aside class="hidden lg:block tableOfContentContainer" id=tableOfContentContainer><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#prerequisites>Prerequisites</a><ul><li><a href=#tools>Tools</a></li><li><a href=#optional-use-of-tmux>Optional use of tmux</a></li></ul></li><li><a href=#setting-up-vms-with-k8s-components>Setting up VMs with K8s components</a><ul><li><a href=#on-all-nodes>On all nodes</a></li></ul></li><li><a href=#enabling-the-vmware-vsphere-cloud-provider>Enabling the VMware vSphere Cloud Provider</a><ul><li><a href=#on-the-masters>On the master(s)</a></li></ul></li><li><a href=#initialising-the-cluster-with-kubeadm>Initialising the cluster with kubeadm</a><ul><li><a href=#on-all-nodes-1>On all nodes</a></li><li><a href=#on-the-master-nodes>On the master node(s)</a></li><li><a href=#on-your-laptop>On your laptop</a></li><li><a href=#on-the-worker-nodes>On the worker nodes</a></li></ul></li><li><a href=#verify-setup>Verify setup</a></li></ul></nav></aside></div></main></div><footer class=footer><span>&copy; 2023 <a href=https://blah.cloud/>Blah, Cloud</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/JPbaU rel=noopener target=_blank>BurgerMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>