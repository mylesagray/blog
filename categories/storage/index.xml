<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Storage on Blah, Cloud</title>
    <link>https://blah.cloud/categories/storage/</link>
    <description>Recent content in Storage on Blah, Cloud</description>
    <image>
      <url>https://blah.cloud/images/og-card.jpg</url>
      <link>https://blah.cloud/images/og-card.jpg</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 10 Oct 2019 12:21:35 +0000</lastBuildDate><atom:link href="https://blah.cloud/categories/storage/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ClusterAPI for vSphere, now with CNS support</title>
      <link>https://blah.cloud/kubernetes/clusterapi-for-vsphere-now-with-cns-support/</link>
      <pubDate>Thu, 10 Oct 2019 12:21:35 +0000</pubDate>
      
      <guid>https://blah.cloud/kubernetes/clusterapi-for-vsphere-now-with-cns-support/</guid>
      <description>Using CAPV to deploy K8s clusters with vSphere CNS</description>
    </item>
    
    <item>
      <title>Using Velero for K8s Backup and Restore of CSI Volumes</title>
      <link>https://blah.cloud/automation/using-velero-for-k8s-backup-and-restore-of-csi-volumes/</link>
      <pubDate>Fri, 04 Oct 2019 12:18:17 +0000</pubDate>
      
      <guid>https://blah.cloud/automation/using-velero-for-k8s-backup-and-restore-of-csi-volumes/</guid>
      <description>How to backup and restore K8s applications on vSphere</description>
    </item>
    
    <item>
      <title>Using the vSphere Cloud Provider for K8s to dynamically deploy volumes</title>
      <link>https://blah.cloud/kubernetes/using-the-vsphere-cloud-provider-for-k8s-to-dynamically-deploy-volumes/</link>
      <pubDate>Fri, 08 Feb 2019 22:38:35 +0000</pubDate>
      
      <guid>https://blah.cloud/kubernetes/using-the-vsphere-cloud-provider-for-k8s-to-dynamically-deploy-volumes/</guid>
      <description>How to provision Kubernetes Persistent Volumes dynamically on vSphere</description>
    </item>
    
    <item>
      <title>vSAN SPBM and vCloud Director</title>
      <link>https://blah.cloud/cloud/vsan-spbm-vcloud-director/</link>
      <pubDate>Sat, 02 Dec 2017 13:31:36 +0000</pubDate>
      
      <guid>https://blah.cloud/cloud/vsan-spbm-vcloud-director/</guid>
      <description>I had a question last week from Bozo Popovic during our EMEA field SE training session on vSAN operations relating to SPBM support for service providers that use vCloud Director in their environments.
Next up Mr. @mylesagray giving a #vSAN operations overview to our EMEA field at the @vmwarevsan workshop this morning pic.twitter.com/48seQc8i7d
&amp;mdash; Cormac Hogan (@CormacJHogan) November 30, 2017  I am stating this for clarity - since the vCD 9.</description>
    </item>
    
    <item>
      <title>Migrating vSAN vmkernel ports to a new subnet</title>
      <link>https://blah.cloud/infrastructure/migrating-vsan-vmkernel-ports-new-subnet/</link>
      <pubDate>Fri, 03 Nov 2017 14:01:47 +0000</pubDate>
      
      <guid>https://blah.cloud/infrastructure/migrating-vsan-vmkernel-ports-new-subnet/</guid>
      <description>After deploying a vSAN cluster, the need sometimes arises to make changes to its network configuration, such as migrating the vmkernel network of the cluster to a new subnet. This requirement may appear for example when changing the network in which the vSAN cluster is running, or even, in a more complex scenario such as when a standalone vSAN needs to be converted to a stretched cluster.
In these sorts of situations, complications may be encountered if the subnet in use for the vSAN vmkernel ports cannot be routed to the network as a whole, as it is in use elsewhere in the organization, and is currently isolated in an L2 segment.</description>
    </item>
    
    <item>
      <title>Customer, Partner, Vendor.</title>
      <link>https://blah.cloud/infrastructure/customer-partner-vendor/</link>
      <pubDate>Tue, 18 Jul 2017 11:17:15 +0000</pubDate>
      
      <guid>https://blah.cloud/infrastructure/customer-partner-vendor/</guid>
      <description>Over the last 9 months, a lot has happened in my life; I have a nice titanium plate in my shoulder now courtesy of a major car accident. I changed roles at Novosco from Infrastructure Engineer to Cloud Technologist - focusing more on R&amp;amp;D and emerging platforms, and I helped out Frank Denneman and Niels Hagoort in editing their best-selling vSphere 6.5 Host Deep Dive book.
Through the course of the time off I had as a result of now being part-Iron Man, it gave me a lot of time to think about what&amp;rsquo;s important to me and what I enjoy, as I&amp;rsquo;m sure most people do every few years.</description>
    </item>
    
    <item>
      <title>vSphere 6.5 Host Resources Deep Dive</title>
      <link>https://blah.cloud/hardware/vsphere-6-5-host-resources-deep-dive/</link>
      <pubDate>Wed, 21 Jun 2017 12:21:56 +0000</pubDate>
      
      <guid>https://blah.cloud/hardware/vsphere-6-5-host-resources-deep-dive/</guid>
      <description>Over the last 6-9 months, I have been reviewing the vast majority of a new book just released to print by Frank Denneman and Niels Hagoort - The vSphere 6.5 Host Resources Deep Dive.
 
This book is, without a doubt, the most in-depth look at host design I have ever read, we are not talking about standard best practices here, though those are in there too. More, low-level understanding of why best practices exist and even challenging some existing perceptions and paradigms about why technologies should be used and more importantly, how they should be utilised.</description>
    </item>
    
    <item>
      <title>Replicating SAN on openSUSE with VAAI</title>
      <link>https://blah.cloud/hardware/replicating-san-opensuse-vaai/</link>
      <pubDate>Sat, 27 Aug 2016 12:59:18 +0000</pubDate>
      
      <guid>https://blah.cloud/hardware/replicating-san-opensuse-vaai/</guid>
      <description>Preamble This article was written a few years back, but never published - it was some work I was doing in my lab to try and get to grips around the work involved in creating a SAN with synchronous replication built in from scratch.
It in no way should be used for production, but rather as a learning exercise - as previously stated the instructions are a few years old and version specific, so openSUSE may well now support some of the modules I had to compile and create repos for manually, also DRBD9 has been released and should obviously be used in place of DRBD8 as I have below.</description>
    </item>
    
    <item>
      <title>LSI3108 based controllers now VSAN 6.2 Certified</title>
      <link>https://blah.cloud/hardware/lsi3108-based-controllers-now-vsan-6-2-certified/</link>
      <pubDate>Fri, 29 Apr 2016 09:22:23 +0000</pubDate>
      
      <guid>https://blah.cloud/hardware/lsi3108-based-controllers-now-vsan-6-2-certified/</guid>
      <description>After a long an arduous certification and regression testing process following many problems with LSI 3108 based controllers that I have been using for VSAN they are finally VSAN 6.2 certified.
Having seen and opened multiple tickets about strange controller behaviors (hot add controller do VMware have released a FW/HW and Software combo that, according to a highly regarded VMware internal storage resource:
 Its certainly the most tested combination of a firmware/driver/controller ever at this point [&amp;hellip;] My understanding is the reason this took so long is they didnâ€™t just fix the big issue, but also minor ones too, and any minor regressions</description>
    </item>
    
    <item>
      <title>VSAN Observer RVC in vCenter Appliance 6.0 U1</title>
      <link>https://blah.cloud/virtualisation/vsan-observer-rvc-in-vcenter-appliance-6-0-u1/</link>
      <pubDate>Tue, 06 Oct 2015 09:18:45 +0000</pubDate>
      
      <guid>https://blah.cloud/virtualisation/vsan-observer-rvc-in-vcenter-appliance-6-0-u1/</guid>
      <description>Using vSAN observer inside vCenter 6.0</description>
    </item>
    
    <item>
      <title>Fix for CBT bug in VMWare Products</title>
      <link>https://blah.cloud/infrastructure/fix-cbt-bug-vmware-products/</link>
      <pubDate>Tue, 02 Dec 2014 18:00:13 +0000</pubDate>
      
      <guid>https://blah.cloud/infrastructure/fix-cbt-bug-vmware-products/</guid>
      <description>VMWare, as of writing, has a nasty bug that means your backups that run utilising CBT (hint: if you have basically any enterprise backup product worth its salt, it&amp;rsquo;s got CBT enabled) it loses track of the changed blocks when the VMDK reaches any Power 2 value of 128GB (128, 256, 512, 1024, etc.) which may make your backup unrecoverable.
The VMWare bug is in KB:
 kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;amp;cmd=displayKC&amp;amp;externalId=2090639
 The remedy for this is to disable and re-enable (reset) CBT on the affected machines, this can be done with the machine powered off or with it turned on by running PowerCLI commands and a snapshot, we will be doing the latter, no one likes downtime:</description>
    </item>
    
  </channel>
</rss>
